---
title: "9주차 머신러닝의 적용"
excerpt: "예측 함수의 성능 평가, 최적 모델의 선택, Bias와 Variance, 학습 곡선, 학습 알고리즘의 성능 향상에 대해 다룹니다."

wirter: myeongwoo Yoon
categories:
  - Machine Learning
tags:
  - Machine Learning

toc: true
toc_sticky: true
use_math: true
  
date: 2025-06-14
last_modified_at: 2025-06-14
---

예측 함수의 성능 평가
======

* 예측 함수 $h(x)$: 입력값 $x$에 대해 출력값 $y$를 예측하는 머신러닝 모델
  - 보통 파라미터 $w$를 포함해 $h(x;w)$로 나타냄
  <p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-1.png" width="500"></p>
* 최적 파라미터 $w^{*}$: 비용 함수를 최소화하는 값
  <p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-2.png" width="400"></p>
* 학습 완료 후 모델 평가: 학습에 사용되지 않은 **unseen data(test set)**을 사용해 **일반화 성능 평가**

Options to Consider To Improve Learning Algorithms
------

1. 데이터 수 늘리기(Collecting more training samples)
  - 일반화 성능 향상 가능, 하지만 비용 큼
  - Sometimes getting more training data does not help
2. 특징 수 줄이기(Try smaller set of features)
  - 오버피팅(Overfitting) 방지
3. 특징 수 늘리기(Try getting additional features)
  - If current set of features are not informative enough
4. Polynomial Feature 추가(Try adding polynomial features)
  - 곱, 제곱 등($x^2_1, x^2_2, x_1x_2$ 등등)을 하여 새로운 특징 값 추가
5. 정규화 파라미터 $\lambda$ 감소(Try decreasing regularization parameter $\lambda$)
  - 학습 데이터 적합성 향상(To fit to the training data well)
6. 정규화 파라미터 $\lambda$ 증가(Try increasing regularization parameter $\lambda$)
  - 과적합 방지(Overfitting)
  
진단(Diagnostic)의 필요성
------

* 어떤 방법이 효과적인 성능 향상을 가져오는지 파악
* Diagnostic을 통해 직관적 판단과 성능 향상 방향 제시 가능.
* 초기 투자(시각화, 실험 등)가 필요하지만 장기적으로 시간과 자원을 절약.

&ensp;Diagnostics can take time to implement. But doing so can be a very good use of time.

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-3.png" width="600"></p>

* 낮은 결과가 반드시 좋은 예측함수를 의미한다고 볼 수는 없음

진단을 위한 주요 방법
------

* 학습/테스트 분할
  - 일반적으로 전체 데이터 중 70%는 학습, 30%는 테스트로 나눈다.
  <p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-4.png" width="600"></p>
  - Learn parameter w from training data: Minimizing training error $J(w)$
  <p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-5.png" width="600"></p>
* Logistic Regression(로지스틱 회귀)의 경우: Misclassification Rate
  - Misclassification Rate: The fraction of the data that hypothesis has mislabeled
  - 분류 문제에서는 비용 함수 대신 **0 / 1 오차** 사용 가능
  <p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-6.png" width="600"></p>
  - 전체 오차율
  <p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/1-7.png" width="600"></p>

최적 모델의 선택
======

&ensp;예측 모델을 설계할 때 **다항식 차수, 특징 선택, 정규화 파라미터** 등을 결정해야 한다. 이와 같은 결정은 예측 성능에 큰 영향을 미치므로, 모델을 선택하는 과정이 필요하다.

데이터 분할 방식
------

&ensp;모델 선택을 위해 전체 데이터를 3개로 나눈다.
* Training set(학습 데이터): 모델 학습용, 약 60%
* Cross validation set(검증 데이터): 모델 선택(차수 d결정 등)에 사용, 약 20%
* Test set(테스트 데이터): 최종 일반화 성능 측정에 사용, 약 20%

일반화(Generalization) 문제
------

&ensp;학습 데이터에 과하게 맞추면, **새로운 데이터에는 잘 작동하지 않을 수 있다.**
* 일반화 오차: 모델이 학습에 사용되지 않은 데이터에 대해 보이는 오차
  - 머신러닝 알고리즘의 파라미터가 training 데이터에 적합 시, 학습 데이터에 대해서 측정된 오차 값이 실제 일반화 오차(일반적 검증이나 Test 데이터에서 얻은 오차)에 비해 작음

모델 선택의 예
------

1. 10개의 서로 다른 차수의 다항식을 고려함 (1차 ~ 10차)
2. 각 모델마다 학습 데이터를 이용해 파라미터 w를 학습
3. 각 모델의 w를 이용해 Cross Validation 오차를 계산
4. Cross Validation 오차가 가장 작은 모델 선택
5. 최종적으로 선택된 모델을 test set에 적용하여 일반화 성능 측정

&ensp;Test 데이터로 직접 모델을 선택(d 결정)하면 낙관적인(optimistic) 결과가 나온다. 이는 Test set에 미리 노출되었기 때문에, 그에 맞춘 모델이 실제로는 일반화가 안 될 수 있음.

Bias와 Variance
======

&ensp;만약 우리가 개발한 머신러닝 알고리즘이 우리가 기대했던 것보다 성능이 좋지 않다면 다음 원인일 수 있다(데이터 피팅의 두가지 오차 원인).
1. High bias problem: 모델이 나타내는 예측 값과 실제 값과의 차이
  - 예측 값이 실제 예측하고자 한 정학한 값으로부터 얼마나 떨어져 있는가?
2. High variance problem: 주어진 데이터에 대해서 모델의 예측 값이 얼마나 변동성이 있는지 나타낸 값
  - 모델을 반복 구현한 값의 변동성이 주어진 예측 값에 비해서 얼마나 큰가?

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-1.png" width="600"></p>

* High bias(Underfitting): 모델이 너무 단순해서 데이터의 패턴을 못 잡음.
* High Variance(Overfitting): 모델이 너무 복잡해서 훈련 데이터에 과하게 맞춤.(**강의록에 글자 잘못 쓴것 같음**)

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-2.png" width="600"></p>

* 학습 오차는 꾸준히 감소하고 검증 오차는 U자 형태(적절한 복잡도에서 최소화됨)
* 학습 오차(Training Error)와 교차 검증 오차(Cross Validation Error)가 둘다 크면 **High Bias Problem**
* 학습 오차(Training Error)가 작고, 교차 검증 오차(Cross Validation Error)가 크면 **High Variance Problem**

&ensp;Bias 영역과 Variance 문제는 서로 다른 영역에서 다른 현상으로 나타날 수 있다.<br/>
<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-3.png" width="600"></p>

* High Bias: 여를 들어, 중심에서 멀리 퍼짐
* High Variance: 예를 들어, 중심엔 있지만 퍼저 있음

&ensp;즉, Bias가 작아지면 복잡도가 높아지고, Variance가 낮아지면 복잡도가 줄어든다. 따라서 좋은 모델은 Bias와 Variance의 균형이 필요하다.

MSE 오차 분해
------

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-4.png" width="600"></p>

* $\sigma^2$: 데이터 생성 과정에서의 불가피한 노이즈
* Variance: 학습 데이터에 따라 모델 예측이 얼마나 흔들리는지
* Bias$^2$: 모델의 평균 예측값이 정답에서 얼마나 떨어졌는지

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-5.png" width="600"></p>

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-6.png" width="600"></p>

$\lambda$ 최적 선택 방법
------

1. 여러 $\lambda$ 값들에 대해 모델 학습
2. 각 모델의 Cross Validation 오차 계산
3. 오차가 가장 낮은 $\lambda$ 선택
4. 이때의 파라미터로 Test 오차 계산하여 일반화 성능 확인

&ensp;즉, 0부터 증가시켜 나가며 정규화 파라미터 $\lambda$ 값을 선택하고 각각의 training 오차 값을 계산한 후, 최적인 파라미터를 획득해야 한다.<br/>
<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/3-7.png" width="600"></p>

학습 곡선
======

&ensp;학습 곡선은 학습 데이터의 개수를 늘려가며 관찰한 **오차의 변화**를 시각화한 그래프이다.
* x축: 학습 데이터 개수(m)
* y축: 오차

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/4-1.png" width="600"></p>

&ensp;두 가지 오차를 함께 비교한다.
* Training Error: 학습 데이터에 대하 예측한 결과와 실제 값의 평균 제곱 오차(MSE)
* Cross Validation Error: 검증 데이터에 대해 예측한 평균 제곱 오차

&ensp;학습 곡선을 그리는 이유는 다음과 같다.<br/>
<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/4-2.png" width="700"></p>

예시: 다항식 적합(Polynomial Fitting)
------

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/4-3.png" width="600"></p>
<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/4-4.png" width="600"></p>

* 데이터가 적을 때는 오차가 거의 없음
* 데이터가 많아질수록 학습 오차가 증가
* 검증 오차는 데이터가 늘어날수록 감소하다가 어는 순간 수렴

문제 유형에 따른 학습 곡선의 형태
------

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/4-5.png" width="700"></p>
<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/4-6.png" width="700"></p>

학습 알고리즘의 성능 향상
======

&ensp;자동차 가격을 예측하는 선형 회귀 모델을 만들었으나, 새로운 데이터에 대한 오차가 매우 크면, **학습 알고리즘의 성능 향상**이 필요하다. 다음은 성능 향상 전략들이다.<br/>

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/5-1.png" width="600"></p>

신경망 구조 선택 실용 팁
------

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/5-2.png" width="600"></p>

은닉층(Hidden layer) 선택 전략
------

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/5-3.png" width="600"></p>

모델 선택과 평가 방법
------

* 데이터를 Training, Cross Validation, Test 3분할
* 서로 다른 구조(은닉층 수, 유닛 수)에 대해 실험 후 최적 모델 선정
* 다양한 파라미터 설정 테스트가 중요

<p align="center"><img src="/assets/img/Machine Learning/9주차 머신러닝의 적용/5-4.png" width="500"></p>