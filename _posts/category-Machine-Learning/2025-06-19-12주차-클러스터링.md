---
title: "12주차 클러스터링"
excerpt: ""

wirter: sohee kim
categories:
  - Machine Learning
tags:
  - Machine Learning

toc: true
toc_sticky: true
use_math: true
  
date: 2025-06-19
last_modified_at: 2025-06-19
---

비지도학습
=======

&ensp;비지도 학습: 출력값(라벨)이 주어지지 않은 데이터에서 데이터의 패턴이나 구조를 찾는 방법이다. -> 유사한 데이터를 그룹핑하는 Clustering이 목적<br/>

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-1.png" width="600"></p>

&ensp;Clustering (군집화): 비지도학습의 대표 예시<br/>
&ensp;비지도학습의 대표적인 기법은 Clustering 즉 비슷한 데이터를 묶는 것이다.<br/>
&ensp;예: 고객 행동 분석<br/>
* 온라인 쇼핑몰에서 고객의 웹사이트 방문 경로를 기록함.
* 이를 바탕으로 고객들이 자주 이동하는 경로, 많이 방문하는 페이지를 분석해볼 수 있어.
* 이런 분석은 라벨 없이도 가능해. 고객이 어떤 경로를 가는지는 알지만, 그 경로에 "이건 좋은 행동" 같은 라벨은 없잖아?
* 대신, 비슷한 행동을 보이는 고객끼리 **그룹(Cluster)**으로 묶을 수 있어.

&ensp;Clustering이 쓰이는 실제 분야<br/>
&ensp;다음은 Clustering이 사용되는 다양한 예시이다.:<br/>
1. 시장 조사 (Market Research)
* 소비자 행동 데이터를 기반으로 유사한 소비패턴을 가진 고객들을 묶음.
* 예: 자주 세일 제품을 사는 고객 vs 프리미엄 상품만 사는 고객
2. 이상 탐지 (Anomaly Detection)
* 정상적인 데이터 패턴에서 벗어난 데이터를 찾는 데 사용됨.
* 예: 건강 데이터에서 콜레스테롤이 극단적으로 높은 사람 → 잠재적 질병
3. 소셜 네트워크 분석
* SNS 활동 패턴을 기반으로 친한 친구 그룹을 찾아냄.
* 예: 서로 댓글을 자주 다는 사람들 → 같은 커뮤니티
4. 문서 분류 (Topic Clustering)
* 검색된 문서를 주제별로 자동 분류.
* 예: "머신러닝", "축구", "요리" 주제로 나눠 보여주기
5. 이미지 분할 (Image Segmentation)
* 이미지 안의 **각 부분을 객체(예: 나무, 건물)**로 구분.
* 예: 위성 사진을 보고 건물, 도로, 나무로 구분

&ensp;지도학습 vs 비지도학습<br/>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-2.png" width="600"></p>

K-Means 알고리즘
======

&ensp;K-Means 알고리즘<br/>
* 반복적인 알고리즘을 통하여 처음 주어진 Clustering 결과로부터 성능을 향상
* 반복 알고리즘을 계속 진행하여 최종적으로 원하는 결과를 얻는 데 활용

&ensp;목적<br/>
* 데이터를 비슷한 성질끼리 묶어서 그룹화(Clustering) 하는 것이 목적이다.
* 이 그룹의 중심을 Centroid(중심점)라고 한다.

&ensp;K-Means의 기본 아이디어: 두 가지 단계를 반복<br/>
1. Cluster Assignment (할당)

&ensp;각 데이터를 가까운 중심점(Centroid)에게 소속시켜 준다.<br/>

2. Centroid Movement (이동)

&ensp;각 클러스터에 속한 데이터를 보고, 그 평균으로 중심점을 새로 계산한다.<br/>

&ensp;이 두 과정을 계속 반복하다 보면, 더 이상 중심점이 움직이지 않을 때가 오고, 그때 Clustering이 완성된다.<br/>

&ensp;K-Means 알고리즘 과정 (2개 클러스터 예시)<br/>
&ensp;Step 0: 중심점 초기화<br/>
* 러스터 수가 2개라고 가정하면, 2개의 랜덤한 중심점(μ₁, μ₂) 를 잡는다.

&ensp;Step 1A: 할당 단계<br/>
* 각 데이터를 보고, 어느 중심점이 더 가까운지 계산한다.
* 가까운 쪽 클러스터에 색칠해서 소속시켜준다. (예: 초록/빨강으로)

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-3.png" width="600"></p>

&ensp;Step 1B: 중심점 이동 단계<br/>
* 방금 소속된 데이터들만 모아서 평균 위치를 계산한다.
* 중심점을 그 평균 위치로 이동시킨다.

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-4.png" width="600"></p>

&ensp;그리고 나서?<br/>
* 다시 Step 1A로 돌아가서 새 중심점 기준으로 다시 할당하고,
* 또 평균을 구해 중심점을 다시 이동하고...
* 이 과정을 반복하다가 중심점이 더 이상 움직이지 않으면 종료!

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-5.png" width="600"></p>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-6.png" width="600"></p>

&ensp;수학적으로 정리하면?<br/>
* 입력:
    - K: 우리가 몇 개의 클러스터로 나눌지 정함
    - 데이터: 각 샘플은 n차원 벡터
* 알고리즘:
1. K개의 중심점(μ₁ ~ μ_K) 을 랜덤하게 초기화
2. 아래 두 과정 반복
    - (A) 각 데이터 x⁽ⁱ⁾에 대해 가장 가까운 중심점 μ_k 찾아서, 그 클러스터에 소속 (index 값 c⁽ⁱ⁾)
    - (B) 각 클러스터에 대해 그 안에 있는 점들의 평균으로 중심점 업데이트

&ensp;주의할 점: 클러스터에 데이터가 하나도 없으면?<br/>
* 클러스터에 아무도 속하지 않으면 그 클러스터를 없애거나, 새로 중심점을 랜덤으로 초기화할 수 있다.

&ensp;T-Shirt Sizing 예시로 이해해보자!<br/>
* 어떤 회사가 티셔츠를 S, M, L 세 사이즈로만 만들기로 했다면?
* 고객의 체형 데이터를 클러스터링해서 3개의 그룹(S, M, L) 으로 나누는 것이 목적이다.
* 이 경우 K는 3으로 고정, 우리가 꼭 3개의 클러스터를 얻어야 하는 상황!

&ensp;정리<br/>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-7.png" width="600"></p>

* K-Means는 비지도 학습에서 가장 많이 쓰이는 클러스터링 알고리즘
* 데이터를 일정 개수의 그룹으로 나누고 싶을 때 유용
* 중심점을 정하고, 가까운 데이터끼리 묶고, 그걸로 다시 중심을 이동시키는 걸 반복하는 방식

K-Means 알고리즘의 최적화 목적 함수
=======

&ensp;핵심 용어<br/>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-8.png" width="600"></p>

&ensp;K-Means의 목적 함수 ⭐<br/>
&ensp;각 데이터와 그 데이터가 속한 클러스터 중심과의 거리 제곱의 평균을 최소화<br/>

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-9.png" width="600"></p>

* J: 목적 함수 (cost function or distortion)
* 의미: 각 데이터가 자기 클러스터 중심과 가까워지도록 만들기

&ensp;K-Means 알고리즘 동작 순서 ⭐<br/>
&ensp;초기화<br/>
* 클러스터 개수 K를 정하고, K개의 중심(μₖ)을 무작위로 설정

&ensp;[Step A] Cluster Assignment ⭐<br/>
* 각 데이터 x⁽ⁱ⁾를 가장 가까운 클러스터에 할당(= c⁽ⁱ⁾를 결정)

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-10.png" width="600"></p>

&ensp;[Step B] Centroid Movement ⭐<br/>
* 각 클러스터 중심 μₖ를 업데이트
* 방법: 그 클러스터에 속한 모든 데이터의 평균

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-11.png" width="600"></p>

&ensp;반복: A → B → A → B … 반복하며 J를 최소화할 때까지<br/>

&ensp;요약<br/>
&ensp;K-Means는 클러스터 중심과의 거리 제곱 평균을 최소화하면서 비슷한 데이터를 묶는 비지도 학습 알고리즘이다.<br/>

랜덤 초기화와 K-Means 알고리즘
======

&ensp;1. K-Means 알고리즘 시작: 클러스터 중심(centroids) 초기화<br/>
* K-Means 알고리즘을 시작할 때 가장 먼저 하는 일은 K개의 클러스터 중심(μ₁, μ₂, .., μₖ) 을 무작위로 선택하는 것!
* 이 중심점들은 전체 데이터 중 K개를 랜덤하게 뽑아 결정한다.
* 예: 데이터가 14개 → 클러스터 수 K는 보통 2~3개로 설정 가능 (K < m)

&ensp;랜덤 초기화가 Clustering 결과에 미치는 영향<br/>
* 좋은 초기화 예시:

<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-12.png" width="600"></p>

* 서로 다른 그룹의 데이터에서 중심점을 잘 뽑음
* 이후 반복 학습을 통해 우리가 기대한 이상적인 클러스터링 결과에 도달할 가능성 높음

* 나쁜 초기화 예시:
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-13.png" width="600"></p>

* 비슷한 그룹의 데이터 2개를 중심으로 선택 → 편향된 클러스터링 결과
* 실제로는 다른 그룹인데 같은 그룹으로 판단해버릴 수도 있음

&ensp;Global Optimum vs Local Optimum<br/>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-14.png" width="600"></p>

&ensp;어떻게 하면 Global Optimum에 도달할 수 있을까?<br/>
&ensp;핵심 전략: K-Means를 여러 번 반복해서 제일 좋은 결과를 선택하자!<br/>
&ensp;실행 순서 예시<br/>
1. K-Means 알고리즘을 100번 실행 (매번 초기화 다르게)
2. 각 실행마다 비용 함수(J)를 계산
3. 비용 함수 값이 가장 낮은 결과 선택

&ensp;비용 함수 = 클러스터 중심과 각 점 사이의 거리 총합 -> 이 값이 낮을수록 군집화가 잘 되었다는 뜻<br/>

&ensp;클러스터 수에 따른 전략<br/>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-15.png" width="600"></p>

&ensp;정리<br/>
* K-Means는 초기화 위치에 따라 결과가 달라짐
* Global Optimum을 얻으려면 여러 번 초기화 후 최적 결과 선택
* 클러스터 개수가 작을 때 랜덤 초기화 반복이 더 효과적

Cluster 수의 결정
=====

&ensp;1. 왜 Cluster 수를 정해야 할까?<br/>
&ensp;K-means알고리즘을 사용하묜 데이터를 여러 그룹(Cluster)으로 나누게 된다. 근데 그룹을 몇 개로 나눌까하는 질문은 명확한 정답이 없다. 예를 들어 같은 데이터를 2개나 4개의 Cluster로 나눌 수도 있는데 각각 다르게 보이지만 둘 다 괜찮아 보인다.<br/>
&ensp;결론: K(cluster 수)는 사람이 정해야 하고 정확한 정답은 없다.<br/>

&ensp;2. Cluster 수를 정하는 대표적인 방법<br/>
&ensp;(1) Elbow Method (엘보우 기법)<br/>
* K 값을 1부터 차례대로 늘려가며 K-means 알고리즘을 실행하고, 그때마다 비용 함수 (Cost Function) 값을 계산
* 이 값을 그래프로 그리면 대체로 비용이 급격히 줄어들다가, 어느 순간부터 줄어드는 폭이 작아져요.
* 이 꺾이는 지점이 마치 **팔꿈치(Elbow)**처럼 보인다고 해서, 이 지점을 적절한 K 값으로 선택해요.

&ensp; 예시:<br/>
&ensp;K = 1, 2, 3 … 증가시키면서 Cost 계산 -> K = 3에서 꺾였으면, K = 3이 적절한 Cluster 수!<br/>
&ensp;Elbow Method의 한계<br/>
* 그래프가 부드럽게 감소할 경우엔 꺾이는 지점이 명확하지 않아 어렵다.
* 그러므로 이 방법도 완벽한 기준은 아님.

&ensp;3. 목적 기반 선택 (Purpose-based choosing)<br/>
&ensp;어떤 목적을 위해 Clustering을 하느냐에 따라 Cluster 수를 미리 정하는 경우도 많다.<br/>

&ensp;예시: 티셔츠 사이즈 분류<br/>
* 목적: 키와 몸무게 데이터를 이용해 사람들을 티셔츠 사이즈로 나누기
* Cluster 수 = 사이즈 종류
    - 비용을 줄이고 싶으면: S, M, L → Cluster 3개
    - 만족도를 높이고 싶으면: XS, S, M, L, XL → Cluster 5개

&ensp;즉, **"판매 전략"**에 따라 K를 결정하는 것이 목적 기반 선택이다.<br/>

&ensp;4. 정리 (한눈에 보기)<br/>
<p align="center"><img src="/assets/img/Machine Learning/12. 클러스터링/12-16.png" width="600"></p>