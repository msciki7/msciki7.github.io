---
title: "3주차 다변수 선형 회귀"
excerpt: ""

wirter: sohee kim
categories:
  - Machine Learning
tags:
  - Machine Learning

toc: true
toc_sticky: true
use_math: true
  
date: 2025-05-27
last_modified_at: 2025-05-27
---


1\. 다변수 선형 회귀
======
* 목표: 여러 개의 입력 특정값(features)을 이용해 자동차 가격(Price) 예측
* 예측 입력 변수:
    - $x_1$ : 엔진 출력 (Engine Power)
    - $x_2$ : 최대 회전속도 (Peak RPM)
    - $x_3$ : 자동차 도어 개수(Number of Doors)
* 예측 함수(Hypothesis Function): $h(x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3 = \mathbf{w}^T \mathbf{x}$  

2\. 수학적 표현
======

1. 예측 변수 (Hypothesis)
* 일반화된 벡터 표현 : $h_w(x) = w^Tx$
* $w= [w_0, w_1, ..., w_n]^T$ (n+1개의 파라미터)
* $x = [1, x_1,..., x_n]^T$ (Bias를 위해 $x_0 = 1$ 포함) 

2. 비용함수(cost Function)
* 평균 제곱 오차: $J(\mathbf{w}) = \frac{1}{2m} \sum_{i=1}^{m} \left( h_{\mathbf{w}}(x^{(i)}) - y^{(i)} \right)^2$ 

3. 파라미터 최적화 방법
&ensp; Gradient Descent (경사 하강법)<br/>
* 모든 파라미터 $w_j$ 에 대해 반복적으로 다음과 같이 업데이트: $w_j := w_j - \alpha \cdot \frac{\partial J(\mathbf{w})}{\partial w_j}$

* α: 학습률 (learning rate)
* 파라미터 벡터화 표현: $\mathbf{w} := \mathbf{w} - \alpha \cdot \nabla J(\mathbf{w})$ 

&ensp;파생된 편미분 식: $\frac{\partial J(\mathbf{w})}{\partial w_j} = \frac{1}{m} \sum_{i=1}^{m} \left( h_{\mathbf{w}}(x^{(i)}) - y^{(i)} \right) \cdot x_j^{(i)}$<br/>

&ensp;파라미터 벡터화: 비용함수가 최솟값이 될 때까지 반복 

3\. 특정 값 스케일링
======

1. 왜 스케일링이 필요한가?
*  여러 개의 특징값(features)이 서로 **값의 범위(Range)**가 다를 경우,
    - 예: 엔진 파워 x1 = (100 ~ 250), Peak RPM(4000 ~ 8000)
* 이런 비균형한 스케일은 비용 함수 J(w)의 등고선이 찌그러지게(skewed contours) 만들어 경사하강법이 최솟값으로 수렴하는 속도를 느리게 하거나 잘못된 방향으로 진동하며 수렴을 방해한다.

2. 해결책: 특징 값 스케일링 방법
* 방법 1: 최댓값 기준 정규화 (Min-Max Scaling)
    - 각 feature를 해당 feature의 최댓값으로 나눔: $x_j' = \frac{x_j}{\max(x_j)}$
    - 예 :
        + 엔젠파워: $x'_1 = x_1/250$
        + RPM: $x'_2 = x_2/8000$
    - 결과적으로 각 feature의 최대값이 1이 되며 값의 범위를 비슷하게 맞출 수 있다.

* 방법 2: 평균 정규화 (Mean Normalization)
* 수식: $x_j' = s_j (x_j - \mu_j)$ 
* $μ_j$ : feature j의 평균
* $s_j$ : 동적 범위(Dynamic Range) 또는 표준편차(Standard Deviation)
* 엔진파워: $x_1' = \frac{150}{x_1 - 175}$
* RPM: $x_2' = \frac{x_2 - 6000}{4000}$ 

3. 스케일링 결과의 영향
* 학습 전에 스케일링을 적용하면 다음과 같은 효과:
    - 등고선이 원형에 가까워짐
    - 경사하강법의 수렴 속도 증가
    - 더 안정적인 학습 가능
* 스케일링은 선형 회귀뿐만 아니라 로지스틱 회귀 등 다른 경사하강법 기반 알고리즘에도 효과적임

&ensp;올바른 vs 잘못된 스케일 예시
<p align="center"><img src="/assets/img/Machine Learning/3. 다변수 선형 회귀/3-1.png" width="600"></p>

김소희바보