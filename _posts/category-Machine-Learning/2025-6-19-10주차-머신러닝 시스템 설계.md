---
title: "10주차 머신러닝 시스템 설계"
excerpt: ""

wirter: sohee kim
categories:
  - Machine Learning
tags:
  - Machine Learning

toc: true
toc_sticky: true
use_math: true
  
date: 2025-06-19
last_modified_at: 2025-06-19
---

머신러닝 시스템 설계 시 고려사항
======

&ensp;예시: 진단 알고리즘의 평가 문제<br/>
* 어떤 질병에 대해 **양성 환자 비율이 1%**밖에 안 되는 상황.
* 두 연구원의 실험:
    - A 연구원: 머신러닝 알고리즘으로 진단 → 98% 정확도
    - B 연구원: 그냥 모두 음성이라고 예측함 → 99% 정확도
* 이 경우 단순히 정확도(accuracy)로는 모델의 성능을 제대로 판단할 수 없음.
* 이런 경우를 불균형 데이터 문제라고 부름. 이 문제에서는 정확도 외의 평가 기준이 필요함

&ensp;🧠 머신러닝 시스템 성능 향상을 위한 3가지 방법<br/>
1. 많은 데이터를 수집하라
2. 좋은(정교한) 특징 값을 정의하라
3. 문제에 특화된 특징 값을 찾아라

&ensp;📩 예시: 스팸 이메일 분류기 (Spam Classifier)<br/>
&ensp;💡 목표<br/>
* 이메일이 스팸인지 아닌지를 판단하는 머신러닝 모델 만들기
* 이진 분류기(Binary Classifier)사용 -> 결과는 1(스팸) 또는 0(정상)

&ensp;🧾 데이터 표현 방식<br/>
* 입력 (x): 이메일의 특징을 담은 벡터 (단어의 존재 여부 등)
* 출력 (y): 이메일이 스팸인지 아닌지 (0 또는 1)

&ensp;📌 특징 벡터 예시
* "buy", "deal", "discount" 같은 단어 100개를 선정
* 각 이메일에 대해 해당 단어가 포함되었는지 확인
* 포함되면 1, 아니면 0
* 결과적으로 100차원 벡터 x = \[0, 1, 1, 0, ..., 0\]

&ensp;🧲 데이터 수집 방법<br/>
&ensp;좋은 데이터가 많아야 모델도 잘 배움<br/>
* Honeypot Project 사용:
    - 가짜 이메일 주소를 인터넷에 노출시켜 스팸 메일을 유도
    - 그렇게 받은 스팸 메일들을 학습에 사용

&ensp;🔍 좋은 특징(feature) 찾기<br/>
* 본문의 단어들 외에도 다음과 같은 정보도 사용할 수 있음:
    - 이메일의 라우팅 정보: 어디서 보냈는지, 경로는 어땠는지
    - 이메일 헤더 정보: 서버 주소 등
    - 스펠링 조작 탐지: spam 대신 sp4m, de@l, b0nus 같은 변형 감지
    - 단어 유사성 처리: deal과 dealer, discount 와 discounts 등

&ensp;🛠️ 문제 정의에 특화된 방법<br/>
* 영어 단어의 대소문자 구분, 복수형 등 전처리 고민
* 정교한 알고리즘 도입으로 스팸 감지를 더욱 향상시킬 수 있음

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-1.png" width="600"></p>

&ensp;💡 정리<br/>
&ensp;단순히 정확도만 높다고 좋은 모델이 아니다. 좋은 머신러닝 시스템을 만들려면<br/>
* 좋은 데이터 확보
* 유용한 특징 정의
* 문제에 특화된 아이디어 적용

&ensp;이 세 가지가 모두 필요하다.<br/>

오차 분석 방법 요약
======

&ensp;오차 분석(Error Analysis): 오차 분석이란 모델이 무엇을 잘못 분류했는지를 살펴보고 이를 바탕으로 정확도를 올릴 방법을 찾는 과정이다. <br/>

&ensp;🧭 1단계: 머신러닝 시작할 땐 간단한 알고리즘부터!<br/>
* 처음에는 빠르게 구현 가능한 단순한 알고리즘으로 시작한다.
* 그 결과를 검증용 데이터셋(Cross Validation Set) 으로 평가한다.
* 성능이 기대보다 낮으면 왜 그런지 분석한다.:
    - Bias(편향) 문제인가? → 너무 단순해서 오답을 자주 내는 모델
    - Variance(분산) 문제인가? → 너무 복잡해서 데이터에 과적합된 모델

&ensp;🔍 2단계: 오차 분석 시작<br/>
* 모델이 어떤 데이터를 자주 틀리는지 손으로 직접 살펴본다.
* 검증용 데이터에서 오답이 난 항목들을 카테고리별로 나눠요.
* 패턴이 있는지 관찰해요: 예를 들어 어떤 단어가 자주 나오면 오답이 많다든지!

&ensp;🧪 예시: 스팸 이메일 분류기<br/>
&ensp;📌 상황:<br/>
* 검증용 데이터 500개
* 그중 100개를 잘못 분류함

&ensp;그 100개의 오답을 분류해 보니:<br/>

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-2.png" width="600"></p>

&ensp;➡️ 비밀번호 훔치는 이메일이 제일 문제! → 이 부분을 먼저 개선해야 해요.<br/>

&ensp;🧠 3단계: 왜 오답이 났는지 살펴보기<br/>
&ensp;📌 비밀번호 훔치는 53개 중:<br/>
* 이상한 철자 (예: m0rtgafe) → 5개
* 이메일 경로 특이 → 16개
* 이상한 문장 부호 (!!! 등) → 32개

&ensp;➡️ 맞춤법이 이상한 경우가 가장 많아요 → 여기를 집중 공략!<br/>

&ensp;🧮 4단계: 수치 평가(정량적 평가)를 함께 사용하자<br/>
* 평가 기준을 숫자 하나로 정하면 개선 효과를 쉽게 볼 수 있어요!
* 예: 정확도(Accuracy), 오차율(Error Rate)

&ensp;✔ 예시:<br/>

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-3.png" width="600"></p>

&ensp;→ Stemming을 사용하니 오차가 줄었다.<br/>
&ensp;📌 Stemming: 같은 어근의 단어들을 하나로 묶어주는 작업<br/>
* 예: discount, discounts, discounted, discounting → 모두 "discount"로 처리

&ensp;❌ 하지만 조심할 점도 있다.<br/>
* 어원이 비슷해도 뜻이 다른 단어: 
    - universe vs university → 잘못 묶이면 오답 증가할 수 있다.
* 대소문자 구분도 마찬가지:
    - Mom vs mom
    - 대소문자를 구분했더니 오차가 3.0% → 3.2% 증가 -> 구분 안 하는 게 낮다.

&ensp;📌 마지막 요약 노트<br/>
1. 간단한 알고리즘부터 시작한다.
2. 검증 데이터로 평가하고 오답을 분류한다.
3. 어떤 유형의 오답이 많은지 파악한다.
4. 수치 평가로 효과를 검증한다.
5. 잘못된 부분을 고치기 위한 전략을 세우자

불균형 데이터에서의 오차 평가 방법
======

&ensp;🔍 불균형 데이터(Skewed Class)란?<br/>
&ensp;전체 데이터에서 특정 클래스(부류)의 비율이 매우 적은 경우를 말한다. 그래서 모델이 다수 클래스만 예측해도 정확도가 높게 나온다.(=불합리적 결과)<br/>
&ensp;예시:<br/>
* 전체 환자 100명 중 암 환자 1명
* 즉, 암 환자(1): 1명, 정상 환자(0): 99명 → 극단적으로 불균형한 데이터!

&ensp;🧪 예제: 암 환자 분류기<br/>
* 모델은 암이면 1, 아니면 0을 예측해요.
* 그런데 암 환자가 0.5%밖에 안 되면?

&ensp;📉 항상 0(정상)만 예측하는 단순한 모델도 99.5% 정확도를 보인다. 하지만 이건 암 환자를 전혀 못 잡아낸다. 정확도(Accuracy)는 높지만 실제로는 쓸모없는 모델이 될 수 있다.<br/>

&ensp;더 정확한 평가 척도: Confusion Matrix (혼동 행렬)<br/>
&ensp;우리는 다른 척도들로 모델 성능을 평가해야 한다. 바로 아래 4가지가 핵심이다.<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-4.png" width="600"></p>

* TP: 진짜 암 환자를 암이라고 맞춤
* FN: 암 환자를 정상으로 놓침
* FP: 정상인데 암으로 잘못 판단
* TN: 정상 환자를 정상이라고 맞춤

&ensp;📌 중요한 척도들<br/>
&ensp;3. 🎯 Precision (정밀도)<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-12.png" width="600"></p>

&ensp;➡️ 잘못 예측한 정상인을 암이라고 한 경우(FP) 가 많으면 precision이 떨어짐<br/>

&ensp;4. 🧲 Recall (재현율)<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-11.png" width="600"></p>

&ensp;➡️ 암 환자를 놓치는 경우(FN) 가 많으면 recall이 낮아짐<br/>

&ensp;🎯 Precision vs Recall 차이<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-8.png" width="600"></p>


&ensp;⚠️ 단순 정확도만 보면 생기는 문제<br/>
&ensp;예를 들어, 아래 모델을 보면<br/>
* 실제: 암 환자 1명, 정상 99명
* 모델: 무조건 다 0으로 예측

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-9.png" width="600"></p>

&ensp;-> 정확도는 높지만 recall은 0 → 무용지물!<br/>

&ensp; Good classifier 조건<br/>
&ensp;좋은 분류기란? ->  Precision과 Recall이 모두 높은 분류기<br/>
* Precision, Recall은 0부터 1 사이의 값을 가짐
* 이 값이 1에 가까울수록 성능이 좋은 모델 -> 즉, 놓치지도 않고, 헛짚지도 않는 분류기

&ensp;이진 분류의 전체 구조<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-5.png" width="600"></p>

&ensp;분류기(classifer)가 positive으로 예측한 것, 음성으로 예측한 것으로 나누고 각각  TP, FP, TN, FN을 통해 다양한 평가 척도 정의 가능<br/>

&ensp;기본적인 평가 측정 기준<br/>

* Accuracy (정확도):

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-10.png" width="600"></p>

* Error Rate (오차율):

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-13.png" width="600"></p>

&ensp;ERR = 1 - ACC<br/>

* Precision(정확도)

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-6.png" width="600"></p>

* Recall(재현율)

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-7.png" width="600"></p>

&ensp;또 다른 측정 기준<br/>

* Specificity (특이도)

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-14.png" width="600"></p>

* FPR (False Positive Rate)

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-15.png" width="600"></p>

&ensp;📝 결론<br/>
* 불균형 데이터에서는 단순한 정확도로는 모델을 평가할 수 없다.
* Precision과 Recall을 꼭 함께 보고 판단해야 한다.
* 이 둘을 적절히 조절해서 좋은 Clasifier를 만들어야 한다. 

정밀도와 재현율의 Trade-off
=======

&ensp;복습: 정밀도(Precision)와 재현율(Recall)은 왜 중요할까?<br/>
* 불균형 데이터에서는 정확도(accuracy)만 보면 잘못된 결론에 도달할 수 있어 대신 정밀도와 재현율을 평가 척도로 사용해야 한다.

&ensp;정밀도 vs 재현율, 둘 중 하나만 높일 수 있다면?<br/>
&ensp;이 두개는 보통 서로 반비례하다. 하나를 높이면 다른 하나가 내려간다.<br/>

&ensp;1. 예측 기준(threshold)을 바꾸면 무슨 일이 일어날까?<br/>
* 로지스틱 회귀 모델은 0과 1 사이의 확률값을 출력한다. 
* 임의로 정한 기준값(threshold) 이상이면 1, 아니면 0으로 분류한다.

&ensp;예시<br/>
* 기준 값이 0.5: 확률이 0.5 넘으면 암(1), 아니면 정상(0)
* 그런데 기준값을 0.7으로 높이면?
    - 진짜 확신할 때만 암이라 예측
    - 암 환자 대부분은 0.7까지 못 올라오니까 암을 잘 못 찾게 됨 -> Recall↓, Precision↑

&ensp;반대로 기준값을 0.3으로 낮추면?<br/>
* 웬만하면 암이라 예측 -> 암 환자 잘 못 놓침 (Recall↑)
* 근데 암 아닌 사람도 암이라고 하니까 Precision↓

&ensp;2. 기준값(threshold)에 따른 변화 요약<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-16.png" width="600"></p>

* Precision ↑ = 예측한 사람 중 진짜 환자 많음
* Recall ↑ = 진짜 환자 중 예측에 성공한 비율

&ensp;3. 그럼 둘 다 중요하면? 어떻게 비교할까?<br/>
&ensp;두 값이 서로 줄다리기하고 있을 때, 균형 있는 평가가 필요하다.<br/>

&ensp;4. F1 Score (F-점수)란?<br/>
* 정밀도와 재현율의 균형을 보는 수치
* 둘 중 하나라도 낮으면 전체 점수가 낮아진다. 
* 수식:
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-17.png" width="600"></p>

* 이걸 조화 평균(harmonic mean)이라고 한다.

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-18.png" width="600"></p>

&ensp;결론 요약<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-19.png" width="600"></p>

학습 데이터 수
=======

&ensp;1. 예시로 이해하는 학습 데이터의 중요성<br/>

&ensp; 예시 1: 헷갈리는 단어 구별하기<br/>
* 단어 예시: to, two, too
* 문장: For breakfast, I ate __ eggs.
* 정답: two(문맥상 두 개의 계란이니까)

&ensp; 연구 프로젝트 (2001년)<br/>
* 위와 같은 문제에서, 데이터의 개수와 정확도의 관계를 그래프로 표현함.
* X축: 데이터 수(단위는 백만 = 1M = 100만)
* Y축: 정확도(0.7 ~ 1 사이)

<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-20.png" width="600"></p>

&ensp;결과 해석<br/>
* 데이터 수가 많아질수록 정확도도 상승!
* 성능이 좋다고 알려진 알고리즘조차도 데이터가 부족하면 성능이 낮을 수 있음
* 중요한 결론:
    - 좋은 알고리즘보다 많은 데이터가 더 중요할 수 있다.

&ensp;2. 알고리즘보다 중요한 건 데이터 수?<br/>
* 예를 들어 파란색 실선 알고리즘이 더 성능이 좋은 것으로 알려졌지만
* 많은 데이터를 가진 보통의 알고리즘이 적은 데이터를 가진 고급 알고리즘보다 성능이 더 좋았다.

&ensp;즉 좋은 알고리즘 < 더 많은 데이터 라는 것이 핵심 결론

&ensp;3. 이 말이 항상 맞는 건 아니다!<br/>

&ensp;조건1: 문제에 충분한 정보가 있는 경우<br/>
* 예시: 나는 아침에 두 개의 계란을 먹었다.
* -> 누구든지 정답(two)을 쉽게 맞힐 수 있다.
* 즉 특징이 충분하고 정보가 풍부한 문제

&ensp;조건 2: 정보가 부족한 문제<br/>
* 예시: 자동차 가격을 예측하는데, 오직 "엔진 파워"만 가지고 예측
* → 너무 많은 영향을 주는 요소가 빠져 있음 (브랜드, 연식, 연비 등)
* → 사람조차도 예측이 어려움

&ensp;→ 이런 경우에는 데이터를 늘려도 정확도는 그다지 오르지 않음.<br/>

&ensp;4. Bias와 Variance 관점에서 보기<br/>
* Bias(편향): 모델이 너무 단순해서 문제의 복잡성을 잘 표현 못함
* Variance(분산): 학습 데이터에 너무 민감하게 반응함 (과적합 가능)

&ensp;조건<br/>
* 특징 벡터가 충분히 있고(n+1 차원)
* 복잡한 예측 모델 사용(예: 딥러닝, 여러 레이어)
* 즉 Low Bias가 보장된 상태

&ensp;→ 남은 문제는 Variance, 즉 오버피팅만 줄이면 됨.<br/>
&ensp;이때 필요한 것은? -> 데이터를 더 많이 확보해서 분산(Variance)을 줄이는 것<br/>

&ensp;5. 결론 정리<br/>
<p align="center"><img src="/assets/img/Machine Learning/10. 머신러닝 시스템 설계/10-21.png" width="600"></p>

&ensp;이 3가지 조건이 모두 맞는다면 **학습 오차(Training Error)와 테스트 오차(Test Error)**를 모두 낮출 수 있고 매우 높은 성능의 머신러닝 알고리즘을 만들 수 있다.<br/>

&ensp;마지막 정리<br/>
* 데이터 수가 많을수록 테스트 오차는 낮아질 가능성이 크다
* 하지만 그 전제는:
    - 좋은 특징 값
    - 적적히 복잡한 모델
    - 문제 자체가 명확할 것(사람도 맞출 수 있을 정도)
* 이 세 가지가 갖춰질 때 데이터 수 증가 -> 성능 향상이 이루어진다.

