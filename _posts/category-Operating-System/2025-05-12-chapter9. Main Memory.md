---
title: "Chapter 9. Main Memory"
excerpt: "논리주소와 물리주소의 차이점과 주소를 반환할 때 MMU의 역할을 설명한다. TLB가 포함된 페이징 시스템에서 논리 주소를 물리주소롤 변환한다."

wirter: sohee kim
categories:
  - Operating System
tags:
  - operating system

toc: true
use_math: true
toc_sticky: true
  
date: 2025-05-12
last_modified_at: 2025-05-12
---

1\. Background
======

&ensp;프로그램이 실행되기 위해서는 디스크에서 RAM로 로딩되어야 하고 OS는 이를 프로세스의 메모리 공간에 배치해야 실행 가능한다. CPU는 레지스터와 메인 메모리에만 직접 접근 가능하다. 디스크나 SSD는 파일 시스템을 통해 간접적으로만 접근한다. 메인 메모리는 현대 컴퓨터 시스템의 운영에 중심적인 역할을 한다. 메모리는 각각 주소가 할당된 일련의 바이트들로 구성된다. CPU는 PC가 지시하는 대로 메모리부터 다음 수행할 명령어를 가져오는데 그 명령어는 필요한 경우 추가적인 데이터를 더 가져올 수 있으며 반대로 데이터를 메모리로 내보낼 수도 있다.  이진 주소 + 요청만 보일 뿐 명령의 의미는 모른다. 캐시는 메모리와 레지스터 사이의 중간 단계 저장장치이다. 자주 사용하는 데이터를 빠르게 제공하여 CPU stall을 줄여준다. 잘못된 메모리 접근은 시스템 오류나 보안문제로 이어진다. 따라서 OS는 각 프로세스의 메모리 공간을 분리하고 보호한다. <br/>

&ensp;1_기본 하드웨어(Basic Hardware)<br/>

&ensp;Base and Limit Registers<br/>

&ensp;각 프로세스는 자신만의 메모리 공간을 가져야 한다. 이를 위해서 OS는 Base 레지스터와 Limit 레지스터 한 쌍을 사용한다. <br/>

* Base : 프로세스의 시작 주소를 저장
* Limit : 프로세스가 사용할 수 있는 주소 범위 크기를 저장
* -> 유효 주소 범위 = [Base, Base+Limit)

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-1.png" width="600"></p>

&ensp;어떤 프로세스의 Base = 300040, Limit = 120900 이면 이 프로세스는 메모리 주소 300040 ~ 420939 까지만 접근 가능하다. CPU는 매번 메모리 접근 전에 이 범위 내인지 확인한다. <br/>

&ensp;Hardware Address Protection(주소 보호 동작 흐름)<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-2.png" width="600"></p>

&ensp;CPU가 메모리 접근 시 주소를 다음 조건으로 검사함 : <br/>

1. address >= base ?
2. address < base + limit ?
&ensp;-> 둘 다 만족하면 접근 허용, 하나라도 실패하면 OS에 트랩(trap)<br/>

&ensp;장점<br/>
&ensp;사용자 프로그램이 자신이 할당받은 메모리 외부를 침범하지 못하도록 보호한다. 다른 프로세스 메모리나 OS 영역에 대한 불법 접근을 방지한다. <br/>

&ensp;한계<br/>
&ensp;프로세스마다 고정된 연속된 메모리 공간을 사용해야 하므로 메모리 단편화 발생 가능하다. 현대 시스템은 주로 가상 메모리(Paging)방식으로 전환했다.<br/>

&ensp;2_Address Binding<br/>

&ensp;주소 바인딩(address binding)은 프로그램 실행과정에서 기호(symbolic) 주소 -> 실제(physical) 주소로 매핑하는 과정이다. <br/>

1. 프로그램은 실행 전에 메모리에 로드됨
* 디스크에 저장된 프로그램들은 input queue에 대기함
* 프로그램은 메모리에 올라가야 실행 가능

2. 바인딩이 필요한 이유
&ensp;모든 사용자 프로세스를 항상 물리 주소 0에서 실행하는 것은 불가능하고 비효율적이다. 그래서 주소를 유연하게 매핑해줄 필요가 있다.<br/>

3. 주소 표현 단계별 흐름
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-3.png" width="600"></p>

4. 바인딩 역할
* 바인딩은 주소 공간 간의 변환(mapping)을 의미한다.
* 기호 주소 -> 상대 주소
* 상대 주소 -> 절대 주소

5. 주소 바인딩의 세 가지 시점

1. compile time(컴파일 시점 바인딩)
* 메모리 위치가 컴파일 시점에 고정되어 있는 경우
* 생성되는 코드는 절대 주소(absolute code)를 사용
* 단점 : 코드 위치가 변경되면 다시 컴파일해야 함, 매우 정적인 시스템

2. Load Time(로드 시점 바인딩)
* 프로그램을 메모리에 로드할 때 주소를 결정
* 따라서 컴파일러는 relocatable code(이동 가능한 코드)를 생성해야 함
* 이 방식은 동일한 프로그램을 다양한 위치에 로드 가능

3. Execution Time(실행 시점 바인딩)
* 바인딩이 실행 중(run time)에 일어남
* 즉 프로그램이 실행 ㄷ중에 다른 메모리 영역으로 이동할 수 있음
* 이 경우에는 동적 주소 변환이 필요함

&ensp;Modern systems는 대부분 Execution-time 바인딩을 사용한다. 이 방식은 프로세스 보호, 메모리 공유, 메모리 단편화 해결에도 유리하다. <br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-4.png" width="600"></p>

&ensp;3_Logical vs Physical Address Space<br/>

1. Logical Address(논리 주소/ 가상 주소)
* CPU가 프로그램을 실행할 때 생성하는 주소
* 프로세스가 보는 주소
* 일반적으로 사용자 프로세스 관점의 주소이며, 실제 메모리에는 존재하지 않음 → 가상 주소라고도 불림

2. Physical Address (물리 주소)
* 실제 RAM에 존재하는 주소
* 메모리 컨트롤러나 하드웨어가 접근하는 실제 위치

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-5.png" width="600"></p>

&ensp;컴파일 또는 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같다. 그러나 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다르다. 이러면 논리 주소를 가상 주소(virtual address)라 한다. 프로그램에 의해 생성된 모든 논리 주소 집합을 논리 주소 공간(logical address space)이라 하며 이 논리 주소와 일치하는 모든 물리 주소 집합을 무릴 주소 공간(physical address space)이라 한다. <br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-6.png" width="600"></p>

&ensp;MMU(Memory Management Unit)
&ensp;MMU는 실행 시간(run time)에 논리 주소를 물리 주소로 매핑하는 하드웨어 장치이다. 즉 프로그램의 실행 중에는 가상 주로를 물리 주소로 바꿔어준다. MMU는 실행 시점에 논리 주소를 물리 주소로 매핑하며, 사용자 프로그램은 물리 주소를 직접 보지 않고 안전하고 유연한 메모리 관리가 가능해진다. <br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-7.png" width="600"></p>

* CPU가 생성한 논리 주소(Virtual Address)를 실제 메모리에서 사용할 수 있는 물리 주소(Physical Address)로 변환
* 사용자 프로그램은 물리 주소를 절대 알 수 없고, 오직 논리 주소만 사용함

&ensp;가장 간단한 MMU 구현 방식: Relocation Register(base register)<br/>

&ensp;CPU가 생성한 논리 주소에 relocation register 값을 더해서 물리 주소 생성<br/>
&ensp;물리 주소 = 논리 주소 + relocation register 값<br/>

&ensp;실행시간 바인딩은 주소가 메모리에 실제로 접근되기 바로 직전에 바인딩이 수행된다. 사용자 프로그램은 논리 주소를 사용한 것이고 메모리 하드웨어는 논리 주소를 실제 주소로 바꾼 것이다. 이 덕분에 가상 메모리, 페이징, 프로세스 보호가 가능해진다. <br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-8.png" width="600"></p>

&ensp;4_Dynamic Loading (동적 로딩)<br/>
&ensp;프로세스의 크기는 메모리의 크기보다 커서는 안 된다. 메모리 공간의 더 효율적으로 이용을 위해서는 동적 적재(dynamic loading)를 해야한다. <br/>

&ensp;정의<br/>
&ensp;루틴이 호출될 때까지 메모리에 로드되지 않는 방식<br/>
* 즉, 프로그램의 일부 함수(루틴)는 호출되기 전까지 디스크에 남아 있음
* 호출 시에만 필요한 코드가 메모리로 로딩됨

&ensp;특징<br/>
* 메모리 절약: 사용하지 않는 코드는 아예 로드하지 않음
* Relocatable load format로 디스크에 저장
* OS의 특별한 지원 없이도 프로그램 설계만으로 구현 가능하다. 사용자 자신이 프로그램의 설계를 책임져야 한다. 운영체제는 동적 적재를 구현하는 라이브러리 루틴을 제공해 줄 수는 있다. 

&ensp;5_Dynamic Linking (동적 링킹)<br/>
&ensp;동적 연결 라이브러리(DLL)는 사용자 프로그램이 실행될 때 사용자 프로그램에 연결되는 시스템 라이브러리이다.<br/>
&ensp;어떤 운영체제는 정적 연결(static linking)만을 지원한다. 이러한 시스템에서는 라이브러리가 이 프로그램의 이진 프로글매이미지에 끼어들게 된다.<br/>
&ensp;동적 연결 개념은 동적 적재의 개념과 유사하다. 동적 적재에서는 로딩(loading)이 실행 시까지 미루어졌었지만 동적 연결에서는 연결(linking)이 실행 시기까지 미루어지는 것이다. DLL은 라이브러리(실행 가능 이미지에 해당 언어 라이브러리)를 여러 프로세스 간에 공유할 수 있어 메인 메모리에 DLL 인스턴스가 하나만 있을 수 있다. 이러한 이유로 DLL은 공유 라이브러리라고도 한다. <br/>

&ensp;정의<br/>
&ensp;링킹(라이브러리 연결)을 실행 시간까지 지연시키는 방식<br/>
* 실행 중에 필요한 라이브러리를 런타임에 메모리로 연결(link)
* 작은 코드 조각인 stub가 라이브러리 주소를 찾아 실제 루틴을 호출

&ensp;특징<br/>
* 주로 **공유 라이브러리 (shared libraries, .so 파일 등)**에 사용됨
* OS의 지원이 필요함
* 라이브러리 버전을 바꾸거나 업데이트할 때도 유용함

&ensp;두 개념 비교<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-9.png" width="600"></p>

&ensp;동적 로딩은 "필요할 때만 코드 불러오기", 동적 링킹은 "실행 중에 외부 라이브러리를 연결"하는 방식이며, 두 개념 모두 프로그램의 효율성과 유연성을 높이는 핵심 메커니즘이다.<br/>

2\. 연속 메모리 할당(Contiguous Memory Allocation)
======

&ensp;연속적인 메모리 할당에서 각 프로세스는 다음 프로세스가 적재된 영역과 인접한 하나의 메모리 영역에 적재된다.<br/>

&ensp;1_ Contiguous Allocation (연속 할당)<br/>

1. 개요
* 메인 메모리는 운영체제(OS)와 사용자 프로세스 둘 다 수용해야 함
* 메모리는 제한된 자원이므로 효율적인 할당 필요

2. 연속 할당 방식이란?
&ensp; 메모리를 할당하는 가장 간단한 방법 중 하나는 프로세스를 메모리의 가변 크기 파티션에 할당하는 것이다. 각 파티션에는 정확히 하나의 프로세스만 적재될 수 있다. 이 가변 파티션 기법에서 운영체제는 사용 가능한 메모리 부분과 시용 중인 부분을 나타내는 테이불을 유지한다. 처음에는 모든 메모리가 사용자 프로세스에 사용 가능하며, 하나의 큰 사용 가능한 메모리 블록인 hole로 간주한다. 결국에는 메모리에는 다양한 크기의 hole이 생기게 된다. <br/>
* 하나의 프로세스가 하나의 연속된 메모리 공간에 적재됨
* 이는 초기 메모리 관리 방식 중 하나로 단순하고 구현이 쉬움

3. 메모리 분할 방식
1. 운영체제 영역 (OS)
* 시스템 코드, 인터럽트 벡터 등이 포함됨
2. 사용자 프로세스 영역
* 각각의 사용자 프로세스는 연속된 블록에 적재됨

4. 주소 보호: Relocation + Limit Registers
* 사용자 프로세스끼리의 메모리 침범을 막기 위해 다음 레지스터 사용:
* Base Register : 해당 프로세스의 물리 주소 시작 위치 저장
* Limit Register : 논리 주소의 허용 범위(크기) 저장

&ensp;→ MMU가 실행 시간에 논리 주소를 동적으로 물리 주소로 변환<br/>
&ensp;physical address = logical address + base register<br/>

5. 기타 특정
* 커널 코드 일부는 실행 후 메모리에서 제거 가능 (transient)
* 커널 크기도 유동적으로 변경 가능 (예: 사용하지 않는 장치 드라이버 제거)

&ensp;Contiguous Allocation은 프로세스를 연속된 메모리 공간에 적재하는 초기 메모리 관리 방식으로 구현은 간단하지만 외부 단편화와 유연성 부족 문제가 있어 현대 시스템은 페이징과 같은 기법을 주로 사용한다.<br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-10.png" width="600"></p>

&ensp;Memory Allocation(가변 파티션 방식)

1. Variable-Partition Allocation
&ensp;프로세스마다 필요한 만큼만 메모리를 할당해주는 방식<br/>
* 각 프로세스는 자기 크기만큼의 메모리 블록을 받음
* 이때 할당되지 않은 공간 hole(빈 공간)이라고 부름

2. Hole 관리와 병합
* 프로세스가 종료되면 그 메모리 블록은 해제되고 hole이 됨
* 인접한 hole이 있다면 합쳐짐 → 외부 단편화 방지

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-11.png" width="600"></p>

1. 프로세스 5, 8, 2 가 적개되어 있고 메로리가 완전 활용 중이다.
2. 프로세스 8이 종료된 후 하나의 연속된 hole이 생긴다.
3. 프로세스 9가 도착하고 hole에 적재된다.
4. 프로세스10도 hole에 적재된다. 

&ensp;Dynamic Storage Allocation Problem(동적 할당 문제) <br/>

&ensp;프로세스가 필요한 크기의 메모리를, hole 리스트 중 어디에 배치할 것인가?<br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-12.png" width="600"></p>

&ensp;보통 First-Fit과 Best-Fit이 실용적이며 효율도 좋다. Worst-Fit은 오히려 낭비가 커서 잘 사용되지 않다.

&ensp;가변 파티션 방식은 효율적인 메모리 사용을 위해 빈 공간(Hole)을 관리하며, 이를 위한 동적 할당 전략으로 First-Fit, Best-Fit, Worst-Fit이 있으며, 속도와 공간 활용 측면에서 First/Best가 유리하다.<br/>

&ensp;2_Fragmentation<br/>

1. External Fragmentation (외부 단편화)
&ensp;메모리 전체적으로는 충분한 공간이 있지만, 연속된 블록이 없어서 할당할 수 없는 상태<br/>
* 예시: 3개의 빈 공간 각각 10KB 있지만, 20KB 요청이 오면 할당 불가
* 주로 **가변 파티션(variable-partition)**에서 발생
* 연속적 할당이 필요할 때 문제가 됨

2. Internal Fragmentation (내부 단편화)
&ensp;메모리를 할당했지만, 실제로 요청된 크기보다 조금 더 큰 블록이 할당되면서 남는 부분이 낭비되는 현상
* 예시: 34KB 요청했는데 40KB 블록이 할당 → 6KB 낭비
* 고정 크기 파티션(fixed partition), 페이지 단위 할당 등에서 주로 발생

&ensp;단편화 분석: 50-percent rule<br/>
&ensp;First-Fit 방식에서는 N개의 블록이 할당되면, 평균적으로 0.5N 개의 외부 단편화 블록이 생긴다. 즉 1/3이 쓸 수 없게 된다. <br/>
* 메모리 효율성이 급격히 떨어질 수 있다는 경험적 규칙

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-13.png" width="600"></p>

&ensp;해결 방법:  Compaction (압축)<br/>
&ensp;메모리 안에 흩어진 빈 공간들을 한 곳으로 모아서 큰 연속 공간을 만드는 것<br/>
&ensp;재배치가 어셈블 또는 적재 시에 정적으로 행해진다면 압축은 실행될 수 없다. 압축은 프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우에만 가능하다. 주소가 동적으로 재배치할 수 있다면 재배치 작업은 프로그램과 데이터를 새로운 위치로 옮기고 새 위치를 반영하기 위하여 기준 레지스터만 변경하면 완료된다. 
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-14.png" width="600"></p>

&ensp;외부 단편화 문제를 해결할 수 있는 다른 방법은 한 프로세스의 논리 주소 공간을 여러 개의 비연속적인 공간으로 냐누어 필요한 크기의 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 방법이다. 이것은 컴퓨터 시스템에 가장 일반적인 메모리 관리 기법인 페이징에서 사용되는 전략이다.

3\. 페이징(paging)
======

&ensp;1_기본 방법<br/>

&ensp;연속된 물리적 공간을 요구하지 않고 프로그램을 고정된 크기의 블록으로 나누어 메모리에 분산시켜 배치하는 방식<br/>

&ensp;**물리 메모리**는 **프레임(frame)**이라 불리는 같은 크기 블록으로 나누어진다. **논리 메모리**는 **페이지(page)**라 불리는 같은 크기의 블록으로 나누어진다. 프로세스가 실행될 때 그 프로세스의 페이지는 파일 시스템 또는 예비 저장장치로부터 가용한 메인 메모리 프레임으로 적재된다. 예비 저장장치는 메모리 프레임 혹은 프레임의 묶음인 클러스터와 동일한 크기의 고정 크기 블록으로 나누어진다. <br/>

&ensp;특징<br/>
* 외부 단편화가 없음
* 프로그램 실행을 위해 N개의 빈 프레임에 N개의 페이지를 로딩
* 변환을 위해 페이지 테이블(page table) 필요

&ensp;주소 변환 방식<br/>
&ensp;CPU가 만든 논리 주소를 두 부분으로 나눠 물리 주소로 변환<br/>
* page number(p) : 프로세스 **페이지 테이블** 을 액세스할 때 사용. 페이지 테이블은 물리 메모리의 각 프레임의 시작 주소를 저장하고 있다.
* page offset(d) : 기본 주소와 결합하여 메모리 장치에 전송되는 물리적 메모리 주소를 정의. 참조되는 프레임 안에서의 위치

&ensp;CPU에 의해 생성된 논리 주소를 물리 주소로 변환하기 위해 MMU가 취한 단계<br/>
1. 페이지 번호 p를 추출하여 페이지 테이블의 인덱스로 사용
2. 페이지 테이블에서 해당 프레임 번호 f를 추출
3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꿈

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-15.png" width="600"></p>

&ensp;오프셋 d는 변하지 않기 때문에 대체되지 않으며 프레임 번호와 오프셋은 이제 물리 주소를 구성한다. <br/>
&ensp;프레임 크기와 마찬가지로 페이지 크기는 하드웨어에 의해 정해진다. 논리 주소 공간의 크기가 $2^{m}$ 이고 페이지 크기가 $2^{n}$ 바이트인 경우 논리 주소의 상위 m-n 비트는 페이지 번호를 지정하고 n 하위 비트는 페이지 오프셋을 지정한다. <br/>

&ensp;Paging Hardware 구조<br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-16.png" width="600"></p>

* CPU가 논리 주소 [p|d] 생성
* -> p 를 페이지 테이블의 인덱스로 사용해 프레임 번호 f 획득
* -> 최종 물리 주소 [f|d] 생성하여 메모리 접근

&ensp;이 과정을 하드웨어(MMU)가 자동으로 처리<br/>

&ensp;예시 구조: 논리 <-> 물리 메모리<br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-17.png" width="600"></p>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-18.png" width="600"></p>

&ensp;논리적 순서와 물리적 위치는 전혀 다를 수 있다. 하지만 프로세스는 연속된 논리 주소만 알면 된다. <br/>

&ensp;Paging Example<br/>
* 메모리 크기: 32바이트
* 페이지 크기: 4바이트 → 총 8페이지
* n=2, m=4: 주소는 4비트, 그 중 2비트는 페이지 번호(p), 나머지 2비트는 오프셋(d)

* 논리 메모리에서 page 0~3 → page table에서 각각 frame 5, 6, 1, 2로 매핑
* 실제 물리 메모리는 연속적이지 않음 (분산 저장)
* 논리 주소: 연속 / 물리 주소: 불연속

&ensp;Internal Fragmentation(내부 단편화)<br/>
&ensp;페이징 기법을 사용하면 외부 단편화가 발생하지 않는다. 모든 놀고 있는 프레임이 프로세스에 할당될 수 있기 때문이다. 만약 프로세스가 페이지 경계와 일치하지 않는 크기의 메모리를 요구한다면 마지막 페이지 프레임은 전부 할당되지 않는다. 하지만 내부 단편화 발생 가능하다. <br/>

* 예시<br/>
  - 페이지 크기: 2,048 B
  - 프로세스 크기: 72,766 B → 35페이지 + 1,086 B
  - 36번째로 할당되는 페이지 프레임은 2,048 - 1,086 = 962 B 의 내부 단편화가 발생

  - 평균 내부 단편화 = 1/2 프레임 크기(작은 페이지 크기가 바람직 함)
&ensp;그러나 페이지 크기가 작아지면 그에 반비례하여 페이지 테이블의 크기가 커지게 되고 이 테이블이 차지하는 공간은 낭비된다. 일반적인 추세는 페이지 크기가 프로세스, 자료, 메인메모리가 커짐에 따라 함께 커져 왔다. <br/>

&ensp;페이징의 가장 중요한 특징은 메모리에 대한 프로그래머의 인식과 실제 내용이 서로 다르다. 프로그래머는 메모리가 하나의 연속적인 공간이며 메모리에는 이 프로그램만 있다고 생각한다. 그러나 실제로는 프로그램은 여러 곳에 프레임 단위로 분산되어 있고 많은 다른 프로그램이 올라와 있다. 프로그래머가 생각하는 메모리와 실제 물리 메모리의 차이는 주소 변환 하드웨어에 의해 해소된다. 논리 주소는 물리 주소로 변환된다. 이 사상은 운영체제에 의해 조정된다. 따라서 사용자 프로세스는 자기의 것이 아닌 메모리는 접근조차 할 수가 없다. 페이지 테이블을 통하지 않고서는 다른 공간에 접근할 길이 없으며 페이지 테이블은 그 프로세스가 소유하고 있는 페이지들만 가리키고 있기 때문이다. <br/>

&ensp;Free Frames 관리<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-19.png" width="600"></p>

* Before Allocation
  - 빈 프레임 목록:[13, 14, 18, 17, 20, 19, 21]
  - 새 프로세스가 4페이지 필요

* After Allocation
  - 각 페이지가 프레임에 배치되고 page table에 등록됨:
  - page 0 → 14
  - page 1 → 13
  - page 2 → 18
  - page 3 → 20
  - 이 구조 덕분에 연속된 공간이 없어도 페이지를 어디든 배치 가능

&ensp;2_하드웨어 지원(Hardware Support)<br/>

&ensp;Page Table 구현 방식<br/>
&ensp;프레임 테이블은 각 프레임당 하나의 항목을 가지고 있으며 프레임이 비어 있는지, 할당되는지, 할당되었다면 어느 프로세스의 어느 페이지에 할당되었는지를 나타낸다.<br/>
&ensp;컴퓨터는 페이지 테이블을 메인 메모리에 저장하고 **페이지 테이블 기준 레지스터(PTBR)**로 하여금 페이지 테이블을 가리키도록 한다.  <br/>

* PTBR (Page Table Base Register) : 메인 메모리에 있는 페이지 테이블의 시작 주소를 가리킴

* 문제: 두 번 메모리 접근 필요<br/>
1. 페이지 테이블 조회 (프레임 번호 찾기)
2. 실제 데이터 접근
* 해결책: TLB (Translation Lookaside Buffer) 사용<br/>

&ensp;TLB (Translation Lookaside Buffer)<br/>
* 정의 : 페이지 테이블에서 최근 참조된 주소를 캐싱하는 고속 메모리 (associative memory)
* 기능
  - TLB miss → 페이지 테이블 접근 → TLB에 캐시
  - TLB hit → 바로 물리 주소 획득 (빠름)
*  성능 향상 요소
  - TLB는 보통 수십~수천 개 항목만 저장 (작다!)
  - ASID(주소 공간 식별자): context switch 때 TLB flush 안 해도 됨
  - 일부 엔트리는 wired down (절대 삭제 안 됨, 커널용 등)
  - 교체 알고리즘 필요 (LRU, RR 등)

&ensp;요약<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-20.png" width="600"></p>

&ensp;Associate Memory(= TLB)<br/>
* TLB는 **연관 메모리(associative memory)**라고도 불림
* 연관 메모리는 병렬 탐색 가능: 여러 항목을 동시에 검사
* 구조: (Page #, Frame #) 쌍들
&ensp;주소 변환 (p, d)
* 만약 page number p가 TLB에 있으면 ➝ TLB hit
   - 해당 frame number f 바로 반환
* 없다면 ➝ TLB miss
  - page table에서 frame number 찾고 TLB에 추가

&ensp;Paging Hardware with TLB
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-21.png" width="600"></p>

* CPU는 논리 주소 (p, d)를 생성
* TLB에 p가 있으면 바로 frame f 획득 → 주소 조합 (f, d)
* TLB에 없으면 page table에서 p → f 찾아서 다시 조합

&ensp;Effective Access Time (EAT, 유효 접근 시간)<br/>
* 계산식 : $EAT = (1 + \varepsilon)\alpha + (2 + \varepsilon)(1 - \alpha)$

* $\alpha$ : TLB hit ratio (성공률)
* $\varepsilon$ : TLB 접근 시간
* 1 : 메모리 접근 (TLB hit일 때 1회)
* 2 : TLB miss 시 → page table + 데이터 2번 접근

* 예시
  - $\alpha = 80%$ , 메모리 접근 = 10ns, TLB 접근 시간 무시 -> EAT = 0.8×10 + 0.2×20 = 12ns
  - $\alpha = 99%$ , → EAT = 0.99×10 + 0.01×20 = 10.1ns

&ensp;Memory Protection<br/>
&ensp;페이징 환경에서 메모리 보호는 각 페이지에 붙어있는 보호 비트(protection bits)에 의해 구현된다. 이 비트들은 보통 페이지 테이블에 속해 있다. <br/>

* 보호 방식
   - Protection bit: read-only, read-write, execute 등 제어 가능
   - Valid / Invalid bit: 해당 페이지가 현재 프로세스에 유효한가?
* 유효성 체크
  - valid → 정상 접근
  - invalid → 접근 시 trap (예외) 발생 → OS가 제어권을 가져감
* PTLR (Page Table Length Register)
  - 페이지 테이블의 유효한 길이를 나타냄
  - 접근하려는 페이지 번호가 PTLR보다 크면 → invalid

&ensp;Valid / Invalid Bit in Page Table<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-22.png" width="600"></p>

* 각 페이지 테이블 항목에 v 또는 i 비트 있음
   - v: 해당 페이지가 유효함 (frame에 매핑되어 있음)
   - i: 해당 페이지는 없는 주소거나 다른 프로세스 주소

&ensp;공유 페이지(Shared Pages)<br/>
* shared code(공유 코드)
  - 여러 프로세스가 하나의 읽기 전용(read-only) 코드 복사본을 공유
  - 보통 reentrant code(재진입 가능한 코드) 사용
    + 예: shard libraries, 컴파일러, 텍스트 에디터, 윈도우 시스템 등

* 특징 
  - 다중 스레드가 같은 주소 공간을 공유하는 방식과 유사
  - IPC(프로세스 간 통신)에도 사용 가능 (단, read-write 공유 허용 시)

* Private Code & Data (개인 코드와 데이터)
  - 각 프로세스는 자신만의 개별 복사본을 가짐
  - 논리 주소 공간 어디든 위치할 수 있음
  - 쓰기나 실행 등의 연산이 필요하므로 공유하지 않음

&ensp;Shared Pages 예제<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-23.png" width="600"></p>

&ensp;요약비교<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-24.png" width="600"></p>


4\. Structure of the Page Table
=======


* 페이지 테이블의 크기 문제<br/>
  - 32비트 주소 공간에서 4KB 페이지 크기를 사용하면:
    + 주소 공간 크기 : $2^{32}$ = 4GB
    + 페이지 크기 : $2^{12}$ = 4KB
    + 페이지 개수 : $2^{32} / 2^{12} = 2^{20}$ = 1M entries
    + 각 페이지 테이블 엔트리가 4바이트라면, 전체 페이지 테이블 크기 = 4MB
  - 이만한 크기의 테이블을 연속된 공간에 할당하는 건 비효율적이므로, 더 나은 구조가 필요

&ensp;계층적 페이지 테이블(Hierarchical Paging)<br/>

* 논리 주소를 여러 개의 필드로 나누어 계층적으로 페이지 테이블을 나눔
* 가장 단순한 형태: 2단계 페이지 테이블 (Two-Level Paging)
* 논리 주소 공간이 크면, 페이지 테이블도 커짐 -> 계층적 페이지 테이블로 나눠서 효율적인 메모리 사용 가능

&ensp;Two-Level Page-Table Scheme<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-25.png" width="600"></p>

* outer page table: p₁을 인덱스로 사용
* 해당 항목이 가리키는 inner page table에서 p₂를 인덱스로 사용해 frame 번호 획득
* 오프셋 d를 frame 주소에 붙여서 실제 물리 주소 계산

* 예시
* 32비트 주소를 다음과 같이 나눔:
* 페이지 오프셋: 10비트 ($2^{10}$ = 1KB)
* 페이지 번호 : 22비트 -> 다시 두 부분으로 나눔
  - p₁: outer page table index (12비트)
  - p₂: inner page table index (10비트)
  - -> 전체 논리 주소: p₁ (12) | p₂ (10) | d (10)

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-26.png" width="600"></p>

&ensp;Address-translation Scheme<br/>

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-27.png" width="600"></p>

1. 논리 주소 구성
* p₁: outer page table에서 접근할 인덱스
* p₂: inner page table (page of page table)에서 접근할 인덱스
* d: page offset, 해당 물리 프레임 내에서의 실제 위치

2. 주소 변환 과정
1. CPU가 논리 주소를 생성: p₁ | p₂ | d
2. p₁을 이용해서 outer page table에서 해당 inner page table의 주소를 얻음.
3. 그 주소에서 p₂ 인덱스를 이용해 실제 프레임 번호를 얻음.
4. 마지막으로 그 프레임 주소에 오프셋 d를 더해서 최종 물리 주소를 계산. 

&ensp;64-bit Logical Address Space<br/>
&ensp;현대 컴퓨터 시스템은 64비트 주소 공간을 사용한다. 이 말은 논리 주소 공간이 $2^{64}$ 크기임을 의미한다. <br/>

* 기본 조건 예시
  - 페이지 크기: 4KB = $2^{12}$ bytes
  - 따라서 필요한 페이지 수 : $2^{64} / 2^{12} = 2^{52}$
  - 즉 페이지 테이블에 $2^{52}$ 개의 항목이 필요함
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-28.png" width="600"></p>

&ensp;문제점<br/>
* 각 페이지 테이블 항복이 4바이트(또는 8바이트)라고 가정하면 : 
  - 단일 페이지 테이블의 크기 = $2^{52} * 4 $ bytes = $2^{52}$ bytes (16 PB)
  - -> 이것은 너무 커서 물리 메모리에 적재할 수 없음

&ensp;해결책: 계층적 페이징 (Hierarchical Paging)<br/>
* Two-Level Paging
* 주소 구성: p₁(42 bits) | p₂(10 bits) | d(12 bits)
* 하지만 p₁ = 42 bits → $2^{42}$ 개의 외부 페이지 테이블 항목 필요 -> 여전히 엄청난 크기 (4TB 이상)

&ensp;더 나은 해결책: Three-Level Paging<br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-29.png" width="600"></p>

* p₁: 2⁰~2³¹ 외부 페이지 테이블 (가장 상위)
* p₂: 중간 계층 페이지 테이블
* p₃: 실제 페이지 테이블
* d: 페이지 내 오프셋

&ensp;장점<br/>
* 각 레벨의 테이블 크기를 제한할 수 있음
* 실제 메모리에 필요한 페이지 테이블만 동적으로 로드 가능
* 공간 낭비 줄이고 효율적 메모리 접근 가능

&ensp;단점<br/>
* 주소 하나를 변환하는 데 최대 4번의 메모리 접근이 필요:
  - 3개의 페이지 테이블 참조 (p₁, p₂, p₃)
  - 1번의 실제 데이터 접근 (offset)
* 하지만 TLB(Translation Lookaside Buffer)를 통해 이를 캐싱하여 효율적으로 해결 가능

&ensp;Hashed Page Table<br/>
&ensp;해시 함수로 가상 페이지 번호를 해시 테이블의 인덱스로 변환하고 그 인덱스를 기반으로 체이닝 방식으로 실제 물리 프레임을 찾는 구조이다. <br/>

&ensp;사용 배경<br/>
* 32비트 이상의 주소 공간에서는 페이지 테이블이 너무 커짐
* 특히 희소(sparse) 주소 공간에서는 낭비가 많음
* 전통적인 계층적 페이지 테이블로는 비효율적 -> 해시 기반 접근이 더 적절

&ensp;작동 방식<br/>
1. 해싱
* 가상 페이지 번호 p를 해시 함수 h(p)에 넣어 해시 테이블 인덱스를 구함
2. 체이닝(Chaining)
* 해당 인덱스에는 **연결 리스트(chain)**가 있음
* 리스트의 각 노드는 다음 세 가지 정보를 가짐:
  1. 가상 페이지 번호
  2. 매핑된 물리 프레임 번호
  3. 다음 노드를 가리키는 포인터

3. 검색(Matching)
* 연결 리스트를 따라가며 가상 페이지 번호와 일치하는 항목을 찾음
* 일치하면 해당 물리 프레임 번호를 반환함 → 주소 변환 성공

&ensp;Clustered Page Tables (64비트 주소 공간 대응)<br/>
&ensp;64비트 시스템에서는 페이지 수가 $2^{64}$ 페이지 크기 만큼 커짐 -> chaining 도 비효율적일 수 있다.<br/>

* **해시 테이블 엔트리 하나가 여러 가상 페이지(예: 16개)**를 처리하도록 함
* 각 해시 엔트리는:
  - 연속된 가상 페이지들의 공통된 해시 결과를 처리
  - 효율적으로 체이닝 수를 줄임

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-30.png" width="600"></p>

&ensp;전체 흐름 요약<br/>
* 가상 주소 → 해시 테이블 → 해시 체인 탐색 → 물리 주소로 변환

&ensp;구성 요소 설명<br/>
1. logical address (가상 주소)
* p : 가상 페이지 번호 (page number)
* d : 페이지 내 오프셋 (page offset)
&ensp;-> 이는 페이지 내에서의 정확한 위치를 나타낸다. <br/>

2. hash function (해시 함수)
* 가상 페이지 번호 p를 입력으로 받아 해시 테이블의 인덱스를 생성한다.
* 예: hash(p) = h

3. hash table(해시 테이블)
* 해시 함수의 결과로 나온 인덱스에 **연결 리스트(chain)** 가 저장되어 있다.
* 이 리스트에는 여러 항목이 들어갈 수 있다. 왜냐하면 서로 다른 가상 페이지 번호가 같은 해시 값을 가질 수 있기 때문이다. (해시 충돌)

4. chain entry 구조 (리스트 항목)
* q: 가상 페이지 번호
* s: 물리 프레임 번호
* 다음 노드에 대한 포인터
&ensp;이러한 구조로 인해 여러 개의 노드를 순서대로 검색해야 할 수 있다.<br/>

5. 주소 변환 과정
&ensp;단계별 정리:
1. CPU가 p, d로 구성된 가상 주소를 생성
2. p를 해시 함수에 입력 → 해시 테이블 인덱스 구함
3. 해당 인덱스의 체인을 따라가며 p와 일치하는 q를 찾음
4. 일치하는 항목 발견 시 해당 s (물리 프레임 번호)를 가져옴
5. 최종적으로 r = s와 d를 결합 → 물리 주소 r:d 생성
6. 물리 메모리 접근 완료!

&ensp;그림 흐름<br/>
&ensp;logical address(p, d) -> hush function -> hash table -> chain entry 비교(q == p?) -> s 반환 -> physical address(r = s, d) -> access physical memory<br/>

&ensp;Inverted Page Table<br/>
&ensp;일반적인 페이지 테이블 방식과는 정반대의 방식이다. <br/>
<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-31.png" width="600"></p>

1. 기존 방식의 문제
* 각 프로세스마다 거대한 페이지 테이블을 유지해야 함 (특히 64-bit 시스템에서는 매우 큼)

2. Inverted Page Table의 핵심 아이디어
&ensp;각 물리 페이지마다 하나의 엔트리를 유지<br/>
* 각 엔트리는 다음을 포함
  - 이 물리 페이지에 대응되는 가상 주소
  - 해당 페이지를 소유한 프로세스 정보
&ensp;즉, 실제 메모리(physical memory)를 기준으로 관리<br/>

3. 장점
&ensp;페이지 테이블 크기를 물리 메모리 크기에 비례하게 줄일 수 있다<br/>

4. 단점
&ensp;가상 주소로부터 물리 주소를 찾을 때, 역 테이블 전체를 탐색해야 한다.(성능 저하) 이를 해결하기 위해 해시 테이블을 도입해 빠르게 해당 항목을 찾도록 하던가 TLB (Translation Lookaside Buffer) 를 함께 사용하여 속도 개선할 수 있다.<br/>

5. 공유 메모리는 어떻게 구현할까?
&ensp;다수의 가상 주소가 하나의 물리 프레임을 참조해야 한다. 그래서 가상 주소들을 하나의 물리 주소에 매핑한다. 다만 이는 특별한 관리와 OS지원이 필요하다.<br/>

&ensp;Inverted Page Table의 구조적 동작<br/>
&ensp;전통적인 방식에서는 각 프로세스가 가상 페이지마다 페이지 테이블 엔트리를 갖지만, 역 페이지 테이블에서는 모든 물리 프레임마다 하나의 테이블 엔트리를 가지고 있다.<br/>

1. 입력: Logical Address (가상 주소)
* 구성: pid | p | d
  - pid: Process ID (해당 가상 주소가 어떤 프로세스의 것인지 식별)
  - p: Virtual Page Number (가상 페이지 번호)
  - d: Offset (페이지 내 위치)

2. 역 페이지 테이블 구조
* 테이블 엔트리 구성: pid | p
  - 각 물리 프레임이 어떤 프로세스의 어떤 가상 페이지를 담고 있는지를 기록
* 선형 탐색 or 해시 검색을 통해 해당 pid + p를 찾는다.
* 일치하는 인덱스 i를 찾으면, 이는 해당 물리 프레임 번호가 된다.

3. 물리 주소 구성
* 구성: i | d
  - i: 물리 프레임 번호 (역 페이지 테이블에서 찾은 인덱스)
  - d: Offset (가상 주소에서 그대로 유지)

&ensp;흐름 요약<br/>
1. CPU는 pid | p | d로 구성된 가상 주소를 생성
2. 역 페이지 테이블에서 pid, p에 해당하는 엔트리를 탐색 (→ 인덱스 i)
3. 해당 인덱스를 물리 프레임으로 사용하고, 오프셋 d를 붙여 최종 **물리 주소 i | d**를 만든다.
4. 해당 물리 주소로 메모리에 접근

5\. 스와핑(Swapping)
======

&ensp;스와핑(Swapping)은 프로세스를 메모리에서 디스크(백업 저장소)로 내보내고, 필요 시 다시 메모리로 가져오는 메모리 관리 기법입니다. 운영체제가 메모리 부족 시 사용한다.<br/>

* Swapped out: 프로세스 P₁이 메모리에서 백업 저장소로 이동
* Swapped in: 백업 저장소에 있던 프로세스 P₂가 메모리로 복귀
&ensp;->총 메모리 용량보다 많은 프로세스를 다룰 수 있게 한다.<br/>

&ensp;구성요소<br/>
1. Backing Store (백업 저장소):
* 모든 사용자 프로세스의 메모리 이미지가 저장 가능한 디스크 공간
* 빠른 접근 속도 필요
2. Ready Queue:
* 메모리에 다시 올라올 준비가 된 프로세스들의 목록

&ensp;Roll Out / Roll In<br/>
* 우선순위 기반 스와핑
* 낮은 우선순위 프로세스를 내보내고, 높은 우선순위 프로세스를 load하고 실행함

&ensp;스와핑 시간<br/>
&ensp;대부분의 시간은 데이터 복사에 소모된다. 복사되는 데이터 양에 비례하여 전송 시간 증가한다.<br/>

&ensp;물리 주소 동일하게 돌아와야 할까?<br/>
* 주소 바인딩 방법에 따라 다르다
  - 고정 바인딩 (compile-time / load-time) → 같은 주소로 돌아와야 함
  - 실행 시간 바인딩 (execution-time) → 다른 위치로 돌아와도 됨
    + 동적 재배치(예: MMU, 페이지 테이블 사용)

&ensp;운영체제 지원 및 조건<br/>
* 스와핑은 많은 OS에서 기본 비활성화 상태
* 메모리 사용량이 임계치를 초과하면 활성화됨
* 메모리 사용량이 다시 줄어들면 비활성화

<p align="center"><img src="/assets/img/Operating System/9. Main Memory/9-32.png" width="600"></p>

* swap out: 메모리 ➝ 디스크로 이동
* swap in: 디스크 ➝ 메모리로 복귀
* backing store: 디스크 상 저장소
* user space: 사용자 프로세스들이 위치하는 메모리 영역
* swap을 통해 더 많은 프로세스를 실행 가능

&ensp;Context Switch Time including Swapping<br/>

&ensp;스와핑(Swapping): 현재 CPU에 올릴 다음 프로세스가 메모리에 없으면, 다른 프로세스를 디스크로 내보내고(swap out), 새로운 프로세스를 메모리에 올리는 작업(swap in)이 필요하다.<br/>

&ensp;스와핑의 성능 저하:<br/>
* 100MB 프로세스를 50MB/sec 속도로 디스크에 저장하려면 2000ms (2초) 소요
* 같은 크기의 프로세스를 다시 불러오면 또 2000ms
* 합쳐서 총 4초 (4000ms) 의 context switching overhead 발생

&ensp;최적화:
* 실제 사용 중인 메모리만 스와핑 → 불필요한 낭비 줄이기
* request_memory()와 release_memory() 시스템 콜로 운영체제가 메모리 사용량을 더 정확히 파악 가능

&ensp;스와핑에 대한 제한 조건:<br/>
* Pending I/O가 있으면 해당 프로세스를 스와핑할 수 없음 (I/O가 잘못된 프로세스에 적용될 수 있음)
* 해결책으로 double buffering 사용 → I/O 데이터를 커널 공간에 옮긴 후 디바이스로 보내기 (하지만 성능 오버헤드 존재)

&ensp;현대 운영체제에서는 표준 스와핑은 잘 안 쓴다. 대신 수정된 방식(modified swapping)을 사용한다. 다만 메모리가 매우 부족할 때만 스와핑을 수행한다.<br/>

&ensp;Swapping on Mobile Systems<br/>
* 모바일 시스템에서는 스와핑이 일반적으로 지원되지 않다. 
  - 플래시 메모리 공간이 작음
  - 쓰기 수명 제한
  - CPU-플래시 간 처리 속도 느림
* 대안적 접근 방식:
  - iOS: 앱에게 메모리 해제를 요청 (asks apps) → 플래시에서 읽기 전용 데이터 다시 불러오도록 설계
  - Android: 메모리가 부족하면 앱을 종료하지만, 앱의 상태(application state)를 먼저 저장해서 나중에 빠르게 재시작 가능
* 공통점: 두 OS 모두 페이징(paging) 은 지원함 → 메모리 부족 상황에 대처 가능