---
title: "Chapter 5. CPU Scheduling"
excerpt: ""

wirter: sohee kim
categories:
  - Operating System
tags:
  - operating system

toc: true
use_math: true
toc_sticky: true
  
date: 2025-04-07
last_modified_at: 2025-04-07
---


1\. 기본 개념
======

&ensp;코어가 하나인 시스템에서는 한 순간에 오직 하나의 프로세스만 실행될 수 있다. 나머지 프로세스는 CPU의 코어가 가용 상태가 되어 다시 스케줄 될 수 있을 때까지 기다려야 한다. 다중 프로그래밍의 목적은 CPU 이용률을 최대화하기 위해 항상 실행 중인 프로세스를 가지게 하는 데 있다. <br/>

&ensp;1_CPU-I/O 버스트 사이클(CPU-I/O Burst Cycle)<br/>
&ensp;프로세스 실행은 CPU 실행과 I/O 대기의 사이클로 구성된다. 프로세스들은 이들 두 상태 사이를 교대로 왔다 갔다 한다. 프로세스 실행은 CPU 버스트(burst)로 시작된다. 뒤이어 I/O 버스트가 발행하고 그 뒤를 이어 또 다른 CPU 버스트가 발행하며 이어 또 다른 I/O 버스트 등등으로 진행된다. <br/>

&ensp;2_CPU 스케줄러(CPU Schedler)<br/>
&ensp;CPU가 유휴 상태가 될 때마다 운영체제는 준비 큐에 있는 프로세스 중 하나를 선택해 실행해야 한다. 선택절차는 CPU 스케줄러에 의해 수행된다. 스케줄러는 실행 준비가 되어 있는 메모리 내의 프로세스 중에서 선택하여 이들 중 하나에게 CPU를 할당한다.<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-1.png" width="600"></p>

&ensp;3_선점 및 비선점 스케줄링(Preemptive and Nonpreemptive Scheduling)<br/>
&ensp;CPU 스케줄링 결정은 네 가지 상황에서 발생할 수 있다.<br/>
* 한 프로세스가 실행 상태에서 대기 상태로 전환될 때<br/>
* 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때<br/>
* 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때<br/>
* 프로세스가 종료할 때<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-2.png" width="600"></p>

&ensp; 상황 1, 4에서만 스케줄링이 발생할 경우 우리는 이러한 스케줄링 방법을 비선점(nonpreemptive) 또는 협조적(cooperative)이라고 한다. 그렇지 않으면 그것은 선점(preemptive)이라고 한다. 비선점 스케줄링하에서는 일단 CPU가 한 프로세스에 할당되면 프로세스가 종료하든지 또는 대기 상태로 전환해 CPU를 방출할 때까지 점유한다. <br/>

&ensp;4_디스패처(Dispatcher)<br/>
&ensp;CPU 스케줄링 기능에 포함된 또 하나의 요소는 디스패처(dispatcher)이다. 디스패처는 CPU 코어의 제어를 CPU 스케줄러가 선택한 프로세스에 주는 모듈이며 다음 같은 작업을 포함한다.<br/>
* 한 프로세스에서 다른 프로세스로 문맥을 교환하는 일<br/>
* 사용자 모드로 전환하는 일<br/>
* 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동하는 일<br/>

&ensp;디스패처는 모든 프로세스의 문맥 교환 시 호출되므로 가능한 한 최고로 빨리 수행되어야 한다. 디스패처가 하나 이 프로세스를 정지하고 다른 프로세스의 수행을 시작하는데까지 소요되는 시간을 디스패치 지연(dispatch latency)이라고 한다. <br/>
<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-3.png" width="600"></p>


2\. 스케줄링 기준(Scheduling Criteria)
======

*  Maximize CPU 이용률(utilization): 실제 시스템에서는 40%에서 90%까지의 범위를 가져야 한다.<br/>
* Maximize 처리량(throughput): CPU가 프로세스를 수행하느라고 바쁘다면 작업이 진행되고 있는 것이다. 작업량 측정의 한 방법은 단위 시간당 완료된 프로세스의 개수이다. 이것을 처리량(thoughput)이라고 한다. <br/>
* Minimize 총처리 시간(turnaround time): 특정한 프로세스의 입장에서 보면 중요한 기준은 그 프로세스를 실행하는 데 소요된 시간일 것이다. 프로세스의 제출 시간과 완료 시간의 간격을 총처리 시간이라고 한다. 총처리 시간은 준비 큐에서 대기한 시간, CPU에서 실행하는 시간, 그리고 I/O 시간을 합한 시간이다.<br/>
* Minimize 대기시간(waiting time): CPU 스케줄링 알고리즘은 프로세스가 실행하거나 I/O을 하는 시간의 양에 영향을 미치지는 않는다. 스케줄링 알고리즘은 단지 프로세스가 준비 큐에서 대기하는 시간의 양에만 영향을 준다. 대기 시간은 준비 큐에서 대기하면서 보낸 시간의 합이다.<br/>
* Minimize 응답 시간(response time): 대화식 시스템에서 총처리 시간은 최선의 기준이 아닐 수도 있다. 프로세스가 어떤 출력을 매우 일찍 생성하고 앞서의 결과가 사용자에게 출력되는 사이에 새로운 결과를 얻으려고 연산을 계속하는 경우가 있다. 따라서 또 다른 기준은 하나의 요구를 제출한 후 첫 번쨰 응답이 나올 때까지의 시간이다. 응답시간이라고 하는 이 기준은 응답이 시작되는 데까지 걸리는 시간이지 그 응답을 출력하는 데 걸리는 시간은 아니다.<br/>

&ensp;CPU 이용률과 처리량을 최대화하고 총처리 시간, 대기 시간, 응답 시간을 최소화하는 것이 바람직하다. 대부분의 경우 평균 측정 시간을 최적화하려고 한다. 그러나 어떤 경우에는 평균보다는 최솟값 또는 최댓값을 최적화하는 것이 바람직할 수도 있다.<br/>

3\. 스케줄링 알고리즘(Scheduling Algorithms)
======

&ensp;CPU 스케줄링은 준비 큐에 있는 어느 프로세스에 CPU코어를 할당할 것인지를 결정하는 문제를 다룬다. <br/>

&ensp;1_선입 선처리 스케줄링(First-Come, First_Served Scheduling)<br/>
&ensp;가장 간단한 CPU 스케줄링 알고리즘은 선입 선처리(FCFS)스케줄링 알고리즘이다. 이 방법에서는 CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받는다. 프로세스가 준비 큐에 집입하면 이 프로세스의 프로세스 제어 블록(PCB)을 큐의 끝에 연결한다. CPU가 가용 상태가 되면 준비 큐의 앞부분에 있는 프로세스에 할당된다. 이 실행 상태의 프로세스는 이어 준비 큐에서 제거된다. 부정적인 측면으로 선입 선처리 정책하에서 평균대기 시간은 종종 길 수 있다.<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-4.JPEG" width="600"></p>
&ensp;프로세스들이 p1, p2, p3 순으로 도착하고 선입 선처리 순으로 서비스받는다면 다음의 Gantt차트(참여한 각 프로세스의 시작 시각과 종료 시각을 포함하여 특정 스케줄 기법을 도시하는 막대형 차트)에 보인 결과를 얻는다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-5.JPEG" width="600"></p>

&ensp;프로세스 p1의 대기 시간은 0밀리초이며 프로세스 p2는 24밀리초이고 프로세스 p3은 27밀리초이다. 그러므로 평균대기 시간은 (0 + 24 + 27)/3 = 17밀리초이다. 그러나 프로세스들이 p2, p3, p1 순으로 도착하면 다음 Gantt차트와 같다.<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-6.JPEG" width="600"></p>

&ensp;평균대기 시간은 이제 (6+0+3)/3 = 3밀리초이다. 그러므로 선입 선처리 정책하에서 평균대기 시간은 일반적으로 최소가 아니며 프로세스 CPU 버스트 시간이 크게 변할 경우에는 평균대기 시간도 상당히 변할 수 있다. 모든 다른 프로세스들이 하나의 긴 프로세스가 CPU를 양동하기를 기다리는 것을 호위 효과(convoy effect)라고 한다. 이 효과는 짧은 프로세스들이 먼저 처리되도록 허용될 때보다 CPU와 장치 이용률이 저하되는 결과를 낳는다. 선입 선처리 스케줄링 알고리즘은 비선점형이다. 일단 CPU가 한 프로세스에 할당되면 그 프로세스가 종료하든지 또는 I/O 처리를 요구하든지 하여 CPU를 방출할 때까지 CPU를 점유한다.<br/>

&ensp;2_최단 작업 우선 스케줄링(Shortest-Job-First Scheduling)<br/>
&ensp;CPU 스케줄링의 다른 접근 방법은 최단 작업 우선(shortest-job-first, SJF)알고리즘이다. 이 알고리즘은 각 프로세스에 다음 CPU 버스트 길이를 연관시키다. CPU가 이용 가능해지면 가장 작은 다음 CPU 버스트를 가진 프로세스에 할당한다. 두 프로세스가 동일한 길이의 다음 CPU버스트를 가지면 순위를 정하기 위해 선입 선처리 스케줄링을 적용한다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-7.JPEG" width="600"></p>
<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-8.JPEG" width="600"></p>

&ensp;프로세스 p1의 대기 시간은 3밀리초, 프로세스 p2의 대기 시간은 16밀리초, 프로세스 p3는 9밀리초이고 프로세스 p4는 0초이다. 그러므로 평균대기 시간은 (3 + 16 + 9 + 0)/4 = 7밀리초이다. <br/>

&ensp;SFJ 스케줄링 알고리즘은 주어진 프로세스 집합에 대해 **최소의 평균대기 시간**을 가진다는 점에서 최적임을 증명할 수 있다. 짧은 프로세스를 긴 프로세스 앞으로 이동함으로써 짧은 프로세스의 대기 시간을 긴 프로세스의 대기 시간이 증가하는 것보다 더 많이 줄일 수 있다. SJF 알고리즘이 최적이긴 하지만 다음 CPU 버스트의 길이를 알 방법이 없기 때문에 CPU 스케줄링 수준에서는 구현할 수 없다. 다음 CPU 버스트의 길이를 알 수 없으나 그 값을 예측할 수는 있을 것이다. 우리는 다음 CPU 버스트가 이전의 버스트와 길이가 비슷하다고 기대한다. 그러므로 다음 CPU 버스트 길이의 근삿값을 계산해 가장 짧은 예상 CPU 버스트를 가진 프로세스를 선택한다. <br/>

&ensp;다음 CPU 버스트는 일반적으로 측정된 이전의 CPU 버스트들의 길이를 지수 평균한 것으로 예측한다.  지수 평균을 $ \tau _{n+1} = \alpha t_{n} + (1 - \alpha)\tau _{n}$ <br/> 
$t_{n}$ : n 번째 CPU 버스트의 길이,  $\tau_{n+1}$ : 다음 CPU 버스트에 대한 예측값,  $\tau _{n+1} = \alpha t_{n} + (1 - \alpha)\tau _{n}$.<br/>

&ensp;SJF 알고리즘은 선점형이거나 또는 비선점형일 수 있다. 앞의 프로세스가 실행되는 동안 새로운 프로세스가 준비 큐에 도착하면 선택이 발생한다. 새로운 프로세스가 현재 실행되고 있는 프로세스의 남은 시간보다도 더 짧은 CPU 버스트를 가질 수도 있다. 선점형 SJF 알고리즘은 현재 실행하는 프로세스를 선점할 것이고 반면에 비선점형 SJF 알고리즘은 때때로 최소 잔여 시간 우선(shortest remaining time first)스케줄링이라고 불린다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-9.JPEG" width="600"></p>
<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-10.JPEG" width="600"></p>

&ensp;프로세스 p1은 큐에 있는 유일한 프로세스이므로 시간 0에 시작된다. 프로세스 p2는 시간 1에 도착한다. 프로세스 p1의 남은 시간(7밀리초)이 프로세스 p2가 요구하는 시간(4밀리초)보다 크기 때문에 프로세스 p1이 선점되고 프로세스 p2가 스케줄된다. 평균대기 시간은 [(10-1) + (1-1) + (17-2) + (5-3)]/4 = 26/4 = 6.5밀리초이다. 비선점형 SJF 스케줄링은 평균대기 시간이 7.75밀리초가 될 것이다.<br/>

&ensp;3_라운드 로빈 스케줄링(Round-Robin Scheduling)<br/>

&ensp;라운드 로빈(RR) 스케줄링 알고리즘은 선입 선처리 스케줄링과 유사하지만 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점이 추가된다. 시간 할당량(time quan-tum) 또는 
타임슬라이스(time slice)라고 하는 작은 단위의 시간을 정의한다. 시간 할당량은 일반적으로 10에서 100밀리초 동안이다. 준비 큐는 원형 큐(circular queue)로 동작한다. CPU 스케줄러는 준비 큐를 돌면서 한 번에 한 프로세스에 한 번의 시간 할당량 동안 CPU를 할당한다.<br/>

&ensp;라운드 로빈 스케줄링을 구현하기 위해 다시 준비 큐가 전입선출 큐로 동작하게 만든다. 새로운 프로세스들은 준비 큐의 꼬리에 추가된다. CPU 스케줄러는 준비 큐에서 첫 번째 프로세스를 선택해 한 번의 시간 할당량 이후에 인터럽트를 걸도록 타이머를 설정한 후 프로세스를 디스패치(dispatch)한다. <br/>

&ensp;두가지 중 하나가 발생할 것이다. 첫 번째는 프로세스의 CPU 버스트가 한 번의 시간 할당량보다 작을 수 있다. 이 경우에 프로세스 자신이 CPU를 자발적으로 방출할 것이다. 스케줄러는 그 후 준비 큐에 있는 다음 프로세스로 진행할 것이다. 두 번째는 현재 실행 중인 프로세스의 CPU 버스트가 한 번의 시간 할당량보다 긴 경우로 타이머가 끝나고 운영체제에 인터럽트를 발생할 것이다. 문맥 교환이 일어나고 실행하던 프로세스는 준비 큐의 꼬리에 넣어진다. 그 후 CPU 스케줄러는 준비 큐의 다음 프로세스를 선택할 것이다.<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-11.png" width="600"></p>

&ensp;만일 우리가 시간 할당량을 4밀리초로 한다면 프로세스 P1은 처음의 4밀리초를 사용한다. 이 프로세스는 20밀리초가 더 필요하기 때문에 이 프로세스는 첫 번째 시간 할당량 이후에 선점되고 CPU는 큐에 있는 다음 프로세스인 P2에 할당된다. 프로세스 P2는 4밀리초를 필요로 하지 않기 때문에 시간 할당량이 끝나기 전에 종료된다. CPU는 이어 다음 프로세스인 P3에 할당된다. 일단 각 프로세스가 한 번의 시간 할당량을 받으면 CPU는 다음의 시간 할당량을 프로세스 P1에게 할당한다. 라운드 로빈 스케줄의 결과는 다음과 같다.<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-12.png" width="600"></p>

&ensp;이 스케줄에 따르는 평균 대기 시간을 계산해 보면 P1은 6밀리초(10-4)를 기다리고 P2는 4밀리초, 그리고 P3는 7밀리초를 기다린다. 따라서 평균대기 시간은 17/3 = 5.66밀리초이다. 라운드 로빈 스케줄링 알고리즘에서는 유일하게 실행 가능한 프로세스가 아니라면 연속적으로 두 번 이상의 시간 할당량을 할당받는 프로세스는 없다. <br/>

&ensp;준비 큐에 n개의 프로세스가 있고 시간 할당량이 q이면 각 프로세스는 최대 q시간 단위의 덩어리로 CPU 시간의 1/n을 얻는다. 각 프로세스는 자신의 다음 시간 할당량이 할당될 때까지 (n-1) * q시간 이상을 기다리지 않는다. <br/>

&ensp;RR 알고리즘의 성능은 시간 할당량의 크기에 매우 많은 영향을 받는다. 극단적인 경우 시간 할당량이 매우 크면 RR 정책은 선입 선처리 정책과 같다. 이와 반대로 시간 할당량이 매우 적다면 RR 정책은 매우 많은 문맥 교환을 야기한다. 그러므로 시간 할당량이 문맥 교환 시간과 비교해 더 클 것을 원한다. 문매 교환 시간이 시간 할당량의 10%에 근접한다면 CPU 시간의 약 10%는 문맥 교환에 사용될 것이다.<br/>

&ensp;총처리 시간(turnaround time) 또한 시간 할당량의 크기에 좌우된다. 일반적으로 대부분의 프로세스가 단일 시간 할당량 안에 다음 CPU 버스트를 끝낸다면 평균 총처리 시간은 개선된다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-12.png" width="600"></p>

&ensp;4_우선순의 스케줄링(Priority Scheduling)<br/>

&ensp;SJF 알고리즘은 일반적으로 우선순위 스케줄링 알고리즘의 특별한 경우이다. 우선순위가 각 프로세스들에 연관되어 있으며 CPU는 가장 높은 우선순위를 가진 프로세스에 할당된다. 우선순위가 같은 프로세스들은 선입 선처리(FCFS) 순서로 스케줄된다. SJF 알고리즘은 우선순위(p)가 다음 CPU 버스트의 역인 단순한 우선순위 알고리즘이다. CPU 버스트가 클수록 우선순위가 낮으며 그 역도 성립된다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-14.png" width="600"></p>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-15.png" width="600"></p>

&ensp;우선순위 스케줄링은 선점형이거나 또는 비선점현이 될 수 있다. 프로세스가 준비 큐에 도착하면 새로 도착한 프로세스의 우선순위를 현재 실행 중인 프로세스의 우선순위와 비교한다. 선점형 우선순위 스케줄링 알고리즘은 새로 도착한 프로세스의 우선순위가 현재 실행되는 프로세스의 우선순위보다 높다면 CPU를 선점한다. 비선점형 우선순위 스케줄링 알고리즘은 단순히 준비완료 큐의 머리 부분에 새로운 프로세스를 넣는다. <br/>

&ensp;우선순위 스케줄링 알고리즘의 주요 문제는 무한 봉쇄(indefinite blocking) 또는 기아 상태(starvation)이다. 실행 준비는 되어 있으나 CPU를 사용하지 못하는 프로세스는 CPU를 기다리면서 봉쇄된 것으로 간주할 수 있다. 우선순위 스케줄링 알고리즘을 사용할 경우 낮은 우선순위 프로세스들이 CPU를 무한히 대기하는 경우가 발생한다. <br/>

&ensp;낮은 우선순위의 프로세스들이 무한히 봉쇄되는 문제에 대한 한 가지 해결 방안은 노화(aging)이다. 노화는 오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시킨다. 다른 옵션은 로빈과 우선순위 스케줄링을 결합하는 방법이다. 시스템이 우선 순위가 가장 높은 프로세스를 실행하고 우선순위가 같은 프로세스들은 라운드 로빈 스케줄링을 사용하여 스케줄 하는 방식이다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-16.png" width="600"></p>
<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-17.png" width="600"></p>

&ensp;5_다단계 큐 스케줄링(Multilevel Queue Scheduling)<br/>

&ensp;우선순위와 라운드 로빈 스케줄링을 사용할 때 모든 프로세스가 단일 큐에 배치되고 스케줄러는 우선순위가 가장 높은 프로세스를 선택하여 실행시킬 수 있다. 큐가 관리되는 방식에 따라 우선순위가 가장 높은 프로세스를 결정하기 위해 O(n) 검색이 필요할 수 있다. 실제로 우선순위마다 별도의 큐를 갖는 것이 더 쉬운 때도 있으며 우선순위 스케줄링은 우선순위가 가장 높은 큐에서 프로세스를 스케줄한다.<br/>

&ensp;다단계 큐는 우선순위 스케줄링이 라운드 로빈과 결합한 경우에 효과적이다. 우선순위가 가장 높은 큐에 여러 프로세스가 있는 경우 라운드 로빈 순서로 실행된다. 이 방식의 가장 일반적인 형태에서 우선순위가 각 프로세스에 정적으로 할당되며 프로세스는 실행시간 동안 동일한 큐에 남아 있다.<br/>

&ensp;프로세스 유형에 따라 프로세스를 여러 개의 개별 큐로 분할하기 위해 다단계 큐 스케줄링 알고리즘을 사용할 수 있다. 흔히 포그라운드(대화형) 프로세스와 백그라운드(배치) 프로세스를 구분한다. 이 두 가지 유형의 프로세스는 응답 시간 요구 사항이 다르므로 스케줄링 요구 상항이 다를 수 있다. 또한 포그라운드 프로세스는 백그라운드 프로세스보다 우선순위를 가질 수 있다. 포그라운드 및 백그라운드 프로세스에 별도의 큐가 사용될 수 있으며 각 큐에는 자체 스케줄링 알고리즘이 있을 수 있다. 큐와 큐 사이에 스케줄링도 반드시 있어야 하며 일반적으로 고정 우선순위의 선점형 스케줄링으로 구현된다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-18.png" width="600"></p>

&ensp;6_다단계 피드백 큐 스케줄링(Multilevel Feedback Queue Scheduling)<br/>

&ensp;다단계 큐 스케줄링 알고리즘에서는 일반적으로 프로세스들이 시스템 진입 시에 영구적으로 하나의 큐에 할당된다. 대조적으로 다단계 피드백 큐 스케줄링 알고리즘에서는 프로세스가 큐들 사이를 이동하는 것을 허용한다. 어떤 프로세스가 CPU 시간을 너무 많이 사용하면 낮은 우선순위의 큐로 이동된다. 이 방법에서는 I/O 중심의 프로세스와 대화형 프로세스들을 높은 우선순위의 큐에 넣는다. 낮은 우선순위의 큐에서 너무 오래 대기하는 프로세스는 높은 우선순위의 큐로 이동할 수 있다. 이러한 노화 형태는 기아 상태를 예방한다.<br/>

&ensp;다단계 피드백 큐 스케줄러는 다음의 매개변수에 의해 정의된다. <br/>
* 큐의 개수<br/>
* 각 큐를 위한 스케줄링 알고리즘<br/>
* 한 프로세스를 높은 우선순위 큐로 올려주는 시기를 결정하는 방법<br/>
* 한 프로세스를 낮은 우선순위 큐로 강등시키는 시기를 결정하는 방법<br/>
* 프로세스에 서비스가 필요할 때 프로세스가 들어갈 큐를 결정하는 방법<br/>


4\. 스레드 스케줄링(Thread Scheduling)
======

&ensp;1_경쟁 범위(Contention Scope)<br/>

&ensp;동일한 프로세스에 속한 스레드들 사이에서 CPU를 경쟁하기 때문에 프로세스-경쟁-범위(process-contention scope, PCS)로 알려져 있다. CPU상에 어느 커널 스레드를 스케줄 할 것인지 결정하기 위해서 커널은 시스템-경쟁 범위(system-contention scope, SCS)를 사용한다. SCS 스케줄링에서의 CPU에 대한 경쟁은 시스템상의 모든 스레드 사이에서 일어난다.<br/>

&ensp;전형적으로 PCS는 우선순위에 따라 행해진다. 즉 스케줄러는 가장 높은 우선순위를 가진 실행 가능한 프로세스를 선택한다. 사용자 수준 스레드의 우선순위는 프로그래머에 의해 지정되고 스레드 라이브러리에 의해 조정되지 않는다. <br/>

&ensp;2_Pthread 스케줄링(Pthread Scheduling)<br/>

&ensp;스레드를 생성하면서 PCS 또는 SCS를 지정할 수 있는 POSIX Pthreads API를 강조한다. Pthreads는 다음과 같은 범위 값을 구분한다.<br/>
* PTHREAD SCORE PROCESS는 PCS 스케줄링을 사용하여 스레드를 스케줄한다. <br/>
* PTHREAD SCOPE SYSTEM은 SCS 스케줄링을 사용하여 스레드를 스케줄한다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-19.png" width="600"></p>

&ensp;다중 처리기 스케줄링(Myltiple-Processor Scheduling)<br/>

&ensp;CPU가 여러 개인 경우 병행 제어를 해야하기 때문에 스케줄링 더욱 복잡해진다.<br/>
* Homogeneous processor : Queue에 한 줄로 세워서 각 프로세서가 알아서 꺼내가게 할 수 있다.<br/>
* Asymmetric multiprocessing : 하나의 프로세서가 시스템 데이터의 접근과 공유를 책임진다.<br/>
* Symmetric multiprocessing : 각 프로세서가 각자 알아서 스케줄링 결정<br/>
* Processor affinity : 프로세스는  현재 실행 중인 프로세서에 대해 affinity를 가진다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-20.JPEG" width="600"></p>

&ensp;각각 고유한 CPU와 로컬 메모리를 가진 두 개의 물리적 프로세서 칩이 있는 NUMA를 특징으로 하는 아키텍처를 보여준다. 시스템 연결망을 통해 NUMA 시스템의 모든 CPU가 하나의 물리적 주소 공간을 공유할 수 있지만 CPU는 다른 CPU의 로컬 메오리보다 자신의 로컬 메모리에 더 빠르게 액세스 할 수 있다. 운영체제의 CPU 스케줄러 및 메모리 배치 알고리즘이 NUMA를 인식하고 협력하는 경우 특정 CPU에 스케줄 된 스레드를 CPU가 있는 위치에 가장 가까운 메모리에 할당하ㅕ 가능한 가장 빠른 메모리 액세스를 제공할 수 있다.<br/>

5\. 다중 처리기 스케줄링(Multiple-Processor Scheduling)
======

&ensp;여러 개의 CPU가 사용 가능하다면 여러 스레드가 병렬로 실행될 수 있으므로 부하 공유(load sharing)가 가능해진다. 다중 처리기는 여러 개의 물리적 프로세서를 제공하는 시스템을 말하며 각 프로세서에는 하나의 단일 코어 CPU가 포함되어 있다. <br/>
* 다중 코어 CPU<br/>
* 다중 스레드 코어<br/>
* NUMA 시스템<br/>
* 이기종 다중처리<br/>

&ensp;1_다중 처리기 스케줄링에 대한 접근 방법<br/>

&ensp;다중 처리기 시스템의 CPU 스케줄링에 관한 한 가지 해결 방법은 마스터 서버(master server)라는 하나의 처리기가 모든 스케줄링 결정과 I/O 처리 그리고 다른 시스템 활동을 취급하게 하는 것이다. <br/>
&ensp;비대칭 다중 처리(asymmetric multiprocessing)는 오직 하나의 코어만 시스템 자료구조에 접근하여 자료 공유의 필요성을 배제하기 때문에 간단하다. 다중 처리기를 지원하기 위한 표준 접근 방식은 대칭 다중 처리(SMP)이며 각 프로세서는 스스로 스케줄링 할 수 있다. <br/>

&ensp;2_다중 코어 프로세서(Multicore Processors)<br/>

&ensp;SMP 시스템은 다수의 물리 처리기를 제공함으로써 다수의 프로세스가 병렬로 실행되게 한다. 그러나 현대 컴퓨터 하드웨어는 물리적인 칩 안에 여러 개의 처리코어를 장착하여 다중 코어 프로세서(multicore processor)가 된다. 다중 코어 프로세서를 사용하는 SMP 시스템은 각 CPU가 자신의 물리 칩을 가지는 시스템과 비교해 속도가 빠르고 적은 전력을 소모한다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-21.JPEG" width="600"></p>

&ensp;메모리 스톨(memory stall)이 라고 하는 이 상황은 최신 프로세서가 메모리보다 훨씬 빠른 속도로 작동하기 때문에 주로 발행한다. 그러나 캐시 미스(캐시 메모리에 없는 데이터를 액세스)로 인해 메모리 스톨이 발행할 수도 있다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-22.JPEG" width="600"></p>

&ensp;최근 많은 하드웨어 설계는 다중 스레드 처리 코어를 구현하였다. 이러한 설계에서 하나의 코어에 2개 이상의 하드웨어 스레드가 할당된다. 이렇게 하면 메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면 코어가 다른 스레드로 전환할 수 있다. Intel 프로세스는 단일 하드웨어 코어에 여러 하드웨어 스레드를 할당하는 것을 설명하기 위하여 하이퍼-스레딩(동시 다중 스레딩 또는 SMT)이라는 용어를 사용한다.<br/>

&ensp;3_부하 균등화(Load Balancing)<br/>

&ensp;SMP 시스템에서 처리기가 하나 이상이라는 것을 최대한 활용하려면 부하를 모든 처리기에 균등하게 배분하는 것이 매우 중요하다. **부하 균등화(load balancing)**는 SMP 시스템 모든 처리기 사이에 부하가 고르게 배분되도록 시도한다. 부하 균등화는 통상 각 처리기가 실행할 스레드를 위한 자기 자신마느이 준비 큐를 가지고 있는 시스템에서만 필요한 기능이라는 것을 주의해야 한다. <br/>
&ensp;부하 균등화를 위해서는 **push migration**와 **pull migration**방식의 두 가지 일반적인 접근법이 있다. **push migration**에서는 특정 태스크가 쥐적으로 각 처리기의 부하를 검사하고 만일 불균형 상태로 밝혀지면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 스레드를 이동(또는 push)시킴으로써 부하를 분배한다. **pull migration** 방식은 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 pull할 때 일어난다. push와 pull 이주는 상호 배타적일 필요는 없으며 실제로는 부하 균등화 시스템에서 종종 병렬적으로 구현된다.<br/>

6\. 실시간 CPU 스케줄링(Real-Time CPU Scheduling)
======

&ensp;일반적으로 soft real-time systems와 hard real-time systems으로 구분한다. **soft real-time systems**은 중요한 실시간 프로세스가 스케줄 되는 시점에 관해 아무런 보장을 하지 않는다. soft real-time systems은 오직 중요 프로세스가 그렇지 않은 프로세스들에 비해 우선권을 가진다는 것만 보장한다.  **hard real-time systems**은 엄격한 요구 조건을 만족시켜야 한다. 태스크는 반드시 마감시간까지 서비스를 받아야 하며 마감시간이 지난 이후에 서비스를 받는 것은 서비스를 전혀 받지 않는 것과 동일한 결과를 낳는다. <br/>

&ensp;1_지연시간 최소화(Minimizing Latency)<br/>

&ensp;시스템은 일반적으로 실시간으로 발생하는 이벤트를 기다린다. 이벤트는 타이머가 만료되었을 때처럼 소프트웨어적으로 발생하기도 하고 원격으로 제어되던 장치가 방해물을 만났을 때와 같이 하드웨어적으로 발생하기도 한다. 이벤트가 발생하면 시스템은 가능한 빨리 그에 응답을 하고 그에 맞는 동작을 수행하여야 한다. 이벤트 지연시간은 이벤트가 발생하여 그에 맞는 서비스가 수행될 때까지의 시간을 말한다.<br/>
&ensp;1. Interrupt latency - CPU에 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 시작하기까지의 시간을 말한다. 인터럽트가 발생하면 운영체제는 우선 수행 중인 명령어를 완수하고 발생한 인터럽트의 종류를 결정한다. 해당 인터럽트 서비스 루틴(ISR)을 사용하여 인터럽트를 처리하기 전에 현재 수행 중인 프로세스의 상태를 저장해 놓아야만 한다. 이러한 작업을 모두 수행하는 데 걸리는 시간이 인터럽트 지연시간이다. <br/>
&ensp;2. dispatch latency - 스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는 데까지 걸리는 시간을 말한다. CPU를 즉시 사용해야 하는 실시간 태스크가 있다면 실시간 운영체제는 이 지연 시간을 최소화해야 한다. 디스패치 지연시간을 최소화하는 가장 효과적인 방법은 선점형 커널이다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-23.png" width="600"></p>

&ensp;디스패치 지연시간의 충돌 단계는 두 가지 요소로 구성된다. <br/>
&ensp;1. 커널에서 동작하는 프로세스에 대한 선점<br/>
&ensp;2. 높은 우선순위의 프로세스가 필요한 자원을 낮은 우선순위 프로세스 자원이 방출<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-24.png" width="600"></p>

&ensp;2_우선순위 기반 스케줄링(Priority-Based Scheduling)<br/>

&ensp;실시간 운영체제에서 가장 중요한 기능은 실시간 프로세스에 CPU가 필요할 때 바로 응답을 해주는 것이다. 따라서 실시간 운영체제의 스케줄러는 선점을 이용한 우선순위 기반의 알고리즘을 지원해야만 한다. 우선순위 기반의 스케줄링 알고리즘은 각각의 프로세스의 중요성에 따라서 그 우선순위를 부여한다. <br/>
&ensp;그러나 선점 및 우선순위 기반의 스케줄러를 제공하는 것은 단지 soft real-time 기능을 제공하는 것에 불과하다. hard real-time system에서는 실시간 태스크가 마감시간 내에 확실히 수행되는 것을 보장해야만 하며 그렇기 때문에 부가적인 스케줄링 기법이 필요하다. <br/>
&ensp;프로세스들은 새로운 특성들을 가진다. 첫 번째 프로세스들은 주기적이다. 즉 프로세스들은 일정한 간격으로 CPU가 필요하다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-25.JPEG" width="600"></p>

&ensp;3_Rate-Monotonic Scheduling<br/>

&ensp;Rate-monotonic 스케줄링 알고리즘은 선점 가능한 정적 우선순위 정책을 이용하여 주기 태스크들을 스케줄한다. 낮은 우선순위의 프로세스가 실행 중이고 높은 우선순위의 프로세스가 실행 준비가 되면 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스를 선점한다. 주기가 짧은 태스크는 높은 우선순위가 주기가 길면 낮은 우선순위가 배정된다. <br/>
&ensp;Rate-monotonic 스케줄링 기법이 스케줄 할 수 없는 프로세스 집합의 경우 정적 우선순위를 이용하는 다른 알고리즘들 역시 스케줄 할 수 없는 측면에서 최적(optimal)이라고 할 수 있다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-26.JPEG" width="600"></p>

&ensp;Rate-monotonic 스케줄링 기법은 최적이기는 하지만 많은 제약이 있다. CPU 이용률은 한계가 있기 때문에 CPU 자원을 최대화해서 사용하는 것은 불가능하다.<br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-27.JPEG" width="600"></p>

&ensp;4_Earliest-Deadline-First 스케줄링<br/>

&ensp;Earliest-deadline-first(EDF) 스케줄링 기법은 마감시간에 따라서 우선순위를 동적으로 부여한다. 마감시간이 빠를수록 우선순위는 높아지고 늦을수록 낮아진다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-28.png" width="600"></p>

&ensp;Rate-montonic 알고리즘과는 달리 EDF 스케줄링 알고리즘은 프로세스들이 주기적일 필요도 없고 CPU 할당 시간도 상수 값으로 정해질 필요가 없다. 그러나 프로세스가 실행가능해질 때 자신의 마감시간을 스케줄러에게 알려주어야 한다. EDF가 매력적인 이유는 이론적으로 최적이라는 것이다. 이론적으로 모든 프로세스가 마감시간을 만족시키도록 스케줄할 수 있고 CPU 이용률 역시 100%가 될 수 있다. 그러나 실제로 프로세스 사이 또는 인터럽트 핸들링 때의 문맥 교환 비용 때문에 100%의 CPU 이용률은 불가능하다.<br/>

&ensp;5_일정한 비율의 몫 스케줄링(Proportion Share Scheduling)<br/>

&ensp;proportional share 스케줄러는 모든 응용들에 T개의 시간 몫을 할당하여 동작한다. 한 개의 응용이 N개의 시간 몫을 할당받으면 그 응용은 모든 프로세스 시간 중 N/T 시간을 할당받게 된다. 

* Lottery Scheduling
  - 각 프로세스에 일정 수의 복권 티켓을 부여하고 랜덤하게 티켓 하나를 뽑아서 해당 티켓을 가진 프로세스에게 CPU를 할당한다.
  - 티켓이 많을수록 CPU를 더 자주 받을 확률이 높다.
  - 확률 기반 스케줄링

* Stride Scheduling
  - 각 프로세스에 stride를 할당한다.
  - 보폭은 큰 수 / 티켓 수로 계산(티켓이 많을수록 보폭이 작음)
  - pass 값을 누적해가며 가장 pass 값이 작은 프로세스에게 CPU를 할당하고 그 프로세스는 pass += stride
  - 스케줄러는 가장 많은 pass값을 가진 프로세스를 선택

 
* virtual time scheduling
  - virtual time은 현실 시간이 아니라 각 프로세스가 얼마나 정당하게 CPU를 사용하고 있는지를 추적하기 위해 사용하는 논리적 시간이다. 
  - 모든 프로세스에 동일한 실행 기회를 주는 것처럼 동작하도록 CPU 시간을 할당
  - 각 프로세스는 자신이 사용한 시간만큼 가상 시간을 누적
  - 가상 시간이 가장 작은 프로세스가 CPU를 우선적으로 할당
  -  CFS (Linux의 기본 스케줄러)는 이 개념을 사용해서 "누가 얼마나 공정하게 실행되었는가"를 판단

&ensp;6_POSIX 실시간 스케줄링(POSIX Real-Time Scheduling)<br/>

&ensp;POSIX는 실시간 컴퓨터용으로 POSIX.1b라는 확장을 제공한다. <br/>
* SCHED_FIFO : FIFO 큐를 사용하여 먼저 온 것을 먼저 서비스하는 정책에 따라서 스레드를 스케줄한다. 따라서 FIFO 큐의 앞에 있는 가장 높은 우선순위의 실시간 스레드는 종료되거나 블록(block)될 때까지 CPU를 할당받는다. 
* SCHED_RP : 라운드 로빈 정책을 사용하며 같은 우선순위의 스레드에 시간 할당량을 제공하는 것을 제외하면 SCHED_FIFO와 비슷하다. 

&ensp;POSIX API는 스케줄링 정책에 관한 정보를 지정하고 얻어내는 다음과 같은 두 개의 함수를 제공한다.<br/>
* pthread_attr_get schedpoli cy(pthread_attr _t *attr , int *policy) 
* pthread_attr _set schedpoli cy (pthread_attr _t *attr , int policy) 

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-29.png" width="600"></p>

7\. 운영체제 사례들
======

&ensp;1_Linux 스케줄링<br/>

&ensp;버전 2.5전까지는 전통적인 UNIX 스케줄링 알고리즘의 변형을 사용하였다. 버전 2.5에서 이 스케줄러는 철저하게 분석, 수정되어 시스템에 존재하는 태스크 개수와 상관없이 항상 상수 시간에 실행되는 O(1)이라고 알려진 스케줄링 알고리즘을 포함되었다. <br/>
&ensp;Linux 스케줄러는 각 클래스별로 특정 우선순위를 부여받는 스케줄링 클래스에 기반을 두고 동작한다. 다른 스케줄링 클래스를 사용하여 시스템과 프로세스의 요구 조건에 따라 커널은 다른 스케줄링 알고리즘을 수용할 수 있다. 다음에 실행될 태스크를 결정하기 위해 스케줄러는 높은 우선순위 클래스에 속한 가장 높은 우선순위의 태스크를 선택한다. 표준 Linux 커널은 (1) CFS 스케줄링 알고리즘을 사용하는 디폴트 스케줄링 클래스와 (2) 실시간 스케줄링 클래스의 두 스케줄링 클래스를 구현한다. <br/>
&ensp;CFS 스케줄러는 상대 우선순위에 상응하는 시간 할당량의 길이가 정해져 있는 경직된 규칙을 사용하지 않고 각 태스크에 CPU 처리시간의 비율을 할당한다. 이 비율은 각 태스크에 할당된 nice 값에 기반을 두고 계산된다. 적은 nice 값의 태스크는 높은 nice 값의 태스크보다 더 큰 비율의 CPU 처리시간을 할당받는다. Nice 값은 0을 디폴트 값으로 가진다. CFS는 이산 값을 가지는 시간 할당량을 사용하지 않고 대신에 목적 지연시간(targeted latency)을 찾는다. 목적 지연시간은 다른 모든 수행 가능한 태스크가 적어도 한 번씩은 실행할 수 있는 시간 간격을 나타낸다. CPU 시가느이 비율은 이 목적 지연시간의 값으로부터 할당된다.<br/>
&ensp;CFS는 직접 우선순위를 할당하지 않는다. 그보다 CFS는 각 태스크별로 vruntime이라는 변수에 태스크가 실행된 시간을 기록하여 가상 실행 시간을 유지한다. 이 가상실행 시간은 태스크의 우선순위에 기반을 둔 감쇠 지수(decay factor)와 관련된다. 낮은 우선순위 태스크는 높은 우선순위 태스크보다 감쇠율이 높다. 보통 우선순위의 태스크의 경우 가상 실행 시간은 실제 물리적 실행 시간과 같다. 다음에 실행될 태스크를 선택하려면 스케줄러는 단순히 가장 작은 vruntime 값을 가진 태스크를 선택한다. 게다가 실행할 수 있게된 높은 우선순위 태스크는 낮은 우선순위 태스크를 선점할 수 있다.<br/>

&ensp;또한 Linux는 POSIX 표준을 사용하여 실시간 스케줄링을 구현한다. SCHED_FIFO 또는 SCHED_RR 실시간 정책을 사용하여 스케줄된 태스크는 보통의 태스크보다 높은 우선순위를 받고 실행된다. Linux는 실시간 태스크에 할당해주는 우선순위 영역과 보통의 태스크에 할당해주는 영역 등 두 개의 별도 영역을 사용한다. 보통 태스크들은 nice 값에 기반을 둔 우선순위가 할당되는데 -20은 우선순위 100에 +19는 139에 사상된다. <br>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-30.png" width="600"></p>


&ensp;2_Windows 스케줄링<br/>

&ensp;windows는 우선순위에 기반을 둔 선점 스케줄링 알고리즘을 사용한다. Windows 스케줄러는 가장 높은 우선순위의 스레드가 항상 실행되도록 보장한다. Windows커널 중 스케줄링을 담당하는 부분을 디스패치(dispatcher)라고 부른다. 디스패처에 의해 선택된 스레드는 높은 우선순위 스레드에 의해 선점되든지, 연산이 다 끝나든지, 시간 할당량이 만료되든지, 입출력을 위한 것과 같은 봉쇄를 일으키는 시스템 콜을 호출할 때까지 실행된다. 우선순위가 낮은 스레드가 실행 중에 우선순위가 높은 실시간 스레드가 준비 상태가 되면 우선순위가 낮은 스레드는 선점된다. 이와 같은 선점은 필요한 경우에 실시간 스레드가 CPU를 액세스 할 수 있는 우선권을 준다. <br/>
&ensp;디스패처는 스레드의 실행 순서를 정하기 위하여 32단계의 우선순위를 두고 있다. 우선순위는 두 클래스로 구분된다. variable class에 있는 스레드들은 우선순위가 1부터 15까지 이다. 실시간 클래스는 우선순위 16부터 31까지의 스레드를 포함한다. 디스패처는 각 우선순위를 위하여 큐를 사용하고 이들 큐를 높은 우선순위부터 낮은 우선순위까지 조사하면서 준비 상태의 스레드가 있는지를 본다. 준비 상태에 있는 스레드가 없으면 디스패처는 idle 스레드라고 불리는 특수한 스레드를 실행시킨다. <br/>
&ensp;Windows API는 프로세스들이 속할 수 있는 6가지 우선순위 클래스를 제공한다.(IDLE PRIORITY CLASS, BELOW NORMAL PRIORITY CLASS, NORMAL PRIORITY CLASS, ABOVE NORMAL PRIORITY CLASS, HIGH PRIORITY CLASS, REALTIME PRIORITY CLASS) 프로세스는 통상  NORMAL_PRIORITY_CLASS에 속한다. 부모 프로세스가  IDLE PRIORITY_CLASS에 속하지 않고 프로세스가 생성될 때 다른 클래스가 명시되지 않는 한 프로세스는 이 클래스에 속하게 된다. 각 스레드의 우선순위는 그 스레드가 속한 우선순위 클래스와 그 클래스 안에서의 상대적인 우선순위에 기반을 둔다. 각 스레드는 스레드가 속한 클래스의 우선순위 범위 안의 값을 기본 우선순위로 배정받는다. 각 클래스의 디폴트 기본 우선순위는 그 클래스의 NORMAL에 해당하는 상대적인 우선순위를 따른다. <br/>

<p align="center"><img src="/assets/img/Operating System/5. CPU Scheduling/5-31.png" width="600"></p>

&ensp; Windows는 현재 화면에서 선택된 포그라운드 프로세스와 현재 선택되지 않은 백그라운드 프로세스를 구분한댜 Windows는 프로세스가 포그라운드 프로세스가 되면 시간 할당량을 보통 3배정도 증가시킨다. <br/>
&ensp;Windows 7은 사용자 모드 스케줄링(user-mode scheduling, UMS)을 도입하였는데, 응용 프로그램이 커널과는 독립적으로 스레드를 생성하고 관리할 수 있게 한다. 따라서 응용은 Windows 커널 스케줄러의 도움 없이 여러 스레드를 생성하고 스케줄 할 수 있다. 매우 많은 스레드를 생성하는 웅용의 경우 사용자 모드에서 스레드를 스케줄 하면 커널의 개입이 필요하지 않기 때문에 커널 모드 스레드 스케줄링을 이용할 때보다 훨씬 효율적이다.<br/>
&ensp;UMS는 프로그래머가 직접 사용하는 것을 염두에 두지 않고 설계되었댜 사용자 모드 스케줄러를 작성하는 것은 매우 힘든 작업이고 UMS는 그러한 스케줄러를 가지고 있지 않다. 오히려 UMS 위에 구축된 프로그래밍 언어 라이브러리들을 이용하여 스케줄러를 만들 수 있다. 예를 들어, Microsoft는 태스크 기반 병렬성을 제공하기 위해 설계된 C++를 위한 병행 프로그래밍 프레임워크인 Concurrency Runtime (ConRT)를 제공한댜 ConRT는 프로그램을 분해하여 처리기 코어에서 스케줄 될 수 있는 태스크롤 분해하는 설비와 함께 스케줄러를 제공한다. <br/>

















