---
title: "Chapter 10. Virtual Memory"
excerpt: ""

wirter: sohee kim
categories:
  - Operating System
tags:
  - operating system

toc: true
use_math: true
toc_sticky: true
  
date: 2025-05-21
last_modified_at: 2025-05-21
---

1\. 배경
=======

&ensp;코드는 메모리에 있어야 실행될 수 있지만, 전체 프로그램이 항상 동시에 필요하지는 않는다. <br/>
* 일부 코드(예. 에러 처리, 비정상 루틴 등)만 사용될 수 있다.
* 그래서 프로그램 전체를 한꺼번에 메모리에 올릴 필요가 없다. 
* 부분적으로 로드된 프로그램 실행이 가능하다.

&ensp;그에 인한 효과<br/>
* 물리적 메모리의 제한에 덜 구속된다.
* 각 프로그램이 메모리를 적게 차지 → 더 많은 프로그램을 동시에 실행 가능하다.
* I/O 작업 감소 → 프로그램을 메모리에 로드하거나 스왑할 필요 줄어든다. 
* CPU 활용률 증가.

virtual Memory
------

&ensp;사용자 논리 주소 공간(logical memory space)을 물리 주소 공간(physical memory)과 분리하여 더 유연하게 메모리를 사용하는 방식이다. 

* 이점
    - 프로그램의 일부만 메모리에 있어도 실행 가능.
    - 논리 주소 공간은 물리 주소 공간보다 훨씬 클 수 있음 (예: 64비트 시스템에서 2^64까지).
    - 주소 공간 공유 가능: 여러 프로세스가 코드 영역 등을 공유할 수 있음.
    - 프로세스 생성 효율 향상: 복사보다 매핑이 빠름.
    - 동시 실행 프로그램 수 증가
    - I/O 감소: 로딩과 스왑 빈도 증가


Virtual Address Space
------

&ensp;논리적인 주소 공간으로 프로세스가 메모리를 바라보는 방식이다.<br/>

* 구성
  - 보통 0번 주소부터 연속된 공간으로 시작(실제로는 페이지 단위로 관리)
  - 물리 메모리는 페이지 프레임(frame) 단위로 나뉘며 MMU가 논리 주소를 물리 주소로 변환

* 가상 메모리 구현 방식
  - **Demand Paging(요구 페이징)**
    + 실제로 필요한 페이지만 로드하는 방식
    + 처음에는 아무것도 메모리에 올리지 않는다.
    + 접근이 발생할 때 페이지 폴트(Page Fault)가 발생하면 그때서야 디스크에서 해당 페이지를 로드한다. 

* 예시
&ensp;한 프로그램이 1GB이고, 실제 자주 사용하는 부분은 100MB라고 해보죠.

* 기존 방식
  - 1GB 전체를 메모리에 올려야 실행됨.

* 가상 메모리 + 요구페이징
  - 100MB만 먼저 로드됨.
  - 나머지 900MB는 필요할 때만 점진적으로 로드됨.


Virtual Memory Larger Than Physical Memory
------

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-1.png" width="600"></p>

&ensp;구성 요소 설명:<br/>
1. Virtual Memory
* page 0 ~ page v까지 존재하는 가상 메모리의 페이지들이다.
* 각 프로세스는 자신만의 가상 주소 공간을 갖고 있으며, 마치 연속적인 메모리를 쓰는 것처럼 프로그래밍할 수 있다.

2. Memory Map
* 페이지 테이블 또는 매핑 테이블을 의미한다.
* 가상 페이지를 실제 물리 메모리의 어떤 프레임에 매핑할지를 기록해둔 정보이다.
* 예를 들어, page 2 → 물리 메모리의 두 번째 칸으로 매핑됨을 의미한다.

3. Physical Memory
* 실제 컴퓨터의 RAM을 의미한다.
* 크기가 제한되어 있어 모든 가상 페이지를 동시에 담을 수는 없다.
* 자주 쓰는 페이지들만 올라와 있으며, 나머지는 디스크에 보관된다.

4. 디스크/보조 저장소
* 스왑 영역(swap area) 혹은 **백킹 스토어(backing store)**이다.
* 물리 메모리에 없는 가상 페이지들은 여기 저장되어 있다가 필요한 시점에 다시 메모리로 로드된다.

&ensp;동작흐름<br/>
1. 프로세스가 어떤 가상 주소에 접근함.
2. **Memory Map(페이지 테이블)**을 참조하여 해당 주소가 물리 메모리에 존재하는지 확인.
3. 존재하면 바로 접근.
4. 없으면 디스크에서 해당 페이지를 읽어와 물리 메모리에 올림 → 이를 Page Fault라 함.
5. 물리 메모리가 가득 차면 오래된 페이지를 디스크로 내보내고 새로운 페이지를 로드함 (페이지 교체 알고리즘 사용).

&ensp;예시
* 물리 메모리 크기: 4GB
* 가상 메모리 크기: 16GB
* -> 실제 4GB RAM으로 여러 개의 2~3GB급 프로그램을 동시에 실행 가능함.


Virtual-address Space
------

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-4.png" width="600"></p>

&ensp;가상 주소 공간은 프로세스가 자신만의 주소 공간을 갖는 구조로 물리 메모리와는 독립적이다.<br/>

&ensp;📐구성 및 동작 구조<br/>

* 0번 주소부터 위로:
1. code: 프로그램의 실행 코드(텍스트 영역)
2. data: 전역 변수와 static 변수.
3. heap: 동적 메모리 영역 (malloc, new 등) -> 위쪽 방향으로 증가(grows up)

* Max 주소부터 아래로:
4. stack: 함수 호출 시 지역 변수와 리턴 주소 저장. -> 아래쪽 방향으로 감소 (grows down).

&ensp;📌중간의 비어 있는 부분 (hole)<br/>
* Heap과 Stack 사이에는 비어 있는 공간이 존재
* 이는 각 영역이 동적으로 확장될 수 있도록 여유를 둔 것이다.
* 이 비어 있는 공간은 프로그램 실행 중 점점 채워질 수 있다.

&ensp;🔧 기술적 이점<br/>
1. 최대 주소 공간 활용 (Maximizes address space use)
* 서로 반대 방향으로 커지기 때문에, 전체 주소 공간을 효율적으로 활용할 수 있다.

2. Sparse Address Space (희소한 주소 공간)
* 주소 공간 중 일부를 사용하지 않음으로써 "구멍(hole)"이 생기는데, 이 덕분에 동적으로 링크된 라이브러리 등을 중간에 삽입 가능하게 만든다.

3. System Libraries 공유
* OS는 system library를 여러 프로세스가 공유된 가상 주소에 매핑함으로써 메모리 절약을 실현한다.

4. Shared Memory
* 서로 다른 프로세스 간 데이터를 공유할 때, 특정 페이지를 서로 다른 가상 주소 공간에 읽기/쓰기 가능하게 매핑할 수 있다.

5. fork() 최적화
* 자식 프로세스를 생성할 때, 가상 주소 공간을 복사하는 대신 공유(예: copy-on-write)하여 빠르게 생성 가능하게 하다.

Shard Library Using Virual Memory
------

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-2.png" width="600"></p>

&ensp;💡프로세스란?
* 컴퓨터에서 프로그램이 실행되면, 프로세스라는 단위로 메모리 공간이 만들어진다. 
* 이 프로세스는 코드, 데이터, 힙(Heap), 스택(Stack) 공간을 따로 가진다.

&ensp;💡라이브러리란?
* 자주 쓰는 기능(예: printf(), scanf())을 모아둔 코드 파일이다.
* 여러 프로그램에서 이 코드를 매번 복사해서 쓸 필요 없이, 한 번만 메모리에 올려서 여러 프로세스가 공유하면 효율적이다.

&ensp;왼쪽과 오른쪽에 있는 건 두 개의 다른 프로세스이다.
* 각 프로세스는 아래와 같이 생긴 자기만의 메모리 공간을 가지고 있다.
  - code (내 코드)
  - data (내 변수들)
  - heap (내가 동적으로 만드는 데이터)
  - stack (함수 호출 시 쌓이는 공간)

&ensp;🔁‘shared library’는?<br/>
* shared library는 여러 프로세스가 같은 코드를 공유해서 쓰는 라이브러리
* 이 부분은 중간에 있는 파란색 shared pages라는 공간을 통해 같은 메모리를 나눠서 사용

&ensp;🔄 왜 이렇게 하나요?<br/>
* ✅ 메모리 절약
  - 예를 들어 100개의 프로그램이 printf()를 쓴다고 가정할게요.
  - 매번 그 코드를 복사해서 100번 넣으면 메모리 낭비가 심해요.
  - 한 번만 메모리에 올려두고, 모든 프로세스가 그걸 함께 사용하면 메모리를 아낄 수 있어요!
* ✅ 속도 향상
   - 불필요한 코드 중복이 없어서 프로그램을 더 빠르게 시작할 수 있다.

* 왼쪽과 오른쪽 프로세스는 각각의 stack, heap, data, code를 가지고 있다.
* 하지만 shared library 부분은 **서로 연결돼서 같은 페이지(shared pages)**를 사용 중이다. 
  - 마치 둘이 공동 책상에 있는 사전 하나를 같이 보는 것과 같다.

&ensp;📌 정리
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-3.png" width="600"></p>


2\. 요구 페이징(Demand Paging)
======
&ensp;📦 Demand Paging (요구 페이징)이란?
* 개념 요약: 필요할 때만 메모리에 페이지를 불러오는 방식
* 쉽게 말하면?: 컴퓨터에서 프로그램 전체를 한 번에 메모리에 올리지 않고, 진짜 필요한 부분만 그때그때 메모리에 불러오는 방식

&ensp;🖼 그림 설명<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-7.png" width="600"></p>

* 왼쪽 회색 박스 = 메인 메모리 (RAM)
  - 프로그램 A와 B가 메모리에 올라가 있는 상태야.
* 오른쪽 파란 박스 = 디스크 (하드디스크나 SSD처럼 느린 저장공간)
  - 프로그램의 나머지 부분이 저장되어 있다.
* 어떤 페이지(예: 프로그램 A의 3번 페이지)가 필요 없어지면 → 디스크로 "swap out" (내려보내기)
* 나중에 프로그램 B가 어떤 페이지를 필요로 하면 → 디스크에서 "swap in" (불러오기)

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-5.png" width="600"></p>

&ensp;📌 작동 방식 (간단한 흐름)
1. 프로그램이 실행되다가 어떤 페이지가 필요해졌어!
2. 근데 그 페이지가 아직 메모리에 없어!
3. 👉 그래서 페이지 폴트(Page Fault) 발생
4. 운영체제가 디스크에서 필요한 페이지만 메모리로 가져와 (swap in)
5. 그리고 프로그램은 계속 실행해

&ensp;💬 용어 정리
* 페이지(Page): 프로그램을 작게 나눈 조각 (보통 4KB 등)
* 스왑(Swap): 메모리 ↔ 디스크 간의 이동
* 페이지 폴트: 필요한 페이지가 메모리에 없을 때 발생하는 이벤트
* Lazy Swapper: 진짜 필요할 때만 페이지를 가져오는 방식
* Pager: 이 작업을 실제로 수행하는 운영체제 모듈

&ensp;📍 비유로 이해해보기
* 메모리는 냉장고처럼 빠르게 꺼내 쓸 수 있는 공간
* 디스크는 창고처럼 느리지만 큰 공간
* 냉장고에 필요한 음식만 꺼내 두고, 안 쓰는 건 창고에!
* 배고플 때만 음식(페이지)을 꺼내오는 게 Demand Paging이야 🍱

&ensp;✨ 요약
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-6.png" width="600"></p>

basic concepts
------
&ensp;Demand Paging: 컴퓨터가 프로그램 전체를 한 번에 메모리에 올리지 않고, 실제로 필요한 페이지만 메모리에 올리는 방식이다. 즉, "필요할 때만 불러오기!" 전략이다.<br/>
&ensp;💡 왜 사용해요?<br/>
* 📉 메모리 사용량을 줄일 수 있다.
* ⚡ **응답 시간(Response time)**이 더 빨라질 수 있다.
* 👥 동시에 더 많은 프로그램을 실행할 수 있다.

&ensp;🧾 예시 흐름(Demand Paging 동작 과정)<br/>
1. 어떤 프로그램이 실행된다다.
2. 실행 중인 부분에 필요한 **페이지(Page)**가 메모리에 없다면?
3. 운영체제는 디스크에서 해당 페이지를 불러와서 메모리에 올린다.
4. 이 과정을 **페이지 폴트(Page Fault)**라고 한다.

&ensp;🧊 Lazy Swapper & Pager<br/>
* Lazy Swapper (게으른 스와퍼): 정말 필요한 페이지만 가져왔다.
* Pager (페이지 관리자): 어떤 페이지가 필요한지를 판단해서 메모리에 올리는 역할.

Valid-Invalid Bit(유효/무효 비트)
------
&ensp;📌 개념
* 페이지 테이블의 각 항목에는 valid-invalid bit가 있어요.
* 이 비트는 페이지가 메모리에 올라와 있는지 아닌지를 알려줘요.
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-8.png" width="600"></p>

&ensp;🛠 동작
1. CPU가 어떤 페이지를 참조하려고 할 때,
2. MMU가 페이지 테이블을 확인하고,
3. 비트가 v이면 정상 접근 가능!
4. 비트가 i이면 → Page Fault 발생 → 디스크에서 메모리에 불러옴!

&ensp;🔄 요약
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-9.png" width="600"></p>


Page Table When Some Pages Are Not in Main Memory
------

&ensp;이 그림은 가상 메모리(Virtual Memory)시스템에서 일부 페이지만 실제 물리 메모리에 올라와 있는 상황을 보여준다. 가상 메모리는 프로세스마다 독립적인 메모리 공간을 가지도록 해주는 기술이다.<br/>

&ensp;🔹 구성 요소 설명<br/>
1. Logical Memory
* 이건 프로세스가 인식하는 메모리(프로세스의 입장에서 주소 0~7)
* A~ H까지 총 8개의 페이지가 논리 메모리 상에 존재한다.

2. Page Table
* 각 논리 페이지가 물리 메모리 상 어디에 있는지를 알려주는 표
* frame 열: 해당 논리 페이지가 올라간 물리 프레임 번호
* valid-invalid bit 열: 
  - v: valid -> 지금 메인 메모리에 있음
  - i: invalid -> 지금 메인 메모리에 없음(디스크에 있음)
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-9.png" width="600"></p>


3. Physical Memory
* 실제 컴퓨터 하드웨어 상의 메모리 공간
* 지금은 A, C, F 세 페이지만 메모리에 올라와 있음

4. 디스크
* 디스크는 **메모리에 올라오지 않은 나머지 페이지들(B, D, E, G, H)**을 저장하고 있다.
* 필요하면 여기서 불러와요 (-> demand paging)

&ensp;🔄 동작 시나리오 예시<br/>
&ensp;📌 CPU가 페이지 D에 접근하려고 한다면?
1. Page Table을 확인
2. D는 invalid(i) 상태니까 -> Page Fault 발생
3. 운영체제가 디스크에서 D를 찾아 메모리로 불러옴(swap-in)
4. Page Table을 업데이트: D -> 프레임 번호 설정 + valid 비트로 변경

&ensp;💡 핵심 포인트<br/>
* 모든 페이지가 한 번에 메모리에 올라올 필요는 없다
* 필요한 페이지만 가져오는 Demand Paging 방식은 메모리를 효율적으로 사용하게 해준다
* Page Table + Valid Bit + Disk 조합으로 가상 메모리를 구현할 수 있다.

&ensp;🔧 요약<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-11.png" width="600"></p>

Page Fault
------
&ensp;page fault는 CPU가 어떤 데이터를 사용하려고 했는데 그 데이터(또는 코드)가 지금 메인 메모리에 없을 때 발생하는 오류<br/>

&ensp;필요한 데이터가 메모리에 없어서 당황한 CPU가 운영체제에게 도움을 요청하는 상황이라고 생각하면 된다.<br/>

&ensp;Page Fault 발생 시 처리 단계 <br/>
1. 운영체제가 확인
&ensp;운영체제(OS)은 페이지 테이블을 확인해서 왜 접근이 실패했는지 확인<br/>
* Invalid reference(잘못된 접근): 그 주소 자체가 틀림 -> 프로그램 강제 종료(abort)
* Just not in memory(단지 메모리에 없을 뿐): 디스크에 있음 -> 아래 단계를 계속 진행

2. 빈 메모리 프레임 찾기
* 빈 공간이 있는지 확인
* 없다면 기존 페이지 하나를 내보내고(swap out)공간을 만듦

3. 디스크에서 메모리로 데이터 가져오기(swap-in)
* 디스크에 있던 해당 페이지를 메모리로 불러와요
* 보통 몇 ms 정도 걸리는 무거운 작업이다.

4. 페이지 테이블 갱신
* 페이지 테이블의 해당 페이지 entry를 valid 상태를 설정(v)
* 그리고 해당 페이지가 들어온 **물리 주소(프레임 번호)**도 업데이트한다.

5. 중단된 명령 재실행
* 페이지를 찾지 못해 멈췄던 명령을 처음부터 다시 실행시킨다.
* 이번에 메모리에 있으니까 정상적으로 실행된다.

&ensp;요약: Page Fault 처리 흐름
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-12.png" width="600"></p>

&ensp;💡 비유로 이해하면?
&ensp;📚 학생이 참고서를 보려고 했는데 가방에 없어서 사물함에서 꺼내오는 과정과 비슷해요!<br/>
1. 책 찾음(CPU)
2. 없어서 혼남(Page fault)
3. 선생님한테 말함(OS)
4. 사물함에서 가져옴(disk -> memory)
5. 책을 책상에 올리고 계속 공부함(재실행)

steps in handling a page fault(페이지 폴트 처리 단계)
-------

&ensp;💥 상황 설명<br/>
&ensp;CPU가 어떤 데이터 M을 사용하려고 할 때 그 데이터가 현재 메인 메모리에 없다면 page fault가 발생한다.<br/>

&ensp;단계별 설명<br/>

1. load M (참조 시도)
* 사용 중인 프로그램이 주소 M 접근하려고 한다.
* CPU는 MMU(메모리 관리 장치)를 통해 페이지 테이블을 확인한다.
&ensp;-> 이때 페이지 테이블의 valid-invalid 비트를 봤더니 i(invalid) 상태인 것이다.<br/>
&ensp;즉 현재 메모리에 M이 없음<br/>

2. trap(예외 발생, OS 발생)
* MMU가 페잊 폴트를 탐지하면 trap이라는 신호를 발생시켜서 **운영체제(OS**)**에게 제어권을 넘긴다.
&ensp;-> 이 데이터 없어요!도와주세요! 라는 상황

3. Page is on backing store(디스크 확인)
* 운영체제는 해당 페이지가 디스크(Backing Store)에 저장되어 있는지 확인한다.
* 디스크에 있다면 -> 메모리로 옮겨야겠지

4. bring in missing page (디스크에서 가져오기)
* 디스크에 있던 그 페이지를 메모리로 읽어옵니다 (swap-in 작업).
* 이 작업은 수 밀리초까지 걸릴 수 있는 무거운 I/O 작업이다.

5. reset page table (페이지 테이블 갱신)
* 해당 페이지가 올라온 물리 프레임 번호를 기록하고 valid-invalid 비트를 'v'(valid) 로 바꾼다.
&ensp;“이제는 이 페이지 메모리에 있어요~” 라고 표시해주는 거다.

6. restart instruction (명령 재실행)
* 처음에 문제가 발생했던 load M 명령을 다시 실행한다.
* 이번엔 페이지가 메모리에 있으므로 정상 실행된다.

&ensp;🔁 요약: 그림 흐름 순서<br/>
1. 프로그램이 메모리에 없는 페이지 M을 요청
2. MMU → trap → OS 호출
3. OS가 디스크에서 M을 찾음
4. 디스크에서 M을 메모리로 복사
5. 페이지 테이블 갱신 (valid 표시)
6. 처음 명령 다시 실행 (이번엔 성공!)

&ensp;💡 쉽게 예를 들면?<br/>
&ensp;📚 "책상에서 책을 찾으려다 없어서 책장을 뒤져서 다시 가져오는 과정"<br/>
* 책이 책상에 없으면 (page fault)
* 책장(디스크)에서 찾아서 (backing store)
* 책상(메모리)에 올려놓고 (swap-in)
* 다시 공부 시작 (명령 재실행)

Aspects of Demand Paging
------

&ensp;✅ Extreme case: 시작할 때 아무 페이지도 메모리에 없다.<br/>
* 프로세스가 실행을 시작할 때, 메모리에 아무 페이지도 없는 상태로 시작할 수 있다.
* 운영체제(OS)는 먼저 프로그램의 첫 번째 명령어로 점프하려고 하지만 그 명령어가 들어 있는 페이지가 메모리에 없으면 → page fault 발생!
&ensp;그리고 나서 다른 코드들도 실행하려고 할 때마다 페이지 폴트가 생긴다.<br/>

&ensp;🔵 Pure demand paging (순수 요구 페이징)<br/>
* 시작할 때 메모리에 아무것도 없는 상태에서 필요한 페이지가 요청될 때마다 하나씩 가져오는 방식이다.
* 장점은 메모리 절약, 단점은 실행 초기 느릴 수 있음.

&ensp;🔄 한 명령이 여러 페이지에 접근할 수도 있다.<br/>
&ensp;예: x = A[i] + B[j] 같은 명령은...<br/>
* A[i] -> 첫 번째 페이지
* B[j] -> 두 번째 페이지
* x -> 세 번째 페이지
&ensp;-> 한 줄에 세 개의 페이지 폴트가 날 수 있다.<br/>

&ensp;🧠 Locality of Reference (참조 지역성)<br/>
&ensp;현실에서는 대부분의 프로그램이 같은 코드나 데이터를 반복적으로 사용한다.<br/>
&ensp;예: for문, 함수 호출 등
  - 그래서 보통 한 번 페이지를 불러오면 그 페이지를 오랫동안 계속 사용해야 한다.
  - 덕분에 실제로는 페이지 폴트가 자주 일어나지 않는다.

&ensp;🛠 Demand Paging에 필요한 하드웨어 지원
1. Page Table + Valid/Invalid Bit
* 각 페이지가 메모리에 있는지(v), 아니면 **없는지(i)**를 표시한다.
* MMU가 주소를 변환할 때 이 비트를 확인해서 페이지 폴트 발생 여부 판단.

2. Secondary Memory (Swap Space)
* 페이지가 메모리에 없을 경우 → 디스크에 저장된 페이지를 찾아서 메모리에 올려야 한다. 
* 이걸 위해 디스크에 페이지 저장 공간인 swap 공간이 필요합니다.

3. Instruction Restart
* 페이지 폴트 때문에 실패했던 명령어는, 페이지가 메모리에 로드된 후 다시 실행되어야 해요.
* 이를 위해 CPU는 그 명령어를 기억하고 있다가 다시 실행한다.

Performance of Demand Paging
------

&ensp;Demand Paging 동작 방식 (기본 원리)

1. 프로세스 실행 시작 시, 메모리에 아무 페이지도 없음
2. CPU가 어떤 메모리 주소에 접근하면 → Page Fault 발생
3. 운영체제(OS)가 디스크에서 해당 페이지를 메모리에 불러옴
4. 페이지 테이블에 해당 페이지가 올라온 것 표시 (valid bit = v)
5. 원래 하려던 명령 재시작

&ensp;⏱️ EAT (Effective Access Time) 계산<br/>
&ensp;✅ 기본 공식<br/>
&ensp;EAT = (1 - p) × 메모리 접근 시간  + p × (페이지 폴트 처리 시간)<br/>
* p : 페이지 폴트 확률
* 페이지 폴트 처리 시간 = 인터럽트 처리 + 디스크 입출력 + 재시작

&ensp;✅ 예시<br/>
* 메모리 접근 시간: 200ns
* 페이지 폴트 처리 시간: 8ms = 8,000,000ns
* 1/1000의 확률로 페이지 폴트 발생한다고 가정
&ensp;EAT = 0.999 × 200 + 0.001 × 8,000,000  ≈ 8,200ns (느려짐)<br/>
&ensp; 무려 40배 느려짐 → 성능 저하 크므로 p는 매우 작아야 함<br/>

&ensp;⚙️ 최적화 방법<br/>
1. Locality of Reference 활용
* 실제 프로그램은 같은 코드, 같은 데이터에 반복 접근하는 경향 있음
* 덕분에 일부 페이지만 올려도 동작 가능
2. Swap Space 활용
* 디스크에서 Swap 전용 공간을 만들어 페이징 속도 개선
3. Fork() 최적화
* 자식 프로세스 생성 시 페이지 복사 대신 공유 방식 사용
* Copy-on-write 방식으로 메모리 절약

3\. Copy-on-Write
======
&ensp;🧠 Copy-on-Write란?<br/>
&ensp;Copy-on-Write는 부모 프로세스와 자식 프로세스가 처음에는 메모리를 공유하다가, 누군가 수정하려고 할 때 비로소 **진짜 복사(copy)**를 만드는 기술이다.<br/>

&ensp;📌 언제 쓰이냐면?<br/>
&ensp;fork() 시스템 콜을 사용할 때!<br/>
  - 부모 프로세스를 복사해서 자식 프로세스를 만들면, 부모의 메모리 전체를 그대로 복사하는 건 비효율적이다.
  - 왜냐면... 자식 프로세스가 아무것도 안 바꾸면 그 복사본은 쓸모가 없다!!
&ensp;그래서 등장한 게 Copy-on-Write.

&ensp;🔄 어떻게 동작할까?<br/>
1. 부모와 자식 프로세스는 처음엔 같은 메모리 페이지를 공유함.
2. 누군가 그 페이지를 수정하려고 하면
3. 그제야 복사본을 만들어서 수정은 복사본에서 일어남.
4. 분에 불필요한 복사 최소화, 메모리 절약, 속도 빠름

&ensp;💡 더 알아두면 좋은 것들<br/>
* vfork()는 fork()보다 가벼운 변형.
  - 자식이 exec() 호출할 것만 기대하고 사용됨.
  - 부모는 자식이 exec여전히 COW 방식 주소 공간 공유.
  - 여전히 COW 방식 주소 공간 공유.

&ensp;🧊 zero-fill-on-demand?<br/>
* "빈 페이지"를 미리 만들어 두는 메모리 풀에서 가져옴
* 페이지가 처음 요청될 때 0으로 채워서 제공

* Before Process 1 Moddifies Page C
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-13.png" width="600"></p>

* process1와 process2는 둘 다 page A, page B, page C를 같은 물리 메모리를 가리키고 있다.
* 이 단계에서는 아무도 수정을 하지 않았기 때문에 그냥 공유하고 있다.
* 메모리 낭비 없이 효율적이다.

* After Process 1 Modifies Page C
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-14.png" width="600"></p>

* 이제 process1가 page C를 수정하려고 한다.
* 그러자 운영체제가 page C를 복사해서 새로운 물리 메모리 공간에 만들어 준다.
* process1는 새로 복사된 페이지를 사용하고 process2는 원래 page C를 그래도 사용한다.
* 각자 따로 쓰는 구조가 된다.

&ensp;장점<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-15.png" width="600"></p>

4\. 페이지 교체(Page Replacement)
======

&ensp;🧠 문제 상황: "Free Frame이 없다면?"<br/>
&ensp;운영체제는 프로그램을 실행하기 위해 메모리(Frame)를 사용한다. 그런데 모든 메모리가 이미 어떤 페이지로 가득 찬 상황에서, 새로운 페이지를 불러와야 한다면 어떻게 할까? -> 이때 필요한 것이 페이지 교체(Page Replacement) 이다.<br/>

&ensp;🔄 Page Replacement란?
&ensp;**"현재 메모리에 있는 페이지 중 안 쓰는 걸  찾아서, 내보내고 새로운 걸 대신 넣는 것"**이다.<br/>
&ensp;즉, 메모리가 꽉 찼을 때,<br/>
* 지금 당장 안 쓰는 페이지를 찾아서, 디스크(보조기억장치)로 스왑 아웃(swap out) 하고, 필요한 새로운 페이지를 스왑 인(swap in) 하는 거다.

&ensp;🔍 페이지 교체가 필요한 실제 예시<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-16.png" width="600"></p>
&ensp;상황 설명: <br/>
* user1과 user2가 각각 4개의 페이지를 가지고 있다.
* 물리 메모리에는 총 8개의 프레임만 존재
* 현재 모든 메모리 프레임은 꽉 차 있음

&ensp;예를 들어<br/>
* user1이 load M이라는 명령을 실행해서 M페이지를 접근하려고 하는데 M페이지는 현재 메모리에 없음 -> 즉 Page Fault 실행
* 그런데 모든 메모리가 가득 차 있어서 바로 넣을 수 없다.

&ensp;📌 그럼 어떻게 해야 할까?<br/.>
&ensp;-> 어떤 페이지를 골라서 쫓아내야 힌다.(예: User2의 B페이지가 오래동안 사용되지 않았다면 이것을 디스크에 내보냄)<br/>

&ensp;교체 방식 예시 (Page Replacement Algorithms)<br/>
&ensp;운영체제는 어떤 페이지를 교체할지 알고리즘을 통해 결정한다.<br/>
&ensp;대표 알고리즘:<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-17.png" width="600"></p>

&ensp;💡 핵심 정리<br/>
* 페이지 교체는 메모리가 꽉 찼을 때 발생
* 안 쓰는 페이지를 내보내고 필요한 페이지를 불러옴
* 이를 잘하기 위해 OS는 Page Replacement Algorithm을 사용
* 성능을 위해 교체 횟수를 줄이는 것이 중요

Basic Page Replacement
-----
&ensp;컴퓨터는 프로그램을 실행할 때 프로그램의 일부 내용을 **주 기억장치(RAM)**에 올려야 실행할 수 있다. 이때 사용하는 단위가 Page이다. 하지만 RAM은 용량이 제한되어 있어서 모든 페이지를 다 올릴 수 없다. 그래서 어떤 페이지가 필요할 때 RAM에 공간이 없으면 기존 페이지 중 하나를 뺀 다음 새 페이지를 넣는 작업이 필요하다. 이걸 **Page Replacement**라고 한다.

&ensp;🧊 상황 예시: 프레임이 꽉 찼을 때<br/>
* 사용자 1: A, B, C, D, E, F, G, H 페이지가 필요함
* 하지만 RAM은 3개밖에 못 담음(ex. A, B, C)
&ensp;만약 이 상태에서 G페이지가 필요하다면 -> 기존의 어떤 페이지를 하나를 내보내고 G를 넣어야 한다.

&ensp;기본 절차
1. 디스크에서 읽어올 페이지 찾기
* 예: "G" 페이지가 필요하다!
2. RAM에서 빈 공간 있는지 확인
* 빈 공간이 있다면 바로 넣기
* 빈 공간이 없다면, 기존 페이지 중 하나를 골라서 내보냄 (victim page)
3. victim 페이지가 수정되었는지 확인
* 수정됐다면 디스크에 저장 (→ dirty 페이지라 부름)
* 수정 안 됐다면 그냥 버려도 됨
4. 새 페이지(G)를 디스크에서 읽어와서
* RAM의 빈 공간에 넣기
* Page Table 정보도 함께 수정
5. 원래 하려던 명령어 재시작

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-18.png" width="600"></p>

1. 현재 frame f에 있는 페이지를 디스크로 다시 저장함 (swap out)
2. 그 페이지의 valid bit를 i로 바꿈 → 더 이상 메모리에 없음 표시
3. 디스크에서 새로운 페이지를 읽어 RAM에 올림 (swap in)
4. Page Table의 정보도 새 페이지 기준으로 수정함

&ensp;🧩 victim page란?<br/>
&ensp;**"RAM에서 내보낼 페이지"**를 의미한다.RAM에 공간이 부족할 때 어떤 페이지를 선택해서 내보낼지를 정해야 한다. 이때 쓰는 알고리즘이 있다.
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-19.png" width="600"></p>

Page Replacement Algorithms(페이지 교체 알고리즘)
------

&ensp;🔍이건 뭐 하는 알고리즘인가요?<br/>
* 메모리에 빈 공간(프레임)이 없을 때 어떤 페이지를 내보낼지 결정하는 알고리즘이다.

&ensp;💡 왜 중요하죠?<br/>
* 페이지를 잘못 골라서 자주 다시 필요하게 되면 **계속 페이지 폴트(Page fault)**가 발생하고 프로그램 속도가 심각하게 느려질 수 있다.

&ensp;🎯 목표<br/>
* 가장 적은 Page Fault를 발생시키는 게 이 알고리즘의 목표이다.

&ensp;예를 들어 볼게요 👇<br/>
1. 메모리에 A, B, C 페이지가 있음
2. 새로운 D 페이지를 넣어야 하는데 공간이 없음
3. A, B, C 중에 하나를 제거해야 한다.
4. 이때 무엇을 기준으로 하나를 선택할까? -> 이걸 정하는 게 Page Replacement Algorithm

&ensp;📌 대표적인 페이지 교체 알고리즘들<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-20.png" width="600"></p>

Frame-allocation algorithm(프레임 할당 알고리즘)
------

&ensp;🔍 이건 뭐 하는 알고리즘인가요?<br/>
* 각 프로세스에게 메모리 프레임을 몇 개 줄지 결정하는 것이다.
* 다시 말해 여러 프로세스가 동시에 실행될 때:
  - A 프로세스에게 프레임 몇 개
  - B 프로세스에게 프레임 몇 개?
&ensp;🎯 목표<br/>
* 공평하게 나누되 성능도 잘 나오는 방식으로 분배해야 해요.

&ensp;💡 예를 들어 설명해볼게요<br/>
* RAM 전체 프레임: 12개
* 현재 실행 중인 프로세스: 3개
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-21.png" width="600"></p>

&ensp;이렇게 할당을 어떻게 하느냐에 따라 전체 시스템 성능에 큰 영향을 줘요<br/>

&ensp;🎓 쉽게 요약하면<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-22.png" width="600"></p>

&ensp;💬 정리<br/>
* 페이지 교체는 RAM이 부족할 때 어떤 데이터를 버릴지를 정하는 거고,
* 프레임 할당은 각 프로세스에게 메모리 공간을 얼마나 줄지를 정하는 거다.
&ensp;둘 다 잘 설계하지 않으면
  - 프로세스가 느려지고
  - 자꾸 페이지 폴트가 나고
  - 컴퓨터가 뻑뻑해지는 원인이 된다.

First-In-First-Out (FIFO) Algorithm
------

&ensp;가장 먼저 메모리에 들어온 페이지를 가장 먼저 교체하는 방식이다. 즉 오래된 순서대로 메모리에서 제거한다.<br/>

&ensp;🔍 예시 설명<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-23.png" width="600"></p>

&ensp;Reference String: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1<br/>
&ensp;-> 이건 CPU가 차례대로 접근하는 페이지 번호를 나타내는 문자열이다.<br/>
&ensp;가정: <br/>
* 사용할 수 있는 프레임 수는 3개이다.
* 즉 한 번에 메모리에 3개의 페이지만 넣을 수 있다.

&ensp;⛳ 동작 과정<br/>
* 처음엔 메모리가 비어있음 -> 페이지를 넣기만 하면 돼
* 4번째 페이지 2를 넣을 때 이미 3개가 찼기 때문에 가장 오래된 페이지 7을 제거해야 해
* 이런 방식으로 계속 가장 오래된 페이지를 제거하고 새로운 페이지를 넣음

&ensp;📉 Belady's Anomaly란? <br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-24.png" width="600"></p>

&ensp;**Belady의 모순(Belady’s Anomaly)**은 다음과 같은 이상한 현상을 말해:<br/>
&ensp;프레임 수를 늘렸는데도 페이지 폴트가 더 많이 발생하는 현상<br/>
&ensp;일반적으로 프레임이 많으면 더 좋은 성능이 나올 것 같다? -> FIFO 방식에선 그렇지 않은 경우가 있다.<br/>

&ensp;✅ Optimal Page Replacement Algorithm이란?<br/>
&ensp;앞으로 가장 오랫도안 사용되지 않을 페이지를 교체하는 방식이다.<br/>
&ensp;예를 들어:<br/>
* 메모리에 있는 페이지 중에서,
* 앞으로 한참 뒤에 쓰이거나 다시 안 쓰일 페이지를 골라서 빼는 거다.

&ensp;❗ 왜 "Optimal"일까?<br/>
* 이 알고리즘은 **가장 적은 수의 페이지 폴트(page fault)**를 발생시키는 이론적인 최선의 방법이다.<br/>
* 단점? 현실에서 이 알고리즘을 쓸 수 없다.<br/>
&ensp;-> 왜냐하면 앞으로 어떤 페이지가 언제 사용될지 우리가 실제로는 알 수 없기 때문이다.<br/>
&ensp;그래서 이 알고리즘은 주로 다른 알고리즘(LRU, FIFO 등)의 성능을 비교 평가할 때 사용된다.<br/>

&ensp;📌 예시 설명<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-25.png" width="600"></p>

&ensp;이건 CPU가 차례대로 접근하려는 페이지들 리스트이다.<br/>
&ensp;프레임 수: 3개<br/>
&ensp;-> 한 번에 메모리에 3개 페이지만 넣을 수 있다. <br/>

&ensp;⛳ Optimal 알고리즘 동작 방식<br/>
&ensp;예를 들어 설명해보면:
1. 처음에 7, 0, 1이 차례로 들어와서 3개 프레임 다 채워짐(페이지 폴트 3번 발생)
2. 그 다음 2가 들어오려고 한다. -> 이미 프레임이 꽉 찼으니 하나를 빼야 한다.
  &ensp;이때 Optimal은 앞으로 가장 늦게 사용될 페이지를 뺀다.<br/>
  - 앞으로 7은 19번째에 등장함
  - 0은 4번째 뒤
  - 1은 13번째 뒤
  &ensp;-> 그래서 7을 제거하고 2를 넣음<br/>
3. 이런 식으로 계속해서 가장 나중에 쓰일 페이지를 교체하면서 진행된다.

&ensp;장단점 정리<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-26.png" width="600"></p>

&ensp;💡 현실에서는?<br/>
&ensp;우리는 이 알고리즘을 직접 사용하지는 않지만, -> LUR(Least Recently Used)같은 알고리즘이 Optimal을 흉내내기 위한 현실적인 대안이다.<br/>

Least Recently Used (LRU) Algorithm
------

&ensp;**LRU(Least Recently Used)**는 가장 오랫동안 사용되지 않은 페이지를 교체하는 페이지 교체 알고리즘이다.<br/>
&ensp;📌 핵심 아이디어<br/>
* 지금까지의 과거 사용 기록을 바탕으로
* 최근에 사용된 페이지는 앞으로도 사용할 가능성이 높고 오랫동아 안 쓴 페이지는 당분간도 안 쓸 가능성이 크다!라는 가정을 이용

&ensp;💡 어떻게 작동해?<br/>

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-27.png" width="600"></p>

&ensp;🔁 LRU 동작 원리 (간단히 시뮬레이션)<br/>
1. 7, 0, 1 -> 페이지 폴트 발생하며 채워짐(빈 프레임 3개)
2. 다음에 2가 오면 교체 필요
  - 지금 프레임에 있는 건 -> 7 0 1
  - 최근 사용된 시간 순서: 1(가장 최근) 0 7(가장 오래)
  - -> 7이 가장 오래 전에 사용됨 -> 7을 제거하고 2를 넣음
3. 그 다음도 같은 방식으로 계속 진행

&ensp;📊 페이지 폴트 수<br/>
* FIFO: 15 faults
* LRU: 12 faults
* Optimal: 9 faults
&ensp;-> LRU는 현실적으로 자주 사용되는 알고리즘<br/>
&ensp;-> FIFO보다 효율 좋고, Optimal보다는 못하지만 구현 가능<br/>

&ensp;🛠️ 어떻게 구현해?<br/>
&ensp;RU는 가장 최근 사용 시점을 계속 추적해야 한다.<br/>
&ensp;구현 방법 예시:<br/>
1. 시간 기록법 (Timestamp)
  - 각 페이지마다 마지막으로 접근한 시간 기록
  - 교체할 때 가장 오래된 시간 가진 페이지 선택
2. 스택/리스트 이용
  - 페이지가 참조되면 그걸 스택의 맨 위로 올린다.
  - 스택은 항상 최근에 사용된 순서대로 정렬돼 있다.
  - 가장 오래된 건 스택 맨 아래에 있어서 바로 꺼내버릴 수 있다.
  - 📌 단점: 참조할 때마다 스택을 수정해야 하므로 비용이 큼큼.
3. 하드웨어 지원
  - C각 페이지마다 카운터 값을 하나 둔다.
  - 페이지가 참조될 때마다 현재 시각(시스템 시계 값)을 카운터에 기록
  - 페이지를 교체할 때는 카운터 값을 보면서 가장 오래된 시간 값을 가진 페이지를 선택
  - 📌 단점: 테이블 전체를 훑는(검색) 작업이 필요해 성능이 떨어질 수 있음

&ensp;스택 기반 구현 예시<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-28.png" width="600"></p>

* 상황 설명
* 페이지 참조 순서(reference string): 4 → 7 → 0 → 7 → 1 → 0 → 1 → 2
  - tack Before a : 가장 최근에 사용된 페이지는 2, 가장 오래된 건 4
  - Stack After b : 페이지 7이 또 사용돼서 맨 위로 이동함. 나머지는 순서만 밀렸을 뿐 삭제되지 않음.
&ensp;이 구조 덕분에 "가장 오래전에 쓰인 페이지"가 항상 맨 아래에 있어서
교체 대상 선택이 빠르고 직관적이다.

&ensp;🌟 LRU의 장점<br/>
* FIFO보다 성능이 좋음 (Page Fault 적음)
* Belady’s Anomaly(프레임 늘려도 page fault 늘어나는 이상현상)가 발생하지 않음!

&ensp;⚖️ 비교 요약<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-29.png" width="600"></p>

* 🔔 기억 꿀팁
  - Optimal은 미래를 알고 행동하는 “신” 같은 전략
  - LRU는 과거를 보고 예측하는 “현실적 사람” 같은 전략

LRU Approximation Algorithms
------

&ensp;🧠 왜 근사 알고리즘이 필요한가요?<br/>
&ensp;LRU를 구현하려면:<br/>
* 모든 페이지 접근 시간 기록이 필요
* 최근 사용 시각을 저장하려면 하드웨어나 복잡한 자료구조 필요 -> 느리고 비효율적임.
&ensp;그래서 하드웨어 부담 없이 흉내만 내는 방식이 나왔습니다 -> Approximation Algorithms<br/>

&ensp;💡 Reference Bit 기반 근사 방법<br/>
&ensp;✅ Reference Bit란?<br/>
  - 각 페이지 테이블 항목에 1비트짜리 flag를 둔다
  - 이 비트는 CPU가 페이지를 읽거나 쓰면 1로 바뀐다.
  - OS는 이 reference bit를 확인해서 해당 페이지가 최근에 사용됐는지 파악한다.
&ensp;❗ 중요한 특징:<br/>
* reference bit = 1 -> 최근에 사용됨
* reference bit = 0 -> 오래 사용 안 됨 (교체 후보)

&ensp;🔄 Second-Chance Algorithm (= Clock Algorithm)<br/>
&ensp;Reference Bit를 기반으로 만든 LRU 근사 알고리즘이다.<br/>
&ensp;📘 동작 방식 요약:<br/>
1. 페이지들이 원형 큐(시계 형태)에 저장되어 있다고 가정.
2. 교체할 차례가 된 페이지를 가리키는 포인터 존재 (next victim)
3. 포인터가 가리키는 페이지의 reference bit를 확인:
  - 0이면 교체 (replace)
  - 1이면 비트를 0으로 리셋하고, 포인터를 다음 페이지로 이동
4. 조건을 만족할 때까지 시계방향으로 계속 순회. -> 그래서 Clock Algorithm이라고 부름

<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-30.png" width="600"></p>

&ensp;(a)<br/>
* next victim 포인터가 reference bit가 1인 페이지를 가리킴.
* 그 페이지는 한 번 기회를 더 받음 -> bit를 0으로 바꾸고 포인터 이동

&ensp;(b)<br/>
* 다음 페이지가 reference bit = 0 -> 이 페이지는 교체 대상이 됨

&ensp;✅ 장점 vs 한계<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-31.png" width="600"></p>

Enhanced Second-Chance Algorithm
------
&ensp;📌 기본 아이디어:<br/>
&ensp;일반적인 Second-Chance(Clock) 알고리즘은 페이지에 "참조 비트(Reference Bit)"만을 사용하는데, Enhanced 버전은 참조 비트 + 수정 비트(Modified Bit) 를 함께 사용해서 더 똑똑하게 어떤 페이지를 교체할지를 결정한다.<br/>

&ensp;📋 4가지 경우:<br/>
&ensp;이 두 비트를 쌍으로 보고 다음과 같이 우선순위를 정함:<br/>
<p align="center"><img src="/assets/img/Operating System/10. virtual memory/10-32.png" width="600"></p>

&ensp;📌 장점:<br/>
&ensp;더 "지능적"으로 희생 페이지(victim page)를 골라서 성능 향상 가능<br/>

Counting Algorithms (카운팅 알고리즘)
------

&ensp;이 알고리즘은 **페이지가 몇 번이나 참조됐는지(사용됐는지)**를 세서 교체할지 말지를 결정한다.<br/>
* LFU (Least Frequently Used)
  - 가장 적게 참조된 페이지를 교체
  - 이유: “자주 안 쓰였으니까 빼도 괜찮겠지?”
* MFU (Most Frequently Used)
  - 가장 많이 참조된 페이지를 교체
  - 이유: “이제 막 불러와서 자주 쓸 것처럼 보이는 페이지는 아닐 수도 있음.”
* ⚠️ 단점:
  - 페이지마다 카운트를 관리해야 하니까 구현 복잡도 높고 성능 저하 우려
  - 그래서 실제로는 잘 안 씀

Page-Buffering Algorithms (페이지 버퍼링 알고리즘)
------

&ensp;페이지 교체가 필요한 순간에 바로 victim page를 고르기보다, **"여유 페이지 프레임을 미리 준비해두는 방식"**이다.<br/>
&ensp;📌 기본 아이디어:<br/>
* 페이지 교체는 시간이 오래 걸림 → 그래서 교체할 페이지를 미리 정해두고 따로 저장
* 교체가 필요할 땐 이미 준비된 페이지를 써서 시간 단축
&ensp;📋 세부 전략:<br/>
1. Free Frame Pool 유지: 여유 프레임들을 미리 모아두고, 바로 사용할 수 있게 한다.
2. Victim Page 따로 저장:
  - 여유 있을 때, 디스크로 저장해두고 메모리에서는 제거한다.
  - Modified page는 백업한 후 제거한다.
3. Re-use 최적화<br/>
  - 만약 victim page가 다시 필요하면? 디스크에서 다시 가져오는 대신 미리 저장해둔 것을 복원한다.
  
&ensp;📌 장점:<br/>
  - 잘못된 victim을 선택했을 때도 다시 빨리 복구할 수 있음.
  - 페이지 교체에 따른 패널티 감소 (즉, 느려지는 정도가 줄어듦)