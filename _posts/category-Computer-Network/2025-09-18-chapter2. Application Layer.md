---
title: "chapter2. Application Layer"
excerpt: "600"

wirter: sohee Kim
categories:
  - Computer Network
tags:
  - CS

toc: true
use_math: true 
toc_sticky: true

date: 2025-09-18
last_modified_at: 2025-09-27
---

Application Layer: 개요
=====

&ensp;응용 계층은 우리가 실제로 사용하는 인터넷 서비스(웹, 이메일, 채팅, 스트리밍, 게임 등)을 담당하는 계층이다.<br/>
&ensp;즉 우리가 직접 접하는 서비스 = 응용 계층 프로토콜 위에서 동작한다.<br/>

&ensp;학습 목표 (Our Goals)<br/>
&ensp;응용 계층을 배우면서 우리가 얻을 목표는 크게 두 가지이다.<br/>
1. 개념적 + 구현적 이해
    * 단순히 "HTTP는 웹을 만든다" 정도가 아니라, 실제로 어떻게 동작하는지 깊게 이해.
    * 즉, “이론”과 “코딩” 두 가지를 같이 배움.

2. 응용 계층과 하위 계층 관계
    - 응용 계층이 쓰는 전송 계층 서비스 이해하기 (TCP/UDP 차이).
    - 클라이언트-서버 모델과 P2P 모델 배우기.
3. 실제 프로토콜 학습
    - HTTP, SMTP, IMAP, DNS 같은 프로토콜 구조와 흐름 분석.
4. 프로그래밍 경험
    - 소켓 API를 이용해서 간단한 네트워크 프로그램 만들어보기.

&ensp;3. 네트워크 응용 프로그램의 예시
&ensp;우리가 평소 사용하는 앱 대부분이 응용 계층에 속해요.<br/>
* 소셜 네트워킹 (인스타그램, 페이스북)
* 웹 (크롬, 네이버, 구글)
* 메시지 앱 (카톡, WhatsApp)
* 이메일 (Gmail, Outlook)
* 온라인 게임 (롤, 배그)
* 동영상 스트리밍 (유튜브, 넷플릭스)
* P2P 파일 공유 (토렌트)
* VoIP (음성통화) → Skype, Zoom
* 실시간 화상회의 (Google Meet, Teams)
* 인터넷 검색 (네이버, 구글)
* 원격 로그인 (SSH)

&ensp;👉 즉, 우리가 매일 쓰는 대부분의 서비스가 응용 계층 프로토콜을 기반으로 만들어져 있다.<br/>

&ensp;네트워크 앱 만들기<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-1.png" width="600"></p>

&ensp;네트워크 앱을 만들 때 핵심은 엔드 시스템(end systems) 이다.<br/>
* 프로그램은 엔드 시스템에서 실행된다. (예: 웹 브라우저 = 내 PC, 웹 서버 = 구글 서버)
* 이 둘은 네트워크를 통해 통신합니다. (예: 브라우저가 서버에 HTTP 요청, 서버가 응답)
* 네트워크 코어(라우터, 스위치 등)에선 앱을 만들 필요 없음 → 라우터는 단순히 데이터를 전달만 하고, 실제 앱 동작은 서버/클라이언트에서만 이루어짐.

&ensp;👉 정리: 앱 개발자는 서버/클라이언트용 소프트웨어만 만들면 됨!<br/>

Client-Server Paradigm (클라이언트-서버 구조)
-----

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-2.png" width="600"></p>

* 서버(Server)
    - 항상 켜져 있는 컴퓨터(always-on host) → 예: 네이버, 구글 서버
    - 고정된 IP 주소를 가짐 (permanent IP)
    - 보통 데이터 센터에 위치해서 대규모 서비스 처리 가능
* 클라이언트(Clients)
    - 서버에 접속해서 통신하는 쪽
    - 항상 켜져 있는 건 아님 (간헐적 연결 → 모바일, PC)
    - IP 주소가 매번 바뀔 수 있음 (동적 IP)
    - 서로 직접 연결하지 않고, 서버를 통해서만 통신
    - 예: HTTP (웹), IMAP (메일), FTP (파일 전송)

&ensp;비유: 식당처럼 생각할 수 있음<br/>
* 서버 = 식당 주방(항상 열려있음, 고정된 위치)
* 클라이언트 = 손님(왔다 갔다 함, 주문할 때만 연결)

Peer-to-Peer (P2P) Architecture (피어-투-피어 구조)
-----

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-3.png" width="600"></p>

* 항상 켜져 있는 서버 없음
* 서버-클라이언트 관계가 아니라, 모든 노드가 동등 (peer)
* 피어들끼리 직접 연결해서 서비스 요청/제공
* Self Scalability (자체 확장성)
    - 새로운 피어가 들어오면, 서비스 수요도 늘지만 공급 능력도 같이 늘어남
    - 예: 토렌트 → 더 많은 사람이 접속하면 다운로드 속도가 오히려 빨라짐
* 단점:
    - 피어가 자주 접속했다 끊김 → 관리 복잡
    - IP 주소가 자주 변함 → 연결 유지 어려움
* 예: P2P 파일 공유 (토렌트)

&ensp;👉 비유: 친구들끼리 서로 음식을 나눠주는 potluck 파티.<br/>
&ensp;손님이 많아지면 음식도 많아져서 전체 자원이 늘어남.<br/>

Processes Communicating (프로세스 간 통신)
-----

* 프로세스 (Process): 실행 중인 프로그램 (예: 웹 브라우저, 웹 서버)
* 한 컴퓨터 안에서는 OS가 제공하는 프로세스 간 통신(IPC) 으로 데이터 교환
* 다른 컴퓨터끼리는 메시지를 주고받아서 통신
* Client Process
    - 통신을 시작하는 프로세스 (예: 브라우저 → 서버로 요청 보냄)
* Server Process
    - 요청을 기다리고 응답하는 프로세스 (예: 웹 서버)

&ensp;👉 P2P도 결국은 어떤 프로세스는 클라이언트 역할, 어떤 프로세스는 서버 역할을 함.<br/>

Sockets (소켓)
-----

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-4.png" width="600"></p>

* 프로세스가 메시지를 주고받는 출입구(door) 같은 것
* 송신 프로세스:
    - 소켓을 통해 메시지를 “밖으로 밀어냄”
    - 전송 계층(TCP/UDP)에 맡겨서 반대편 소켓까지 전달
* 수신 프로세스:
    - 자기 소켓에서 메시지를 “받아 읽음”
* 양쪽에 소켓이 하나씩 있어야 통신 가능
* 앱 개발자는 소켓 위에서 프로그램 작성, 나머지는 OS가 담당

&ensp;👉 비유: 집에 문이 있어야 택배를 보낼 수 있음.<br/>
&ensp;소켓 = 문, 운송 서비스(TCP/UDP) = 택배 회사, 프로세스 = 집 주인<br/>

Addressing Processes (프로세스 주소 지정)
------

* 메시지를 받으려면 프로세스는 식별자(identifier) 필요
* 식별자 = IP 주소 + 포트 번호
    - IP 주소 → 어떤 컴퓨터인지
    - 포트 번호 → 그 컴퓨터 안의 어떤 앱인지

&ensp;왜 IP만으로는 부족할까?<br/>
&ensp;한 컴퓨터에서 여러 프로그램이 동시에 실행될 수 있기 때문 (예: 웹 브라우저, 메일 서버, 게임 서버)<br/>

&ensp;예시:<br/>
&ensp;HTTP 서버: 포트 80<br/>
&ensp;메일 서버: 포트 25<br/>

&ensp;실제 예:<br/>
&ensp;128.119.245.12:80 → 특정 웹 서버의 HTTP 서비스<br/>

&ensp;👉 비유:<br/>
* IP 주소 = 아파트 주소
* 포트 번호 = 아파트 동/호수<br/>
&ensp;즉, IP만 알면 아파트 건물까지만 갈 수 있고, 포트 번호가 있어야 정확한 집(프로세스)까지 도착 가능.<br/>

Application-Layer Protocol 
-----

&ensp;응용 계층 프로토콜은 네트워크에서 프로그램들이 서로 대화하는 규칙을 정한다.<br/>
* 메시지 유형(Types of messages)
    - 요청(request), 응답(response)같은 종류 정의
    - 예: 브라우저가 GET 요청 → 서버가 200 OK 응답
* 메시지 구문 (Syntax)
    - 메시지 안에 어떤 필드가 있고, 어떻게 구분되는지 정의
    - 예: HTTP 헤더의 Host, User-Agent, Content-Length
* 메시지 의미 (Semantics)
    - 각 필드가 어떤 의미를 가지는지
    - 예: Content-Length: 100 → 메시지 본문이 100바이트라는 뜻
* 교환 규칙 (Rules)
    - 언제, 어떤 상황에서 메시지를 보내고 응답할지
    - 예: 클라이언트가 GET 보내면 서버는 항상 응답해야 함

&ensp;Open vs Proprietary Protocols<br/>
* Open Protocols
    - RFC에 정의, 누구나 접근 가능
    - 예: HTTP, SMTP (인터넷에서 대부분 사용)
* Proprietary Protocols
    - 특정 회사가 비공개로 운영
    - 예: Skype → 내부 프로토콜은 공개되지 않음

&ensp;<b>앱이 필요로 하는 전송 서비스</b><br/>
&ensp;앱마다 원하는 네트워크 특성이 다르다.<br/>
* Data Integrity (데이터 무결성)
    - 파일 전송, 웹 거래 → 절대 데이터 손실 허용 불가
    - 오디오 스트리밍 → 약간의 손실 허용
* Timing (타이밍, 지연 시간)
    - 인터넷 전화, 온라인 게임 → 지연이 크면 사용 불가
* Throughput (처리율, 대역폭)
    - 동영상 스트리밍 → 최소 전송 속도 필요 (예: 5Mbps 이상)
    - 웹 브라우징 → 대역폭이 크면 빨라지지만, 필수는 아님
* Security (보안)
    - 암호화, 무결성, 인증 필요
    - 예: HTTPS → SSL/TLS로 보안 강화

&ensp;앱별 요구사항 정리<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-5.png" width="600"></p>

&ensp;👉 요약:<br/>
* 파일 전송/이메일/웹 → TCP 필수 (신뢰성 중요)
* 실시간 오디오/게임 → UDP 선호 (빠른 반응 중요, 약간의 손실 허용)

Internet Transport Protocols: TCP vs UDP
-----

&ensp;TCP (Transmission Control Protocol)<br/>
* Reliable Transport: 손실된 데이터 자동 재전송
* Flow Control: 송신자가 너무 많이 보내지 않도록 제어
* Congestion Control: 네트워크 혼잡 시 속도 줄임
* Connection-Oriented: 연결을 먼저 맺고 통신 (3-way handshake)
* 단점: 속도가 느려지고, 지연 증가

&ensp;UDP (User Datagram Protocol)<br/>
* Unreliable: 데이터 손실 가능
* No flow/congestion control: 단순하게 빠르게 전송
* No connection setup: 즉시 전송 가능
* 장점: 오버헤드 적고 빠름 → 실시간 앱에 적합 (게임, 스트리밍)

&ensp;👉 Q: UDP는 왜 필요할까?<br/>
* TCP는 너무 무겁고 지연이 커서 실시간 앱엔 부적합
* UDP는 단순해서 속도가 빠르고 지연이 적음

&ensp;Application Protocols + Transport Protocols 매칭<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-6.png" width="600"></p>

&ensp;👉 실제로는 HTTP 기반 스트리밍이 많아서 TCP를 주로 쓰지만, 실시간 통화/게임은 UDP를 더 선호한다.<br/>

&ensp;<b>Securing TCP (TCP 보안)</b><br/>
&ensp;기본 TCP/UDP (Vanilla TCP & UDP sockets)<br/>
* 암호화 없음 → 데이터가 평문(cleartext)으로 인터넷을 지나감
* 예: 아이디/비밀번호가 그대로 전송된다면, 중간에서 가로채면 그대로 보임

&ensp;TLS (Transport Layer Security)<br/>
* TCP 위에 보안 계층 추가
* 제공 기능:
    - 암호화된 연결 (데이터 도청 불가)
    - 무결성 (Integrity): 데이터 변조 방지
    - 인증(Authentication): 상대방이 진짜 서버인지 확인
* 즉, HTTPS = HTTP + TLS + TCP

&ensp;👉 비유<br/>
* 그냥 TCP = 엽서 (누구나 내용을 읽을 수 있음)
* TLS TCP = 봉투에 넣은 편지 (중간에서 봐도 못 읽음)

Web and HTTP
=====

&ensp;웹과 HTTP는 응용 계층의 대표 사례이다.<br/>
* 웹 페이지 구조
    - 웹 페이지 = 여러 객체(objects) 로 구성
    - 객체: HTML 파일, 이미지(JPEG), 오디오, 동영상 등
    - 하나의 기본 HTML 파일 (base HTML) 안에 여러 객체 포함
    - 각 객체는 URL 로 접근 가능
        + URL = 호스트 이름 + 경로 이름
        + 예: www.someschool.edu/someDept/pic.gif

&ensp;👉 비유<br/>
* 웹 페이지 = 책 한 권
* HTML 파일 = 책의 목차
* 이미지/동영상 = 목차가 가리키는 다른 페이지

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-7.png" width="600"></p>

&ensp;<b>HTTP Overview</b><br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-8.png" width="600"></p>

HTTP (HyperText Transfer Protocol)
-----

* 웹에서 쓰는 응용 계층 프로토콜
* 클라이언트-서버 모델 사용
    - 클라이언트: 웹 브라우저 (크롬, 사파리 등) → 요청(request) 보냄
    - 서버: 웹 서버 (Apache, Nginx 등) → 응답(response) 보냄

&ensp;동작 흐름<br/>
1. 브라우저(클라이언트) → HTTP Request (예: GET /index.html)
2. 서버 → HTTP Response (예: 200 OK + HTML 데이터)
3. 브라우저가 응답을 해석해서 사용자에게 보여줌

&ensp;👉 비유<br/>
* 클라이언트 = 식당 손님 (메뉴 주문)
* 서버 = 주방 (주문에 맞춰 음식 제공)
* HTTP Request = 주문서, HTTP Response = 음식

&ensp;HTTP와 TCP<br/>
* HTTP는 TCP 위에서 동작 (보통 포트 80)
* 과정:
1. 클라이언트가 서버와 TCP 연결 (소켓 생성)
2. 연결 위에서 HTTP 메시지를 교환
3. 데이터 전송 끝나면 TCP 연결 종료

* HTTP는 Stateless (무상태)
    - 서버는 이전 클라이언트 요청을 기억하지 않음
    - 각 요청은 독립적으로 처리됨
    - 장점: 단순하고 확장성 좋음
    - 단점: 로그인/장바구니 같은 기능 구현 어려움 → 쿠키/세션 필요

&ensp;👉 비유<br/>
* Stateless HTTP = 패스트푸드점
    - 매번 주문할 때마다 새로 주문서 작성 (직원이 이전 기록 기억 X)
* Stateful Protocol = 단골식당
    - 직원이 저번에 오셨던 손님 기억 → 추가 서비스 가능

&ensp;요약 표<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-9.png" width="600"></p>

&ensp;<b>HTTP Connections: Two Types</b><br/>
* Non-persistent HTTP (비지속 연결, HTTP/1.0 기본)
1. 클라이언트가 서버에 TCP 연결 생성
2. 한 개 객체(object) 만 요청/응답 가능
3. 객체 전송 후, TCP 연결 종료
4. 다른 객체를 받으려면 새로운 TCP 연결 필요

&ensp;👉 즉, 웹페이지 안에 이미지 10개가 있으면 → 10번 TCP 연결<br/>

* Persistent HTTP (지속 연결, HTTP/1.1 기본)
1. 클라이언트가 서버에 TCP 연결 생성
2. 여러 객체를 한 번의 연결로 전송 가능
3. 페이지의 HTML, 이미지, CSS, JS 모두 하나의 TCP 연결로 처리
4. 다 끝나면 TCP 연결 종료

&ensp;👉 즉, 웹페이지 안에 이미지 10개가 있어도 → 1번 TCP 연결<br/>

Non-persistent HTTP
----

&ensp;Non-persistent HTTP 예제<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-10.png" width="600"></p>

&ensp;(안에 HTML + JPEG 이미지 10개 포함)<br/>
&ensp;과정<br/>
&ensp;1a. 클라이언트 → 서버에 TCP 연결 요청 (포트 80)<br/>
&ensp;1b. 서버 → 연결 허용 (accept)<br/>
&ensp;2. 클라이언트 → HTTP 요청 메시지 전송 (GET /home.index)<br/>
&ensp;3. 서버 → 응답 메시지 전송 (HTML 파일 내용)<br/>
&ensp;4. 서버 → TCP 연결 닫음<br/>
&ensp;5. 클라이언트 → HTML 파일 해석, 안에 JPEG 10개 참조 발견<br/>
&ensp;6. JPEG 하나 받을 때마다 다시 TCP 연결 생성 + 종료 반복 (총 10번)<br/>
&ensp;👉 결과: 비효율적 (연결 과정 때문에 지연 발생)<br/>

&ensp;비유<br/>
* Non-persistent HTTP = 택배를 매번 따로 시키는 것
    - 책 1권, 연필 1개, 지우개 1개를 따로따로 주문 → 매번 배송기사 옮

&ensp;RTT와 Non-persistent HTTP 응답 시간<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-11.png" width="600"></p>

&ensp;RTT란?<br/>
* Round Trip Time (왕복 지연 시간) → 클라이언트(내 컴퓨터)에서 서버(웹사이트)까지 작은 패킷 하나가 갔다가 돌아오는 데 걸리는 시간
* 예: 내가 친구한테 "안녕?" 하고 카톡 보냈을 때, "응" 하고 답이 올 때까지 걸리는 시간 = RTT

&ensp;Non-persistent HTTP 응답 시간<br/>
* 웹페이지의 객체 1개(예: HTML 파일 하나) 받을 때 필요한 시간:
1. TCP 연결 맺기 → 1 RTT
2. 요청(request) 보내고, 응답(response) 받기 시작 → 1 RTT
3. 실제 파일 전송 시간 (파일 크기에 따라 달라짐)

&ensp;👉 따라서 총 응답 시간 = 2 RTT + 파일 전송 시간<br/>

Persistent HTTP (HTTP/1.1)
----

&ensp;Non-persistent HTTP의 문제점<br/>
* 매 파일마다 2 RTT 필요 → 너무 느림
* 브라우저가 이미지 10개를 동시에 받으려면 TCP 연결을 10번 따로 열어야 함 → 운영체제(OS) 부담 커짐

&ensp;Persistent HTTP의 장점<br/>
* TCP 연결을 한 번 열고 그대로 유지
* 여러 객체(HTML, 이미지, CSS 등)를 같은 연결로 전송
* 따라서 2 RTT → 1 RTT 로 줄어듦 → 속도가 확실히 빨라짐 🚀

&ensp;👉 비유<br/>
* Non-persistent HTTP = 택배를 물건 하나하나 따로 시킴 (매번 기사님이 왔다갔다)
* Persistent HTTP = 장바구니에 다 담아서 한 번에 주문 (기사님 한 번만 옴)

&ensp;HTTP Request Message (HTTP 요청 메시지)<br/>
&ensp;웹 브라우저가 서버에 "이거 줘!" 하고 요청할 때 보내는 편지 형식이다.<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-12.png" width="600"></p>

&ensp;구성<br/>
1. Request line (요청 줄)
* 무슨 동작을 할지 명령 (예: GET, POST)
* 예: GET /index.html HTTP/1.1 → index.html 파일을 달라, HTTP 1.1 버전 사용
2. Header lines (헤더 줄)
* 추가 정보들
* 예:
    - Host: 요청할 서버 주소
    - User-Agent: 어떤 브라우저인지 (크롬, 파이어폭스 등)
    - Accept-Language: 어떤 언어 선호 (한국어, 영어 등)
    - Connection: keep-alive → TCP 연결 유지
3. Entity body (본문)
* POST 요청일 경우, 로그인 정보 같은 데이터를 여기에 넣음

&ensp;👉 비유<br/>
* Request line = “내가 피자 주문할게! (종류: 페퍼로니)”
* Header = “주소는 여기, 전화번호는 이거, 카드결제 할게”
* Body = “추가 요청사항: 치즈 많이 주세요”

&ensp;요약표<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-13.png" width="600"></p>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-14.png" width="600"></p>

&ensp;정리:<br/>
* RTT = 왕복 지연 시간 (카톡 보내고 답 올 때까지 시간)
* Non-persistent HTTP = 객체마다 TCP 연결 새로 맺음 → 느림
* Persistent HTTP = 연결을 유지하면서 여러 객체 전송 → 빠름
* HTTP 요청 메시지 = 편지와 비슷, (요청 줄 + 헤더 + 본문) 구조

HTTP 요청 메시지 종류 (Request Methods)
-----

&ensp;HTTP 요청은 **클라이언트(브라우저)**가 서버에게 “이런 행동 좀 해줘!”라고 말하는 것이다.<br/>
&ensp;(1) GET<br/>
* 서버에게 정보를 달라고 요청
* 데이터는 URL에 붙어서 전송됨 예) www.site.com/search?keyword=banana
* 특징: 주소창에 보이기 때문에 보안에 취약, 하지만 단순 조회에는 빠르고 가볍다.
* 시험 포인트: GET은 데이터를 URL에 붙여서 보낸다! (보안 취약, 캐싱 가능)

&ensp;(2) POST<br/>
* 서버에게 데이터를 보내는 요청
* 예: 회원가입, 로그인, 글쓰기
* 데이터는 HTTP 메시지 body에 담겨서 전송됨 → URL에는 안 보임
* 특징: 보안성↑, 대용량 데이터 가능
* 시험 포인트: POST는 body 사용, GET은 URL 사용

&ensp;(3) HEAD<br/>
* GET처럼 요청하지만, 본문(body) 없이 헤더 정보만 받음
* 용도: 서버 상태 확인, 리소스 존재 여부 확인
* 예: “이 파일이 있니?” 확인할 때
* 시험 포인트: HEAD는 응답 본문 없음!

&ensp;(4) PUT<br/>
* 서버에 파일 업로드 or 교체
* 예: 기존 파일을 완전히 새 파일로 바꿔치기
* 시험 포인트: PUT은 새로 업로드 + 기존 걸 완전히 대체

&ensp;비유<br/>
* GET: 책 도서관에서 "이 책 좀 보여주세요" → 책 내용 그대로 보여줌
* POST: "새로운 책 내용을 제출할게요" → 도서관이 받아서 등록
* HEAD: "그 책 있나요? 제목만 알려주세요" → 책은 안 보여주고 메타정보만
* PUT: "이 책을 새로운 책으로 완전히 교체해주세요"

&ensp;HTTP 응답 메시지 구조<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-15.png" width="600"></p>

&ensp;서버가 클라이언트에게 주는 답변 편지<br/>
&ensp;구성 요소:<br/>
&ensp;1. Status line (상태줄): 프로토콜 버전 + 상태 코드 + 상태 설명<br/>
&ensp;예: HTTP/1.1 200 OK<br/>
&ensp;2. Header lines (헤더): 부가 정보<br/>
&ensp;예: 날짜, 서버 종류, 컨텐츠 길이, 타입<br/>
&ensp;3. Body (본문): 실제 데이터 (HTML, 이미지, JSON 등)<br/>

HTTP 상태 코드
----

&ensp;2xx (성공)<br/>
* 200 OK: 요청 성공 (시험: 무조건 기본 성공 코드)
* 3xx (리다이렉션)
    - 301 Moved Permanently: 리소스가 다른 주소로 완전히 이동 (시험: URL이 바뀔 때, 브라우저가 자동으로 새 주소로 요청)
* 4xx (클라이언트 에러)
    - 400 Bad Request: 요청이 잘못됨 (문법 오류 등)
    - 404 Not Found: 요청한 문서 없음 (시험에서 제일 많이 나옴)
* 5xx (서버 에러)
    - 505 HTTP Version Not Supported: 서버가 요청받은 HTTP 버전을 지원하지 않음

&ensp;비유<br/>
* 200 OK = "네, 여기 있습니다!"
* 301 Moved Permanently = "그 책은 이사 갔어요. 새 주소로 가세요"
* 400 Bad Request = "말이 이상해요. 무슨 뜻인지 모르겠어요"
* 404 Not Found = "그 책은 없네요"
* 505 Not Supported = "그 언어는 못 알아들어요"

&ensp;HTTP는 원래 Stateless 프로토콜<br/>
* Stateless(무상태): HTTP 요청(Request)과 응답(Response)은 각각 독립적이다.<br/>
&ensp;→ 서버는 "이 요청이 누구의 요청인지" 기억하지 않음.<br/>
&ensp;→ 예를 들어, 내가 쇼핑몰에 로그인하고 장바구니에 물건을 넣어도, 다음 요청 때 서버는 "너가 누구인지" 모름.<br/>

&ensp;장점: 단순하고 서버 부담이 적음<br/>
&ensp;단점: 로그인 유지, 장바구니, 개인화 서비스가 불가능함<br/>

쿠기(Cookies)
----

&ensp;상태(state)를 유지하기 위한 방법이 쿠기이다.<br/>
&ensp;쿠키는 브라우저와 서버가 협력해서 "사용자를 식별할 수 있는 정보"를 주고받는 방법이다.<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-16.png" width="600"></p>

&ensp;쿠키의 4가지 요소<br/>
1. HTTP Response 헤더에 Set-Cookie 값이 들어감 → 서버가 브라우저에게 “이 값 기억해!”라고 지시
2. 이후 브라우저는 HTTP Request 헤더에 Cookie 값으로 붙여 보냄
3. 브라우저 내부에 쿠키 파일로 저장됨 (예: cookies.txt)
4. 서버는 **백엔드 데이터베이스(DB)**에서 이 쿠키 값을 사용자 정보와 매핑

&ensp;즉, 서버는 “쿠키 ID = 12345는 홍길동”이라고 기억하는 방식<br/>

&ensp;쿠키의 동작 예시<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-17.png" width="600"></p>

1. 사용자가 처음 쇼핑몰 방문 → 서버가 Set-Cookie: 1678을 응답에 포함
2. 브라우저는 쿠키 1678을 저장
3. 이후 같은 사이트 방문 시 → 브라우저가 Cookie: 1678을 요청에 포함
4. 서버는 DB에서 1678 → 사용자 홍길동을 찾아내어 개인화된 응답 제공

&ensp;→ 그래서 로그인 유지, 장바구니 저장, 개인 추천 등이 가능해짐<br/>

&ensp;쿠키의 활용<br/>
* 로그인 세션 유지 (내가 로그인한 상태 기억)
* 장바구니 (사이트를 돌아다녀도 담은 물건 유지)
* 개인화 추천 (이전에 본 상품 기반으로 추천)
* 사용자 인증 (접속 권한 있는 사용자 구분)

&ensp;쿠키의 단점과 보안/프라이버시 문제<br/>
* 보안 문제: 세션 쿠키가 탈취되면, 공격자가 내 계정처럼 행동할 수 있음 (세션 하이재킹)
* 프라이버시 문제: 제3자(광고 회사)의 트래킹 쿠키가 여러 웹사이트에서 나를 추적 가능<br/>
&ensp;→ 예: 내가 쇼핑몰에서 신발을 봤더니, 다른 뉴스 사이트에서도 신발 광고가 뜨는 이유<br/>

Web caches (proxy servers)
----

&ensp;원래 방식: 클라이언트(내 컴퓨터)가 웹 서버(예: 네이버 서버)에게 직접 요청해서 데이터를 받아와야 한다.<br/>
&ensp;캐시 방식: 중간에 있는 프록시 서버(Proxy Server)가 대신 받아주고 자주 쓰는 데이터를 저장해둔다. → 다시 같은 요청이 들어오면 원 서버까지 가지 않고 캐시 서버에서 바로 응답해준다.<br/>

&ensp;즉 가까운 편의점에서 물건 사기" 같은 것이다. 마트(원래 서브)까지 멀리 가지 않고 근처 편의점(캐시 서버)에 있으면 거기서 바로 가져올 수 있는 것이다.<br/>

&ensp;동작 과정<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-18.png" width="600"></p>

1. 클라이언트(내 컴퓨터)가 웹 페이지를 요청 → 먼저 프록시 서버로 감
2. 프록시 서버가 확인:
    - 캐시에 있음 → 바로 응답(빠름)
    - 캐시에 없음 → 원래 서버로 요청해서 받아온 뒤 저장해두고, 클라이언트에게 전달
3. 이후 같은 요청이 오면 프록시 서버가 바로 줌

&ensp;Web Cache가 좋은 이유<br/>
* 응답 속도 빨라짐: 가까운 서버(프록시)에서 받으니까 시간 절약
* 트래픽 감소: 매번 원 서버까지 가지 않으니 네트워크 사용량 줄어듦
* 콘텐츠 제공자에게 도움: 서버가 약한(“가난한”) 사이트도 캐시 덕분에 빠르게 서비스 가능

&ensp;추가 개념<br/>
* Web Cache = Proxy Server → 캐시는 서버 역할(클라이언트에게 데이터 제공)과 클라이언트 역할(원 서버에 요청) 둘 다 함
* ISP(통신사, 학교, 회사) 가 보통 캐시 서버를 설치함
* 문제점: 캐시 데이터가 오래되면 실제 서버의 최신 내용과 다를 수 있음 → 이를 해결하려고 HTTP 캐시 제어 헤더(Cache-Control, If-Modified-Since 등) 사용

&ensp;Caching example<br/>

&ensp;1. 기본 상황<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-19.png" width="600"></p>

* 접속 링크 속도(access link rate): 1.54 Mbps
* RTT: 라우터 ↔ 서버 간 왕복 시간 = 2초
* 웹 객체 크기: 100K bits
* 요청률: 15개/초 → 평균 데이터 전송률(= 15 × 100K) 1.50 Mbps

&ensp;성능 계산<br/>
* LAN 이용률: LAN 속도는 1Gbps, 데이터율은 1.5Mbps니까 1.5/1000≈0.0015<br/>
&ensp;LAN은 충분히 여유로움<br/>

* Access link 이용률: 1.5/1.54≈0.97<br/>
&ensp;거의 꽉 찬 상태 (97% 사용)<br/>

* End-to-end delay (E2E 지연): = 인터넷 지연(2초 RTT) + 접속링크 지연(혼잡 큐잉 발생) + LAN 지연  = 2초 + "분 단위" + "μs 단위"<br/>
&ensp;링크 혼잡 때문에 지연이 아주 커짐<br/>

&ensp;여기서 문제는 요청이 몰리면(접속 링크 이용률 0.97 ≈ 97%) 딜레이가 급격히 증가한다는 점이다.<br/> 
&ensp;즉 인터넷을 통해 가져오는 시간이 너무 길어짐 → “병목 현상” 발생<br/>

&ensp;2. 해결책 1: 더 빠른 회선 구매<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-20.png" width="600"></p>

* 접속 링크 속도를 1.54 Mbps → 154 Mbps로 업그레이드
* 그러면 **접속 링크 이용률이 0.0097 (≈ 1%)**로 아주 여유로워짐
* end-to-end 지연은 “분 단위 → ms 단위”로 크게 줄어듦

&ensp;성능 계산<br/>
* Access link 이용률: 1.5/154≈0.0097<br/>
&ensp;1%도 안 씀 → 혼잡 없음<br/>

* End-to-end delay:
&ensp;= 2초 + ms 수준 (큐잉 거의 없음) + μs 수준<br/>
&ensp;체감 속도가 확 좋아짐<br/>

&ensp;하지만 단점: 비용이 매우 비쌈 (학교, 회사 입장에서 부담 큼)<br/>

&ensp;3. 해결책 2: 웹 캐시 설치<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-21.png" width="600"></p>

* 학교 내부(institutional network)에 캐시 서버 설치
* 자주 요청되는 파일은 캐시에 저장 → 이후엔 외부 서버까지 가지 않고 바로 전달

&ensp;성능<br/>
* 캐시 히트율 = 40% (40%는 캐시에서 해결, 60%만 외부 서버로)
* Access link 데이터율: 0.6×1.5=0.9 Mbps
* Access link 이용률: 0.9/1.54≈0.58

&ensp;트래픽이 줄어서 절반 정도 여유 있음<br/>

* 평균 E2E 지연: 0.6×(서버지연≈2s)+0.4×(캐시지연≈ms) = 0.6 × 2.01 + 0.4 × 0.001 ≈ 1.2s

&ensp;결과: 속도는 빨라지고, 비용은 훨씬 저렴!<br/>
&ensp;즉 캐시 설치가 고속 회선 구매보다 경제적<br/>

&ensp;Conditional GET<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-22.png" width="600"></p>

&ensp;캐시와 원 서버의 데이터가 달라질 수 있으니, 조건부 GET을 사용:<br/>
* 클라이언트가 요청할 때 If-Modified-Since: <date> 를 포함
* 서버가 확인: 
    - 파일이 수정 안 됨 → 304 Not Modified (데이터 안 보내고 OK만 줌)
    - 파일이 수정됨 → 200 OK + 새로운 데이터

&ensp;장점: 불필요한 데이터 전송 줄이고, 최신 데이터 유지 가능<br/>

&ensp;성능 계산 정리 (시험 포인트)<br/>

&ensp;1. 이용률(Utilization) 계산<br/>

&ensp;$ U =\frac{평균 데이터율}{링크 속도}$<br/>

&ensp;1에 가까울수록 혼잡 ↑, 큐잉 지연 ↑<br/>

&ensp;2. 평균 지연(E2E delay)<br/>
&ensp;$Delay = 인터넷지연(RTT) + 접속링크지연(혼잡큐잉) + LAN 지연$
&ensp;3. 해석<br/>
* U → 성능 병목 여부.
* Delay → 사용자 체감 속도.
* 캐시/회선 업그레이드 비교 → 비용 대비 효과 분석 문제로 출제.

&ensp;캐시 히트율을 고려해 가중 평균 계산<br/>

HTTP/2 & HTTP/3
----

&ensp;핵심 목표: 여러 개의 객체를 더 빨리 내려받기<br/>
* HTTP/1.1 파이프라이닝: 하나의 TCP 연결에서 GET 여러 개를 연달아 보냄.
하지만 서버 응답은 반드시 순서대로(FCFS)
* 문제1: HOL(Head-of-Line)블로킹
    - 큰 객체가 맨 앞에 오면 뒤의 작은 객체들도 그게 끝날 때까지 대기 → "한 차선 도로에서 큰 트럭이 앞에 있으면 오토바이도 못 앞지르는 상황"
* 문제2: 손실 복구 시 전체 멈춤
    - TCP는 순서 보장이라 세그먼트 하나만 유실되어도 그 뒤 모든 데이터가 정지(재전송될 때까지)
* 그래서 브라우저들은 현실적으로 **동시에 여러 TCP 연결(보통 6개/오리진)**을 열어 병렬화로 버텼음

&ensp;HTTP/2가 한 일<br/>
&ensp;핵심 아이디어: 하나의 TCP 연결 안에서 다중화(multiplexing)<br/>
* 이진 프레이밍 계층: HTTP 메시지를 작은 프레임으로 쪼갠 뒤 전송
* 스트림(stream): 각 요청/응답 흐름에 ID를 붙임
* 우선순위: 클라이언트가 객체 우선순위를 표시 → 서버는 반드시 FCFS일 필요 없음(스케줄링 가능)
* 서버 푸시(server push): HTML이 참조할 걸 서버가 미리 밀어줄 수 있음(요즘은 브라우저에서 거의 비활성화/폐기 추세지만 개념은 시험에 나옴)
* 헤더 압축(HPACK): 중복 많은 헤더를 테이블+허프만으로 압축, 오버헤드↓
* 실무: 대부분 TLS 위의 h2(ALPN으로 협상)

&ensp;그림 해설(HOL 완화)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-23.png" width="600"></p>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-24.png" width="600"></p>

* HTTP/1.1: 큰 객체 O₁이 맨 앞이면 O₂,O₃,O₄가 O₁ 끝날 때까지 대기
* HTTP/2: O₁을 여러 프레임으로 쪼개고, 그 사이사이에 O₂/O₃/O₄ 프레임을 끼워 넣음 → 작은 것들은 즉시 완료, 큰 O₁은 조금 늦어져도 페이지 체감 속도는 확 좋아짐

&ensp;대형 트럭(O₁)을 박스 단위로 나눠 실어 나르며, 그 틈에 오토바이(O₂~O₄)가 새치기 허용되는 다차선 고속도로<br/>

&ensp;그런데 왜 HTTP/3가 또 필요한가?<br/>
&ensp;HTTP/2도 여전히 TCP 위라서...<br/>
* TCP 레벨 HOL 블로킹은 그대로: 패킷 1개 손실 → 연결의 모든 스트림이 정지(재전송까지)
* 보안은 TLS에 의존(바닐라 TCP엔 없음)
* 그래서 HTTP/3 = QUIC 위의 HTTP로 이동:
    - UDP 기반 QUIC: 각 스트림이 독립적인 손실 복구 → 한 스트림 손실이 다른 스트림을 멈추지 않음
    - TLS 1.3 내장, 항상 암호화
    - 핸드셰이크 빠름(1-RTT/0-RTT 재개), 연결ID로 IP 바뀌어도 연결 유지(모바일 이동 등)
    - 혼잡제어/흐름제어 스트림 단위, 더 많은 파이프라이닝

&ensp;세부 용어 한눈정리<br/>
* 파이프라이닝 vs 멀티플렉싱
    - 파이프라이닝(HTTP/1.1): 요청을 연달아 보냄, 응답 순서 고정 → HOL 발생
    - 멀티플렉싱(HTTP/2/3): 메시지를 프레임으로 쪼개 스트림을 교차 전송 → 작은 객체 빠르게
* HOL 블로킹
    - 애플리케이션 레벨(H1.1): 큰 응답이 앞을 막음
    - 트랜스포트 레벨(TCP): 패킷 손실이 연결 전체 데이터를 막음(HTTP/2에도 존재)
    - QUIC(HTTP/3): 스트림별 전달·복구 → TCP-HOL 해소
* HPACK vs QPACK
    - HPACK(HTTP/2) 헤더 압축은 의존성 때문에 때로는 대기
    - QPACK(HTTP/3)은 비차단 설계로 HOL 위험 완화
* 서버 푸시: 개념은 알아두되, 최신 브라우저에서 비추천/중단 추세

&ensp;자주 나오는 비교표<br/>
* HTTP/1.1: 여러 연결, 파이프라이닝(드물게 사용), HOL 심함
* HTTP/2: 하나의 TCP, 프레임/스트림/우선순위/HPACK, 앱-HOL 완화, TCP-HOL은 남음
* HTTP/3: QUIC(UDP), 스트림 독립 손실복구, TLS1.3 내장, 0-RTT, 연결 마이그레이션

E-mail, SMTP, IMAP
=====

E-mail
----

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-25.png" width="600"></p>

&ensp;큰 그림: 이메일은 "우체국 시스템"<br/>
* 사용자 에이전트(MUA): 메일앱/브라우저(Outlook, Gmail 앱 등). 편지 쓰기/읽기 도구 = 집에서 편지 쓰는 사람
* 메일 서버(MTA/MDA): 편지를 전달·보관하는 서버(회사/학교/구글·네이버 서버) = "우체국"
* SMTP(Simple Mail Transfer Protocol): 우체국 사이에 편지를 넘기는 전달 규칙 = 우체국 간 운송 규칙
* POP3/IMAP: 우체국(메일 서버)에 보관된 편지를 꺼내 읽는 규칙. = 사서함에서 꺼내 읽는 방법

&ensp;포인트<br/>
* 보내기는 SMTP, 읽기는 POP3/IMAP(요즘은 IMAP이 대세)
* 서버 ↔ 서버도 SMTP를 씀(사용자 앱이 직접 상대 서버로 가는 게 아님)

&ensp;사용자 에이전트(MUA): 메일 앱이 하는 일<br/>
* 메일 작성(받는 사람, 제목, 본문, 첨부파일) → 자기 메일서버로 보냄
* 보낸 편지는 **서버의 ‘outgoing queue(발송 대기열)’**에 쌓였다가 외부로 전송
* 받은 편지는 **‘mailbox(사서함/INBOX)’**에 저장 → IMAP/POP3로 읽음

&ensp;메일 서버(MTA): 서버가 하는 일<br/>
* message queue(녹색 막대): 나가야 할 메일 대기 공간
* mailbox(노란 칸): 각 사용자의 받은 편지 보관소
* 서버 ↔ 서버 전송은 SMTP로, 신뢰성 있는 전송을 위해 TCP 사용(기본 포트 25)

&ensp;포인트<br/>
* 포트: 서버간 SMTP 25, 클라이언트 제출(submission) 587(STARTTLS), 465(implicit TLS)
* POP3 110(기본)/995(SSL), IMAP4 143(기본)/993(SSL)

&ensp;SMTP 프로토콜 핵심(RFC 5321)<br/>
&ensp;SMTP는 텍스트 명령/응답으로 진행돼요(HTTP랑 비슷한 느낌)<br/>

&ensp;흐름<br/>
1. TCP 연결(25/587/465)
2. HELO / EHLO (기능 확장 알림: ESMTP)
3. 보내는 사람: MAIL FROM:<alice@A.com>
4. 받는 사람(여러 명 가능): RCPT TO:<bob@B.com> (수신자마다 250 OK/550 실패)
5. 본문 전송 시작: DATA → 서버가 354 Start mail input 응답
6. 메시지 전체(헤더+본문) 전송 후 마침표 단독 줄 .\r\n 로 종료 → 서버 250 OK
7. QUIT

&ensp;특징<br/>
* store-and-forward: 상태 서버가 잠깐 다운이면 큐에 두고 재시도(4xx 일시 오류는 재시도, 5xx는 영구 실패)
* 본래 7-bit ASCII 기반 → 한글/첨부파일은 MIME로 인코딩
* STARTTLS로 TLS 보안 연결 업그레이드

&ensp;포인트<br/>
* 명령어 순서(HELO/EHLO → MAIL → RCPT → DATA → . → QUIT)
* 응답 코드 예: 250 OK, 354 Start mail input, 421/450(일시), 550(수신자 없음)

&ensp;RFC 5321: SMTP (Simple Mail Transfer Protocol)<br/>
&ensp;이 RFC는 메일 서버 간 이메일 전송 규칙을 정의한 문서이다.
&ensp;즉, 이메일을 인터넷에서 주고받을 때 어떤 명령과 응답을 주고받아야 하는지 정해놓은 우체국 간 규칙이라고 볼 수 있다.<br/>

&ensp;TCP 사용<br/>
* SMTP는 TCP 위에서 동작한다.
* 이유: 메일은 유실되면 안 되는 데이터이기 때문에 신뢰성을 보장하는 TCP를 사용
* 전송 과정: 클라이언트 메일 서버 → TCP 연결 → 서버 메일 서버

&ensp;직접 전송 방식<br/>
* 송신자 메일 서버가 클라이언트 역할을 하고 수신자 메일 서버가 서버 역할을 해서 직접 데이터를 주고받음
* 예: Alice 메일 서버 → Bob 메일 서버로 직접 메시지를 보냄

&ensp;SMTP 전송 과정 (3단계)<br/>

&ensp;SMTP는 세 단계로 전송이 이루어진다.<br/>
&ensp;(1) Handshaking (인사, 연결 설정)<br/>
* 클라이언트 → HELO 또는 EHLO 명령 (자신의 도메인 알림)
* 서버 → 250 OK 같은 응답 (정상 연결 확인)

&ensp;(2) 메시지 전송<br/>
* MAIL FROM: 송신자 주소
* RCPT TO: 수신자 주소
* DATA → 이후 실제 메일 본문(RFC 5322 형식)이 전송됨 (From:, To:, Subject: 헤더 + 본문)

&ensp;(3) 연결 종료<br/>
* QUIT 명령 → 서버 221 Bye 응답 → TCP 연결 종료

&ensp;Command/Response 방식<br/>
* SMTP는 명령(command) + 응답(response) 구조로 동작
* 명령: ASCII 텍스트 (예: MAIL FROM: <alice@example.com>)
* 응답: 상태 코드 (3자리 숫자) + 메시지
    - 250 OK (성공)
    - 550 No such user (실패, 사용자 없음)

&ensp;메시지 제약<br/>
* SMTP 메시지는 기본적으로 7-bit ASCII만 허용됨
    - 그래서 첨부파일, 한글 같은 비-ASCII 데이터는 MIME(Multipurpose Internet Mail Extensions)을 통해 인코딩 후 전송

&ensp;이메일 메시지 형식(RFC 5322) – DATA에 들어가는 내용<br/>
* 헤더: From, To, Subject, Date, Message-ID, Received, MIME-Version, Content-Type, Content-Transfer-Encoding …
* 빈줄
* 본문(body)

&ensp;중요 구분 – "봉투(envelope)" vs "헤더(내용물)"<br/>
* SMTP envelope의 MAIL FROM/RCPT TO가 실제 배달 주소 판단 기준.
* 헤더의 To/Cc/Bcc는 사람이 보는 정보. Bcc는 헤더에 안 남음(그래서 숨김참조).

&ensp;MIME(첨부/한글)<br/>
* Content-Type: text/plain; charset=UTF-8, multipart/mixed(첨부 포함) 등
* Content-Transfer-Encoding: base64, quoted-printable 등으로 바이너리/한글 안전 전송

&ensp;포인터<br/>
* Received 헤더는 거쳐 간 서버들이 누적 기록 → 스팸 추적, 경로 분석에 사용.
* Bcc는 헤더에 없다(배달은 envelope로 처리)

&ensp;시나리오: Alice → Bob<br/>
1. Alice가 MUA에서 메일 작성
2. Alice의 메일 서버로 제출(submission; 587/465) → outgoing queue 적재
3. Alice 서버의 SMTP 클라이언트가 Bob 도메인의 MX 레코드를 DNS로 조회, 대상 Bob 메일 서버와 TCP 연결
4. SMTP 대화로 메시지 전송(여러 RCPT 가능)
5. Bob 서버는 Bob의 mailbox에 저장
6. Bob은 자신의 MUA로 IMAP/POP3 접속해 읽음(회사/구글처럼 서버에 남겨 두고 동기화하려면 IMAP)

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-26.png" width="600"></p>

&ensp;포인트<br/>
* DNS MX(Mail eXchanger) 조회로 목적지 메일 서버를 찾는다.
* 서버 간은 항상 SMTP. 읽기는 IMAP/POP3

SMTP
-----

&ensp;Sample SMTP interaction 해설 (줄-by-줄)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-27.png" width="600"></p>

&ensp;표기: S=server, C=client(보내는 쪽 메일 서버)<br/>
1. S: 220 hamburger.edu
    - 서버 배너. 서비스 준비됨을 뜻하는 220(성공/준비 완료)코드
2. C: HELO crepes.fr
    - 클라이언트가 자신의 도메인 이름을 밝히며 인사.
    - 실제 운영에선 보통 EHLO(Extended HELO)를 사용 → 서버 기능 목록(STARTTLS, AUTH 등)을 돌려줌.
3. S: 250 Hello …
    - 250 = 성공. “좋아, 계속해.”

4. C: MAIL FROM:<alice@crepes.fr>
    - 발신자(“reverse-path”) 설정. Envelope 발신자(반송 주소)이지, 메시지 헤더의 From:와 다를 수 있음.
5. S: 250 … Sender ok
6. C: RCPT TO:<bob@hamburger.edu>
    - 수신자(“forward-path”) 지정. 여러 명이면 RCPT TO를 여러 번 보냄.
7. S: 250 … Recipient ok
    - 실패하면 예: 550(존재 안 함), 450(임시 문제—나중에 재시도)
8. C: DATA
    - 이제 본문을 보낼게요.
9. S: 354 Enter mail …
    - 354 = “본문 받아. 끝은 CRLF.CRLF(빈 줄 + 점 하나 + 빈 줄)로 표시해.”
10. C: (메시지 본문 전송)
    - 여기에는 RFC 5322 형식의 헤더+바디가 들어감(아래 자세히).
    - 마지막 줄에 .만 있는 줄을 보내 종결(CRLF . CRLF).
    - 주의: 본문에서 줄 첫 글자가 .인 줄은 dot-stuffing 규칙으로 ..로 이스케이프하여 조기 종료 방지.
11. S: 250 Message accepted for delivery
    - 큐에 넣었고, 이제 대상 도메인의 MX(메일 교환 레코드)를 찾아 최종 목적지로 릴레이.
12. C: QUIT → S: 221 … closing
    - 세션 종료. (한 연결에서 여러 번의 MAIL FROM/RCPT/DATA 트랜잭션을 처리할 수도 있음 = persistent 연결)

&ensp;상태코드 빠르게 읽기<br/>
* 2xx 성공, 3xx 추가 입력 필요, 4xx 임시 오류(재시도), 5xx 영구 오류(실패)
* 대표: 220(배너), 250(OK), 354(DATA 시작), 421(서비스 종료/부하), 450/451(임시), 550(수신자 없음), 552(용량 초과)

&ensp;DATA 내용<br/>
* 형식: 헤더(여러 줄) + 빈 줄 + 본문
* 헤더 예시(최소): 

```yaml
From: Alice <alice@crepes.fr>
To: Bob <bob@hamburger.edu>
Date: Tue, 01 Oct 2024 10:00:00 +0000
Subject: Hello
```

* 본문: 실제 텍스트
* 이미지/첨부/한글 등 7-bit를 넘는 데이터는 MIME로 인코딩(Base64 등)하고 Content-Type, Content-Transfer-Encoding을 붙여 multipart로 보냄. (헤더는 RFC 5322, 전송은 RFC 5321)

&ensp;Try SMTP yourself<br/>
* 고전 방식: telnet <서버> 25 → 220 배너를 보면 EHLO your.domain → MAIL FROM: → RCPT TO: → DATA → 본문 → . → QUIT
* 실전 주의
    - 많은 서버/ISP가 25번 포트를 외부에서 막음(스팸 방지)
    - 실제 발송은 587(Submission) 사용 + EHLO 후 STARTTLS와 AUTH로 인증
    - 테스트는 openssl s_client -starttls smtp -connect host:587가 흔함

&ensp;SMTP vs HTTP<br/>
* 상호작용 방식:
    - HTTP = pull(클라이언트가 가져감), SMTP = push(보내는 서버가 밀어 넣음, store-and-forward 릴레이)
* 메시지 종료 표식:
    - HTTP는 Content-Length/Chunked 등으로 구분,
    - SMTP는 CRLF.CRLF + dot-stuffing 규칙
* 문자 집합:
    - 전통 SMTP는 7-bit ASCII 요구 → MIME이 확장 담당
* 연결:
    - 둘 다 명령/응답 텍스트 프로토콜, 상태코드 보냄
    - SMTP 연결은 한 번 열어 여러 수신자/다중 트랜잭션 가능(서버 설정에 따름)

Mail message format = 편지지 규칙 (RFC 5322)
-----

&ensp;메일에 무엇을 어떤 순서로 쓸지에 대한 약속이다.<br/>
&ensp;메일은 두 부분으로 되어 있다.<br/>
1. 헤더(header): 받는 사람, 보내는 사람, 제목 같은 줄 목록
2. 본문(body): 실제 메시지 내용

&ensp;둘 사이에는 빈 줄(black line)이 딱 한 줄 들어간다. 그 빈 줄을 기준으로 여기까지가 헤더, 이제부터 본문이라고 컴퓨터가 알아듣는 거다.<br/>

&ensp;헤더는 이런 식으로 한 줄에 `이름: 값` 형태로 쓴다.<br/>

* From: 누가 보냈는지
* To: 누가 받는지
* Subject: 제목
* Date: 보낸 날짜/시간
* (요즘 자주 보이는 것) MIME-Version:, Content-Type: 본문이 어떤 형식(텍스트/첨부 등)인지

&ensp;예<br/>
```yaml
From: Alice <alice@example.com>
To: Bob <bob@example.net>
Subject: 점심 약속?
Date: Tue, 23 Sep 2025 12:34:56 +0900
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8

안녕 Bob, 오늘 12시에 밥 먹을래?
```

* 위에서 빈 줄 아래가 본문이다.
* 예전 표준은 본문을 ASCII 문자만 허용했는지 요즘은 MiME 덕분에 한글(UTf-8)도 첨부파일도 보낼 수 있다.(첨부는 내부적으로 base64같은 방식으로 텍스트처럼 바꿔서 붙여 보낸다.)

&ensp;헤더에 적히는 To:/From:은 "편지지에 적힌 정보(보여주기용)"이고, 실제 배달 경로에 쓰는 주소는 따로 있어(바로 아래의 SMTP에서 설명하는 봉투 주소)<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-28.png" width="600"></p>

Mail access protocols
------

&ensp;이건 편지지 = 우체국 규칙 (SMTP, RFC 5321)<br/>
&ensp;이건 편지지 규칙이 아니라 우체국(서버)들이 편지를 주고받는 절차에 대한 약속이다. 이름은 SMTP이다.<br/>
&ensp;비유<br/>
&ensp;보내는 사람(내 컴퓨터의 메일 앱) → [SMTP] → 내 메일서버 → [SMTP] → 상대 메일서버 → 받는 사람(상대의 메일 앱)<br/>

* SMTP 대화에서는 봉투 주소를 따로 말한다.
    - MAIL FROM: <보낸 주소>
    - RCPT TO: <받는 주소>

* 이건 실제 배달용 주소(봉투 겉면)이다.
* 편지지 안에 적힌 To:, From(헤더)은 읽는 사람이 보라고 적는 글
* 그래서 Bcc(숨는 참조)가 가능한 것이다. 봉투엔 적혀 있지만 편지지(헤더)에는 안 적을 수 있다.

&ensp;SMPT의 간단한 흐름<br/>
```markdown
서버: EHLO example.com
클라: MAIL FROM:<alice@example.com>
클라: RCPT TO:<bob@example.net>
클라: DATA
      (여기서 위에 설명한 헤더들 + 빈 줄 + 본문을 그대로 보냄)
      .
클라: QUIT
```

&ensp;DATA 단계에서 헤더 + 빈 줄 + 본문을 통쨇 보내는 것이다.(즉 "내용 규칙(RFC 5322 "은 이 단계에서 등장!)

&ensp;<b>메일 “가져오기(읽기)” 방법 = 사서함에서 꺼내오기 (IMAP/POP/HTTP)</b><br/>
&ensp;보내는 건 SMTP로 끝났고 이제 상대편 서버의 사서함에 편지가 들어가 있다.<br/>
&ensp;받는 사람이 그 편지를 읽어오는 방법은 세 가지이다.<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-29.png" width="600"></p>

* IMAP: "서버에 메일을 그대로 두고" 여러 기기에서 동기화하며 읽기 좋아. 폴더, 읽음 상태 등이 기기간에 맞춰진다. (요즘 표준)
* POP3: 예전 방식. "내 컴퓨터로 내려받고 서버에서 지우는" 스타일이 기본. 단일 기기 중심
* HTTP(웹메일): 크롬/사파리 같은 브라우저로 gmail/naver 등 웹사이트에 접속해서 보는 방식
    - 겉으로는 우리가 웹페이지만 보지만 서버 내부에서는 여전히 SMTP/IMAP 같은 프로토콜로 움직인다.

&ensp;자주 헷갈리는 점 정리<br/>
* RFC 번호 정리
    - SMTP(배달 규칙): RFC 5321
    - 메일 메시지 형식(헤더/본문 규칙): RFC 5322 (옛 RFC 822의 새 버전)
* 헤더의 To: vs SMTP의 RCPT TO:
    - To:는 편지에 적힌 표시용
    - RCPT TO:는 실제 배달 주소(봉투 주소). 서로 다를 수 있음(Bcc가 가능한 이유).
* 빈 줄의 의미: 헤더 끝/본문 시작을 구분하는 경계선
* 한글/첨부는 어떻게?: MIME 덕분에 가능. Content-Type, Content-Transfer-Encoding 같은 헤더로 형식과 인코딩을 알려줌

The Domain Name System DNS
=====

&ensp;DNS가 필요한 이유<br/>
* 컴퓨터끼리는 IP주소(예: 142.250.207.36)로 통신한다.
* 사람은 이름(예: www.google.com)이 기억하기 쉽다.
* DNS는 이름 ↔ IP 주소 변환기이다. "구글 어디예요?" 하면 "이 번호로 가세요!" 하고 IP를 알려주는 서비스

&ensp;DNS 동작하는 주체<br/>
* 사용자(브라우저/앱): "www.amazon.com의 IP 알려줘!"
* 재귀(Recursive) DNS: 우리 집·학교·통신사에서 제공하는 대리인. 사용자를 대신해 여기저기 물어봐서 정답을 가져온다.
* 권한(Authoritative) DNS: 어떤 도메인 정보의 정식 원본을 들고 있는 서버(예: amazon.com을 실제로 관리)
* 루트(Root)·최상위 도메인(TLD) 서버: .com, .org, .kr 같은 큰 지도 갈림길을 안내해 주는 서버들

&ensp;주소 찾는 과정<br/>
&ensp;도메인 이름은 점(.)으로 나뉘고 오른쪽에서 왼쪽으로 계층이 깊어진다.<br/>
```markdown
www.amazon.com
└─com (TLD)
   └─amazon (도메인)
      └─www (호스트 이름)
```

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-30.png" width="600"></p>

&ensp;조회되는 이유<br/>
1. 내 컴퓨터 → 재귀 DNS
    - 내 컴퓨터는 설정된 재귀 DNS(보통 ISP나 공용 DNS)에 "이거 IP 뭐예요?"라고 묻는다.
2. 재귀 DNS → 루트 서버
    - "com 담당 어디죠?" → 루트가 .com TLD 서버 목록을 알려준다.
3. 재귀 DNS → .com TLD 서버
    - amazon.com 담당 어디죠? → amazon.com의 권한 DNS 주소를 준다.
4. 재귀 DNS → amazon.com 권한 DNS
    - www.amazon.com의 IP 좀 주세요. → **정답 IP 주소(A/AAAA 레코드)**를 돌려준다.
5. 재귀 DNS → 내 컴퓨터
    - 받은 IP를 **캐싱(기억)**해 두고, 내 컴퓨터에 전달. 브라우저는 그 IP로 접속!

&ensp;이 과정은 보통 몇 ms~수백 ms 안에 끝나고, 결과는 TTL(유효기간) 동안 캐시되어 다음엔 더 빨라진다.<br/>

&ensp;중앙 서버 하나로 관리를 안 하는 이유<br/>
* 한 곳이 고장나면 인터넷이 멈춤(SPOF)
* 전 세계 엄청난 요청량을 못 감당
* 멀리 떨어져 지연 ↑
* 운영/유지보수 지옥 → 그래서 전 세계에 나눠서(분산), 단계별(계층)로 운영한다.

&ensp;루트·TLD·권한 서버<br/>
```css
[루트] ──> [.com TLD] ──> [amazon.com 권한]
          └─> [.org TLD] ...
```

* 루트 서버: “큰 갈림길 안내판”. 논리적으로 13개(A~M) 이름이 있고, 실제로는 전 세계에 수백 대가 anycast로 복제되어 있어 가까운 곳에서 응답한다.
* ICANN: 루트 영역을 관리하는 기관
* DNSSEC: 답변에 전자서명을 붙여 "가짜 답변이냐?"를 검증(무결성/인증). 암호화(비밀유지)는 아님

&ensp;DNS가 제공하는 서비스<br/>
1. 호스트네임 → IP 변환: www.example.com → 93.184.216.34 (A/AAAA)
2. 호스트 별칭(별명) CNAME:
    - 보기 좋은 이름을 **진짜 이름(정식=canonical)**으로 연결
    - 예) shop.example.com → shop-east-1.example-cdn.net
3. 메일 서버 별칭(MX):
    - 이 도메인으로 오는 메일은 어느 서버로?
    - 예) example.com의 MX가 mail.example.com
4. 부하 분산:
    - 한 이름에 **여러 IP(A 레코드 여러 개)**를 돌려주어 라운드로빈/가까운 곳 선택 등 분산(대형 웹·CDN에서 흔함)

&ensp;<b>TLD 서버(Top-Level Domain servers)</b><br/>
* TLD는 도메인의 맨 오른쪽 덩어리야: .com, .org, .net, .kr, .edu 같은 거
* TLD 서버는 "이 구역 담당 사무소". 최종 IP를 모르는 경우가 많고 대신 "그 도메인을 진짜로 책임지는 서버(권한 서버)가 어디에 있는지"를 알려준다.

&ensp;저장 내용<br/>
* 보통 NS 레코드(권한 서버 주소) 와 필요하면 Glue 레코드(A/AAAA) 를 갖고 있다.
    - 예) amazon.com을 물으면 .com TLD 서버는 "amazon.com은 ns1.amazon…, ns2.amazon…에서 책임진다.(=NS) 그리고 그 네임서버의 IP는 이거다.(=Glue)"

&ensp;용어 정리<br/>
* Registry(레지스트리): 특정 TLD 전체를 운영(존 파일 관리, TLD 서버 운영자)
* Registrar(등록대행자): 우리가 도메인을 살 때 이용하는 판매창구
* 우리가 Registrar에서 네임서버를 설정하면 그 정보가 Registry → TLD 서버에 반영된다.

&ensp;<b>Authoritative DNS 서버(권한 서버)</b><br/>
* 어떤 도메인 구역(zone)의 정답 원본을 들고 있는 서버.
* "www.example.com의 IP가 뭐냐?"에 대해 최종 답변을 줄 수 있다.

&ensp;운영하는 사람<br/>
* 회사/학교가 직접 운영할 수도 클라우드 DNS나 호스팅 업체에 맡길 수도 있다.

&ensp;어떤 데이터가 있나? (존 파일 예시)<br/>
```yaml
$ORIGIN example.com.
@     3600 IN A     203.0.113.10        ; 도메인 apex의 IP
www   3600 IN CNAME web-01.example.net. ; www는 별칭
@     3600 IN MX    10 mail.example.com.; 메일 서버
@     3600 IN NS    ns1.dns-host.net.   ; 권한 네임서버 1
@     3600 IN NS    ns2.dns-host.net.   ; 권한 네임서버 2
```

* A/AAAA: 실제 IP
* CNAME: 별칭 → 진짜 이름
* MX: 메일 서버
* NS: 이 존을 책임지는 권한 서버
* 왼쪽의 숫자 3600은 TTL(캐시 유효 시간, 초)

&ensp;Primary/Secondary & 전송<br/>
* 같은 존을 여러 대가 복제해 서비스(가용성↑)
* 존 전송(AXFR/IXFR)은 보통 TCP 53으로 이루어진다.

&ensp;<b>Local DNS name server(우리 편 “대리인”, 재귀 리졸버)</b><br/>
* 집/학교/회사/통신사가 제공하는 재귀(Recursive) DNS. 흔히 기본 DNS라고 부른다.
* DNS 계층 트리의 ‘일원’은 아니고, 프록시/대리인 역할을 한다.
    - 내 컴퓨터는 항상 얘한테만 묻고,
    - 얘가 루트 → TLD → 권한 서버를 차례로 찾아가서 정답을 가져온다.

&ensp;캐시<br/>
* 최근에 본 이름↔IP를 TTL 동안 저장해서 다음 요청을 빠르게 처리
* 새 IP로 바꿨는데 바로 반영 안 되는 이유가 이 캐시 때문(전파 지연)

&ensp;흐름 한 번에 보기<br/>
&ensp;www.amazon.com의 IP가 필요할 때:<br/>
1. 내 PC → Local DNS: "IP 알려줘!"
2. Local DNS 캐시에 없으면
    - 루트에게 “.com 누구 담당?”
    - .com TLD에게 “amazon.com 누가 책임져?”
    - amazon.com 권한 서버에게 “www.amazon.com IP 주세요.”
3. 정답(IP) 받으면 내 PC에 전달 + 캐시 저장

&ensp;세 역할 차이, 한 줄 요약<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-31.png" width="600"></p>

DNS가 이름을 IP로 바꿔 주는 방법 두 가지
-----

* Iterated(반복) 쿼리: "난 최종 답은 몰라. 다음에 누구에게 물어봐야 하는지 알려줄게."
* Recursive(재귀) 쿼리: “네가 알아와.” → 질문 받은 서버가 위로 계속 돌아다니며 최종 답을 구해다 준다.

&ensp;Iterated query(반복 질의)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-32.png" width="600"></p>

&ensp;1. 호스트 → 로컬 DNS(dns.nyu.edu)<br/>
&ensp;"gaia.cs.umass.edu IP 알려줘!"<br/>
&ensp;2. 로컬 DNS → 루트 서버<br/>
&ensp;"gaia.cs.umass.edu 어디로 가면 되죠?"<br/>
&ensp;3. 루트의 응답(Referral)<br/>
&ensp;"나는 최종 IP는 몰라. .edu TLD 서버들에게 물어봐." (응답의 Authority 섹션에 NS, Additional 섹션에 NS의 Glue IP가 들어있을 수 있다.)<br/>
&ensp;4. 로컬 DNS → .edu TLD 서버<br/>
&ensp;"그럼 .edu 담당님, cs.umass.edu는 누가 책임지나요?"<br/>
&ensp;5. .edu의 응답(Referral)
&ensp;"cs.umass.edu의 권한(Authoritative) 네임서버들은 이분들이야."<br/>
&ensp;6. 로컬 DNS → 권한 DNS(dns.cs.umass.edu)<br/>
&ensp;"gaia.cs.umass.edu의 A/AAAA 레코드 주세요."<br/>
&ensp;7.권한 DNS의 최종 응답<br/>
&ensp;"여기가 정답 IP" (예: 128.119.245.12)<br/>
&ensp;8. 로컬 DNS → 호스트<br/>
&ensp;최종 IP를 전달하고, TTL 동안 캐시해 둠. → 다음에 같은 질문이 오면 2~7 없이 바로 답 가능!<br/>

&ensp;Recursive query (재귀 질의)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-33.png" width="600"></p>

&ensp;재귀는 질문을 받은 서버가 ‘끝까지’ 알아와서 한 방에 정답을 주는 방식<br/>
* 장점: 질문자(클라이언트) 입장에선 왕복이 1번이라 단순
* 단점: 재귀를 수행하는 서버에 부담이 몰림. 상위(루트/TLD)가 재귀까지 해 주면 부하 폭증

&ensp;현실<br/>
* 루트/TLD 서버는 재귀를 하지 않는다. (정책적으로 금지)
* 그래서 보통은 내 PC(Stub Resolver) 가 RD(Recursion Desired) 플래그=1 로 로컬 DNS에게 “재귀로 알아와 달라”고 부탁.
* 로컬 DNS는 그 부탁을 받고 위쪽으로는 Iterated(반복) 로 움직여서 정답을 가져온 뒤,
응답에 RA(Recursion Available)=1을 넣어 “재귀 지원했다”라고 알려준다.

&ensp;둘의 차이<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-34.png" width="600"></p>

&ensp;현실적인 전체 흐름<br/>
```markdown
내 PC(재귀 요청 RD=1)
   ↓ (1번만)
로컬 DNS(재귀 수행자)  ← 여기서 캐시/TTL 관리
   ↳ 루트  → TLD  → 권한 (여긴 Iterated, Referral 왕복)
   ← 최종 IP
   ↑ 정답 전달(RA=1)
```

&ensp;<b>캐싱과 업데이트(Caching, Updating DNS Records)</b><br/>
&ensp;핵심 아이디어<br/>
* DNS는 한 번 답을 알게 되면 메모해 두었다가(TTL 동안) 또 물어보면 바로 알려준다. → 이게 캐시(cache)
* TTL(Time To Live): 이 메모를 몇 초 동안 믿어도 되는지를 적어둔 유통기한

&ensp;예<br/>
* 어떤 이름의 TTL이 3600초(=1시간)
* 로컬 DNS가 12:00:00에 정답을 받았다. → 이 답은 13:00:00까지 유효
* 12:30에 같은 질문이 오면? 바로 캐시에서 답! (상위 서버 들쑤시지 않음)
* 13:05에 오면? 유효기간이 끝났으니 다시 위로 올라가(루트→TLD→권한) 새 답을 받아옴

&ensp;포인터<br/>
* 캐시 덕분에 빠르고 트래픽(서버 부하)를 줄인다.
* 대신 바뀐 정보가 전 세계에 퍼지기까지 TTL만큼 시간차(전파 지연)가 생길 수 있다.
* TDL/루트처럼 자주 쓰이는 길안내 표지판 정보도 로컬 DNS에 캐시되기 때문에 루트 서버를 매번 찾지 않아도 된다.

&ensp;DNS 레코드 종류 (DNS records)<br/>
&ensp;DNS는 “리소스 레코드(RR)”라는 카드에 정보를 적어둔다. 모양은:<br/>
```bash
(name, value, type, ttl)
```

&ensp;예를 들어 www.example.com의 IPv4 주소라면:<br/>
```bash
(name=www.example.com, value=93.184.216.34, type=A, ttl=3600)
```

&ensp;꼭 알아둘 타입 5가지<br/>
* type=A: IPv4 주소
    - “이 이름의 전화번호(IPv4)는 뭐야?”
* type=CNAME: 별칭 → "진짜 이름(정식 이름, canonical name)"
    - shop.example.com → shop-east.example-cdn.net

* type=NS: "이 도메인을 책임지는(권한) 네임서버는 누구?"
    - 위임(Delegation)에 쓰임
* type=MX: "메일은 어느 서버로 보내?"
    - 예) example.com의 메일은 mail.example.com으로!

&ensp;(+ 보너스) SOA: 존(구역) 시작 정보, TXT: 각종 인증/검증 문자열(SPF, 도메인 소유증명 등)<br/>

&ensp;<b>DNS 메시지 포맷 (query/reply 공통)</b><br/>
```markdown
<─────2byte ────><─────2byte ────>
┌───────────────┬───────────────┐
│ identification│     flags     │  ← 16비트 ID / 각종 깃발
├───────────────┼───────────────┤
│ #questions    │ #answer RRs   │
├───────────────┼───────────────┤
│ #authority RRs│ #additional RRs│
├────────────────────────────────┤
│ questions (질문 목록)          │
├────────────────────────────────┤
│ answers (정답 목록)            │
├────────────────────────────────┤
│ authority (권한서버 정보)      │
├────────────────────────────────┤
│ additional (도움되는 추가정보)  │
└────────────────────────────────┘
```

&ensp;꼭 보는 필드<br/>
* identification(16비트 번호): 질문과 답을 짝지어 주는 번호. (요청과 응답이 같은 번호)
* flags(깃발):
    - QR: 질의(0)/응답(1)
    - RD (Recursion Desired): “재귀로 알아와 주세요” (내 PC → 로컬 DNS에서 보통 1)
    - RA (Recursion Available): “난 재귀 가능해요” (로컬 DNS가 응답에 1로 돌려줌)
    - AA (Authoritative Answer): “이 답은 권한 서버에서 온 정답이에요”
* 섹션 4개:
    - Question: “이 이름(Type) 알려줘”
    - Answer: 진짜 정답(A/AAAA/CNAME…)
    - Authority: “다음에 여길 찾아가(NS)” 같은 안내
    - Additional: 안내해준 NS의 IP(Glue) 같은 도움 정보

&ensp;<b>도메인(레코드) 넣는 과정 (Inserting records)</b><br/>
&ensp;새 스타트업 networkutopia.com이 생겼다고 가정!<br/>
1. **Registrar(등록대행)**에서 도메인 구매 & 권한 네임서버 정보 제출
    - 예: dns1.networkutopia.com의 IP = 212.212.212.1
2. 이 정보가 Registry → .com TLD에 반영
    - .com TLD는 networkutopia.com의 NS 레코드와, 필요한 경우 NS의 A(Glue) 까지 저장
3. 회사는 스스로(또는 클라우드 DNS) 권한 DNS를 운영하며 존 파일에 아래 같은 레코드를 둠
    - A: www.networkutopia.com → 212.212.212.1
    - MX: networkutopia.com → mail.networkutopia.com 등
4. 누군가 www.networkutopia.com을 묻으면
    - 로컬 DNS가 루트→.com TLD→(NS/Glue로 안내)→권한 DNS 순으로 찾아가 A 레코드를 받아와 캐시/전달

&ensp;<b>보안 이슈 (DNS security)</b><br/>
* DDoS(분산 서비스 거부):
    - 많은 기기가 한꺼번에 특정 DNS(루트/TLD/권한)를 두들겨서 정상 이용을 어렵게 만드는 공격
    - 루트는 전 세계에 복제(Anycast)되고 필터링이 강해서 지금까지는 잘 버텨옴
    - TLD나 개별 권한 서버는 상대적으로 위험이 더 큼
* 가로채기/재지정(Man-in-the-middle, Redirect):
    - 누군가 DNS 응답을 중간에서 바꿔치기하여 가짜 IP로 보내는 공격
    - DNS 포이즈닝: 거짓 답변을 캐시에 심어 다수가 잘못된 곳으로 가게 만듦
* 증폭(Amplification) 악용:
    - 작은 질문에 큰 답이 돌아오는 성질을 악용해, 출발지 IP를 속여(타깃의 IP로) 타깃에게 큰 트래픽을 퍼붓게 만드는 형태
    - 예(개념): 60바이트 질문 → 0바이트 응답이면 약 50배로 커짐(증폭률)
    - 이런 이유로 많은 DNS 서버는 응답 크기 제한/필터링을 한다.
* DNSSEC:
    - "이 응답이 진짜 도메인 주인이 서명한 것이냐?"를 검증하는 기술(무결성/출처 인증)
    - 내용을 암호화하진 않지만, 위·변조를 잡아낼 수 있다.

P2P applications
=====

&ensp;P2P<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-35.png" width="600"></p>

* 상 켜져 있는 중앙 서버가 없음
    - 참여자(=피어, peer)들이 서로 직접 연결해서 필요한 걸 주고받는다.
* 모두가 손님이자 가게
    - 내가 받을 때는 손님(클라이언트), 받을 걸 다 받은 다음엔 남에게도 나눠줘서 가게(서버) 역할을 한다.
* 셀프 확장(Self-scalability)
    - 사람이 늘수록 트래픽을 쓰는 손님도 늘지만, 업로드 해 줄 사람도 같이 늘어난다. → 전체 처리 능력이 커진다.
* 현실의 어려움
    - 피어는 잠깐 접속했다가 나갔다가, 집 인터넷/NAT로 IP가 바뀌기도 해서 관리가 까다롭다.
* 예시
    - 파일공유(BitTorrent), 옛 스카이프(VoIP), 일부 P2P 스트리밍 등

&ensp;<b>파일 배포 속도: 서버-클라이언트 vs P2P</b><br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-36.png" width="600"></p>

&ensp;기호<br/>
* F: 파일 크기(비트 단위로 생각하면 쉬움)
* N: 받는 사람(피어) 수
* uₛ: 서버의 업로드 속도(Mb/s)
* dᵢ: i번째 피어의 다운로드 속도
* uᵢ: i번째 피어의 업로드 속도

&ensp;가정: 가운데 네트워크 대역은 충분(with abundant bandwidth), 병목은 업/다운 용량에만 있다고 본다.<br/>

&ensp;서버-클라이언트 방식의 하한<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-37.png" width="600"></p>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-38.png" width="600"></p>

&ensp;서버는 N명에게 N번 업로드해야 하므로 	
$\frac{N\cdot F}{u_s}$ 
가 걸림<br/>
&ensp;가장 느린 피어의 다운로드가 
$\frac{F}{min d_i}$
 이므로 그보다 빨리 끝낼 수 없음<br/>
* 결국 두 병목 중 큰 쪽이 전체 시간을 결정
* 서버 혼자 모든 걸 감당해야 함
* N명이 있으면 서버는 파일 F를 N번 업로드해야 해서 시간이 N에 비례해서 커짐

&ensp;P2P 방식의 하한<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-39.png" width="600"></p>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-40.png" width="600"></p>

* 서버는 처음 1회분(F)만 올리면 됨 → $\frac{F}{u_s}$ 
* 가장 느린 피어의 다운로드 제한은 동일 → $\frac{F}{min d_i}$
* N명에게 총 N회분(F×N)을 뿌려야 하지만 서버 + 모든 피어의 업로드를 합쳐서 처리 → $\frac{N\cdot F}{u_s \sum u_i}$
* 서버는 처음에 1번만 업로드하면 됨
* 이후 클라이언트들이 서로 파일 조각을 주고받음(업로드 + 다운로드 동시)
* 클라이언트가 늘어나도, 동시에 새로운 업로드 자원이 같이 생기니까 확장성(Self-Scalability)이 뛰어남

&ensp;사람 수(N)가 늘수록 ∑ui도 같이 커져서 배포 시간이 잘 안 늘어남(좋은 확장성)<br/>

&ensp;숫자로 직접 계산해보기<br/>
&ensp;가겹게 1GB 파일(편의상 8,000 Mb로 둠) <br/>
&ensp;서버 업 $u_s = 10 Mb/s$ <br/>
&ensp;모든 피어의 다운 $d_i = 20 Mb/s, 업 u_i = 5 Mb/s,$ <br/>
&ensp;피어 수 N = 10<br/>

&ensp;서버-클라이언트<br/>
* 서버 업로드 병목: $\frac{N\cdot F}{u_s} = \frac{10 \times 8000}{10} = 8000s$ 
* 가장 느린 다운로드: $\frac{F}{min d_i} = \frac{8000}{20} = 400s$
* 결론 $T_{cs} \geq max(8000, 400) = 8000s$ → 약 133.3분(2시간 13분)

&ensp;P2P<br/>
* 서버가 1회분 올리기: $\frac{F}{u_s} = \frac{8000}{10} = 800s$
* 가장 느린 다운로드: $\frac{F}{min d_i} = \frac{8000}{20} = 400s$
* 총 필요 업로드/총 업로드 능력: 

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-41.png" width="600"></p>

* 결론 $T_{p2p} \geq max(800, 400, 1333.3) =1333.3 s → 약 22.2분

&ensp;같은 조건에서 서버-클라이언트 133분 vs P2P 22분 -> 받은 사람들이 곧바로 업로더가 되어 일을 나눠 하기 때문<br/>

&ensp;N이 훨씬 더 커지면<br/>
&ensp;$\frac{N\cdot F}{u_s \sum u_i}$ 항은 $u_i$ 가 모두 비슷하다고 하면 $\sum u_i \approx N \cdot u$ 그래서 극한은 $\frac{N\cdot F}{u_s \sum u_i} \approx \frac{F}{u}$ 로 거의 일정해진다. (우리 숫자에선 $\frac{F}{u_i} = \frac{8000}{5} = 1600s \approx 26.7분$ 근처로 수렴) 반면 서버-클라이언트는 N에 비례해 계속 늘어남<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-42.png" width="600"></p>

* 가로축 (N): 클라이언트 수 (파일을 받고 싶어 하는 사용자 수)
* 세로축 (Minimum Distribution Time): 전체 파일을 모두에게 전송 완료하는 데 걸리는 최소 시간
* 검은 점 (Client-Server):
    - N이 늘어날수록 직선으로 계속 증가 (선형).
    - 이유: 서버 업로드 속도(us)가 한정돼 있는데, N명이 늘어나면 NF/us로 계속 커짐.
* 파란 네모 (P2P):
    - 처음에는 시간이 좀 걸리지만, 클라이언트가 늘어날수록 점점 증가율이 줄어듦
    - 일정 수준 이상에서는 거의 수평에 가까워짐
    - 이유: 피어가 늘어나면 다운로드 수요는 늘지만 업로드 자원도 같이 늘기 때문

&ensp;그래프에서 클라이언트 수가 커질수록 P2P는 완만, Client-Server는 가파르게 증가하는 차이 기억<br/>

P2P file distribution: BitTorrent 
-----

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-43.png" width="600"></p>

&ensp;;용어<br/>
* 파일을 조각(Chunk)으로 쪼갬: 보통 256KB 조각
    - 계산 예) 100MB → 100MB = 100×1024KB = 102,400KB  → 102,400 ÷ 256 = 400조각
    - 계산 예) 1GB 파일 → 1GB = 1024MB = 1,048,576KB →  1,048,576 ÷ 256 = 4,096조각
* 토렌트(torrent): 같은 파일 조각을 서로 주고받는 사람들 무리(스웜, swarm)
* 트래커(tracker): "누가 지금 참여 중인지" 목록을 관리하는 연락처 안내소
    - 새로 온 사람은 트래커에 접속 → 피어 목록을 받고 → 그중 몇 명과 연결을 시작한다.

&ensp;큰 파일을 한 덩어리로 받는 게 아니라 작은 레고조각처럼 나눠서 여러 사람에게서 동시에 받는다.<br/>

&ensp;새 피어가 들어오면<br/>
1. 초기엔 조각이 0개.
    - 트래커에서 이웃(peer) 몇 명을 받아 연결한다.
2. 다운로드하면서 동시에 업로드도 한다.
    - BitTorrent는 "나도 받는 중인데 이미 받은 조각은 남에게 나눠줘"가 기본 룰.
3. 이웃은 수시로 바뀔 수 있음(churn).
    - 누군가는 접속 종료, 누군가는 새로 들어옴 → 더 빠른 상대를 찾으며 이웃을 갈아끼움.
4. 다 받으면 두 가지 선택:
    - 바로 떠나는 사람(리치, leech)
    - 계속 남아 씨드(seeder) 역할로 업로드하는 사람(고마운 존재)

&ensp;"어떤 조각부터 받을까?" — 희귀 우선(rarest-first)<br/>
* 같은 순간, 각 피어가 가진 조각이 제각각이다.
* Alice는 주기적으로 이웃들에게 "너희가 가진 조각 목록(bitfield)을 알려줘!"라고 묻고 가장 희귀한 조각부터 요청한다.
    - 이유 1) 스웜 전체에 조각 종류가 고르게 퍼지도록 해서 막히지 않게 함.
    - 이유 2) 모두가 흔한 조각만 받다 보면 “마지막 몇 조각”이 없어 전체가 멈추는 현상(last-piece problem)을 막는다.

&ensp;"누구에게 보내줄까?" — 눈에는 눈, 이에는 이 (tit-for-tat)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-44.png" width="600"></p>

1. Alice가 Bob을 낙관적 언초크로 시험 송신.
2. Alice가 Bob의 Top-4에 들 정도로 잘 보내주면 Bob도 보답(상호성).
3. 결국 서로의 Top-4가 되어 속도가 더 빨라짐.

* Alice는 지금 자기에게 가장 빠르게 업로드해 주는 피어 상위 4명에게만 우선적으로 조각을 보내준다. → 나머지는 choked(목 졸림) 상태라 당장은 못 받음.
* 이 Top-4는 10초마다 다시 계산한다. 더 빨리 주는 사람이 나타나면 교체!
* 30초마다는 임의의 새 사람 1명에게 시험적으로 보내준다(optimistic unchoke).
    - "새 거래 상대를 탐색"하는 슬롯.
    - 운 좋게 더 빠른 상대를 찾으면 그 사람이 Top-4에 들어오고, 속도가 더 올라간다.
    - 메시지: 잘 올려주는 사람이 더 좋은 상대를 만나고 더 빨리 받는다. (공정한 인센티브)

&ensp;속도가 빠른 이유<br/>
* 조각을 여러 사람에게서 동시에 받음(병렬).
* 받은 사람은 곧바로 다른 사람에게 업로드 시작 → 총 업로드 능력이 눈덩이처럼 커짐.
* 희귀 우선 + tit-for-tat 덕분에
    - 조각이 고르게 퍼지고 잘 업로드하는 피어가 더 빨리 받아 전체 속도가 유지됨.


video streaming and content distribution networks
=====

&ensp;스트리밍<br/>
* 다운로드는 파일 전체를 다 받은 뒤 재생
* 스트리밍은 받으면서 바로 재생, 플레이어가 버퍼(대기 공간)에 몇 초치만 쌓아두고 이어서 틀어준다.

&ensp;문제점<br/>
1. 규모(Scale): 한 대의 초거대 서버가 10억 명을 동시에 감당할 수 없음
    - 예: 사용자 100만 명이 5 Mb/s로 본다면 총 대역폭 = 5,000,000 Mb/s = 5 Tb/s. 한 서버로 불가능
2. 이질성(Heterogeneity): 사람마다 기기·네트워크가 제각각(광랜, LTE, 3G, 지하철…). 어떤 사람은 20 Mb/s, 어떤 사람은 1 Mb/s도 안 나올 수 있음.

&ensp;해결: CDN(콘텐츠 전송망)<br/>
* 동영상 사본을 전 세계 수천 개 엣지 서버에 미리 뿌려둠
* 동영상을 재생하면 가까운 엣지에서 가져오니 지연↓ 끊김↓, 본사(원서버) 부하↓
* DNS로 가장 가까운/가장 덜 혼잡한 엣지 우회 지정하는게 흔한 방식

Multimedia: video
----

&ensp;영상을 데이터로 보면 무엇?<br/>
* 초당 여러 장의 사진(프레임): 예) 24fps면 초당 24장
* **사진(디지털 이미지)**는 픽셀들의 모음, 픽셀은 **RGB 값(비트)**으로 저장

&ensp;압축(코딩) 아이디어 두 가지<br/>
1. 공간(spatial) 중복 제거: 한 프레임 안에서 같은 색이 반복되면 → "보라색 200픽셀" 처럼 색 + 반복개수만 적는다(런-렝스 같은 원리)
2. 시간(temporal) 중복 제거: 연속 프레임은 비슷하니 → **완전한 그림(I-frame)**은 가끔만 보내고, 그 사이엔 **달라진 부분(P/B-frame)**만 보낸다.

&ensp;압축이 필요한 이유<br/>
* 원본(압축 전) 1080p 30fps라고 가정: 1920×1080 픽셀 × 24비트(3바이트) × 30fps
= ~1.49 Gbit/s(초당 186 MB) → 집 인터넷/모바일로는 절대 못 받음
* 압축(H.264/H.265 등)을 쓰면 보통 2~8 Mb/s(HD 기준)로 떨어뜨려 실사용 가능해짐.

&ensp;CBR vs VBR<br/>
&ensp;CBR (Constant Bit Rate, 고정 비트레이트)<br/>
* 매 초마다 비슷한 양의 데이터를 보냄(예: 늘 4 Mb/s)
* 장점: 네트워크·서버가 예측하기 쉬움(대역폭 예약에 유리)
* 단점: 화면이 복잡한 장면도 같은 양으로 보내야 해서 품질이 요동할 수 있음

&ensp;VBR (Variable Bit Rate, 가변 비트레이트)<br/>
* 장면이 복잡하면 많이, 단순하면 적게 보냄
* 장점: 평균 비트레이트 대비 화질↑
* 단점: 순간적으로 치솟는 구간이 있어 네트워크가 감당 못하면 끊길 수도 → 버퍼로 완충

&ensp;실전 스트리밍은 CBR/VBR 한 가지만 고집하지 않고, **적응형 비트레이트(ABR)**를 쓴다. 같은 영상의 여러 품질(240p~4K)을 준비해 놓고 플레이어가 현재 속도를 보고 자동으로 오가며 끊김을 줄인다.(HLS, MPEG-DASH 등)

&ensp;비트레이트와 데이터 사용량 감각 잡기<br/>
* 공식: 시간(초) × 비트레이트(Mb/s) = 총 Mb → ÷8 하면 MB.
* 예1) 1080p 5 Mb/s로 1시간 시청_3600s × 5 Mb/s = 18,000 Mb = 2,250 MB ≈ 2.2 GB
* 예2) 720p 3 Mb/s로 30분_1800s × 3 = 5,400 Mb = 675 MB

&ensp;코덱·예시 비트레이트<br/>
* MPEG-1: ~1.5 Mb/s(옛 CD-ROM 영상)
* MPEG-2: 3–6 Mb/s(DVD/디지털방송)
* MPEG-4 계열(인터넷): 수십 Kb/s ~ 12 Mb/s(화질·해상도·코덱에 따라 넓게 분포) (현대에는 H.264/AVC, H.265/HEVC, AV1 등도 많이 씀)

Streaming stored video
-----

&ensp;스트리밍의 핵심 그림<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-45.png" width="600"></p>

* 서버에 저장된 영상 → 인터넷 → 클라이언트(내 폰/TV) 로 온다.
* 네트워크 상황(집 와이파이·통신사·중간 경로 혼잡)이 계속 바뀌어서, 순간 속도와 지연이 들쭉날쭉하다.

<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-46.png" width="600"></p>

*  계단 그래프 의미:
    - 가로축: 시간, 세로축: 누적 전송량(얼마나 많이 보냈나/받았나)
    - 빨간 계단: 서버가 영상을 보내는 누적량
    - 파란 계단: 클라이언트가 받은 누적량(네트워크 지연만큼 늦게 따라옴)
    - 재생 계단(파란색 우측): 클라이언트가 일정 속도(예: 30fps)로 영상을 화면에 틀어내는 양
    - 점선 순간에 “앞부분은 이미 재생 중인데, 서버는 뒷부분을 아직 전송 중” → 이게 바로 스트리밍

&ensp;저장된 비디오 스트리밍의 어려움<br/>
&ensp;비디오를 서버에서 클라이언트(내 PC, 스마트폰)로 스트리밍할 때 생기는 주요 문제들이다.<br/>

&ensp;1. 연속적인 재생(continuous playout constraint)<br/>
* 영상은 끊기지 않고 원래 타이밍 그대로 재생되어야 한다.
* 예를 들어 영화가 초당 30프레임이면, 네트워크에서 어떤 일이 있어도 클라이언트는 초당 30프레임 속도로 재생해야 함.
* 하지만 문제는 **네트워크 지연(delay)**이 일정하지 않다는 점이에요. 이를 **jitter(지터)**라고 부른다.

&ensp;해결 방법: 클라이언트 측 버퍼(client-side buffer)<br/>
* 영상을 일정 부분 미리 받아서 저장(버퍼링)해 두고, 지연이 생겨도 안정적으로 이어서 재생할 수 있게 한다.
* 유튜브에서 로딩(동그라미 빙글빙글 도는 거) → 이게 바로 버퍼링!
    - 버퍼 언더런: 버퍼가 바닥나서 재생이 멈추는 상태('빙글빙글 로딩')

&ensp;2. 기타 도전 과제<br/>
* 사용자 상호작용: 사용자가 멈춤, 빨리 감기, 뒤로가기 등을 하면 서버가 그 요청을 맞춰 다시 데이터를 보내야 함
* 패킷 손실: 네트워크에서 비디오 데이터가 손실될 수 있고 이 경우 재전송이 필요함

&ensp;Streaming stored video: playout buffering (재생 버퍼링)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-47.png" width="600"></p>

* 빨간선 (server transmission) → 서버에서 일정한 속도로 비디오 데이터를 계속 보냄 (constant bit rate)
* 검은 선 (client video reception) → 네트워크 지연 때문에 클라이언트가 데이터를 받는 시간은 들쭉날쭉(변동 delay)
* 파란 선 (client video playout) → 클라이언트가 실제 영상을 재생하는 속도는 일정해야 함 (끊기지 않고 일정한 속도)

&ensp;그래서 client playout delay가 필요하다.<br/>
* 영상을 바로 재생하지 않고 데이터를 조금 모아서 버퍼에 쌓은 뒤 재생을 시작
* 이렇게 하면 네트워크 지연(jitter)을 흡수해서 시청자가 끊김 없는 영상을 볼 수 있게 한다.

&ensp;<b>DASH(Dynamic Adaptive Streaming over HTTP)</b><br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-48.png" width="600"></p>

&ensp;영상을 몇 초짜리 조각(chunks)으로 잘라 여러 화질(여러 비트레이트)로 준비해 두고 클라이언트(내 폰/TV)가 그때그때 네트워크 상황을 재보면서 다음 조각의 화질을 선택해서 HTTP로 하나씩 받아오는 방식<br/>

&ensp;서버가 하는 일<br/>
1. 원본 영상을 조각으로 분할(보통 조각 길이 2~10초)
2. 각 조각을 여러 화질로 인코딩해 저장
    - 예: 0.8 / 1.5 / 3 / 5 / 8 Mb/s
3. 매니페스트(manifest, MPD) 파일 제공
    - 어떤 화질이 있고 각 조각은 어디(URL)서 받는지 목록표

&ensp;클라이언트가 하는 일<br/>
1. 주기적으로 속도 측정
    - 방금 받은 조각의 크기(비트) ÷ 다운로드에 걸린 시간(초) = 측정 대역폭(Mb/s)
2. 매니페스트를 참고해 조각을 하나씩 요청
    - 현재 속도로 무리 없이 유지할 수 있는 최대 화질을 골라 요청
3. 조각마다 화질을 바꿀 수 있음
    - 지금 빠르면 5 Mb/s, 다음이 느리면 3 Mb/s로 즉시 낮춤

&ensp;요저: 지능은 클라이언트에 있다.<br/>
* 언제 다음 조각을 받을지(버퍼가 모자라거나 넘치지 않게)
* 어떤 화질을 받을지(대역폭 충분하면 ↑)
* 어디서 받을지(CDN 엣지 중 가까운/덜 붐비는 서버)

&ensp;숫자로 감 잡기 (간단 계산 예)<br/>
* 조각 길이 = 4초, 선택지 화질 = 1 / 2.5 / 5 / 8 Mb/s
* 방금 측정한 네트워크 = 6 Mb/s, 현재 버퍼 = 12초

&ensp;조각 크기<br/>
* 1 Mb/s 조각 = 1×4 = 4 Mb
* 2.5 Mb/s 조각 = 10 Mb
* 5 Mb/s 조각 = 20 Mb
* 8 Mb/s 조각 = 32 Mb

&ensp;다운로드 예상 시간(= 조각크기 ÷ 측정대역폭 6 Mb/s)<br/>
* 5 Mb/s 조각(20 Mb) → 3.33초
* 8 Mb/s 조각(32 Mb) → 5.33초

&ensp;버퍼 12초가 있으니 5 Mb/s는 안전, 8 Mb/s도 가능은 하지만 여유가 적음. 보통은 안전 마진(예: 측정값의 70–90%)을 두고 5 Mb/s를 고른 다음, 속도가 더 오르면 그때 8로 올린다.<br/>

&ensp;속도가 뚝 떨어지면?<br/>
* 다음 10초 동안 2 Mb/s로 하락했다고 가정
* 5 Mb/s 조각(20 Mb)을 2 Mb/s로 받으면 10초가 걸림 → 조각 길이(4초)보다 훨씬 김 → 버퍼 소진 위험
* 그래서 즉시 2.5 Mb/s나 1 Mb/s로 화질을 낮춰 받으며 버퍼를 지킴

&ensp;버퍼와 요청 타이밍(언제 받을지)<br/>
* 플레이어는 버퍼 목표치를 잡아요(예: 20–30초)
* 버퍼가 목표보다 낮아지면 빨리 다음 조각을 받고
* 충분히 높으면 잠깐 쉬었다가 받아 네트워크/배터리 효율을 챙긴다.
* 이때 버퍼 기반(BBA), 대역폭 기반(throughput), 하이브리드 같은 ABR 알고리즘을 쓴다.

&ensp;어디서 받을지(WHERE)<br/>
* 매니페스트에 여러 Base URL이 있을 수 있어요(CDN 엣지들)
* 클라이언트는 가까운 서버나 더 빠른 서버를 택해 조각을 요청(또는 DNS가 근접 엣지로 유도)

&ensp;결과적으로<br/>
&ensp;Streaming video = 인코딩(여러 화질) + DASH(조각·선택) + 버퍼링 → 느려지면 화질 낮춰 끊김 방지, 빨라지면 화질 올려 더 선명하게.<br/>

CDN(Content Distribution Network)
-----

&ensp;초거대 서버 한 대’(option 1)가 실패하는 이유<br/>
&ensp;한 서버가 동시에 10만 명에게 1개 영상을 5 Mb/s로 쏜다고 해보자 → 필요 대역폭 = 5 Mb/s × 100,000 = 500 Gb/s<br/>
* 단일 고장점(SPOF): 그 서버/회선이 문제 나면 전부 다운
* 혼잡의 한가운데: 나가는 회선에서 같은 영상을 N번(사용자 수만큼) 반복 전송 → 회선 포화
* 거리 문제: 멀리 있는 이용자일수록 지연·손실 ↑, 품질 ↓
* 한마디로 스케일이 안 된다(doesn’t scale)

&ensp;해결책 = CDN(option 2)<br/>
&ensp;여러 지역에 서버(캐시)를 많이 두고 영상 사본을 저장해 둔다. 사용자는 가까운 캐시에서 받는다.<br/>
&ensp;두 가지 배치 철학<br/>
* enter deep: 아주 많은 작은 캐시를 각 지역망 깊숙이 넣음(이용자와 초근접). 장점: 지연↓, 속도↑. 단점: 박스 관리가 많음. (Akamai 스타일)
* bring home: 각 지역의 거점(POP) 근처에 큰 클러스터를 적은 수 운영. 장점: 운영 쉽고 규모의 경제. 단점: 거리 약간 늘 수 있음. (Limelight 스타일)

&ensp;내가 플레이를 누르면 실제로 무슨 일이?<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-49.png" width="600"></p>

1. DNS/매핑: 앱이 video.cdn.com을 조회 → CDN이 가장 가까운·덜 바쁜 엣지 IP를 돌려줌(지리/IP, RTT 측정, 부하, 헬스 체크를 고려. 때로는 Anycast, HTTP 302 리다이렉트도 사용)
2. 매니페이스(MPD/HLS) 받기: 영상의 조각 목록 + 여러 화질 URL
3. ABR 결정(DASH): 플레이어가 최근 다운로드 속도를 보고 다음 조각 화질을 고름
4. 캐시 히트면 바로 제공, 미스면 엣지가 상위(미들/오리진)에서 가져와 저장 후 제공
5. 경로가 막히거나 노드가 과부화면 다른 엣지로 스티어링(DNS 재응답/리다이렉트)하거나 클라이언트가 다른 Base URL로 전환

&ensp;결과: 백본 트래픽 분산, 사용자와의 물리적 거리 단축, 서버 부하 분산 → 대규모 동시 접속에도 매끈<br/>

&ensp;캐시 내용(콘텐츠 배치)<br/>
* 인기도 기반(Zipf): 많이 보는 것부터 엣지에
* 프리워밍: 신작 공개 전, 예상 인기 지역 캐시에 미리 적재
* TTL/무효화: 업데이트 시 빠르게 갱신
* 계층 캐시: Edge → Mid-tier → Origin 으로 부하 완충

&ensp;이용자 요청이 다른 복사본으로 바뀌는 이유<br/>
* 현재 경로가 혼잡/패킷 손실↑ → 가장 가까운 다른 노드로 재지정
* 같은 도시는 여러 복사본을 가질 수 있어 자체적인 회피가 가능

&ensp;<b>OTT(Over-The-Top)</b><br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-50.png" width="600"></p>

&ensp;넷플릭스 같은 서비스가 ISP의 전용망이 아닌 인터넷 위에서 동영상을 제공하는 모델
&ensp;challenges<br/>
* 어느 CDN 노드에서 줄지(지연/처리량/부하 고려)
* 혼잡 시 시청자 행동(이탈 vs 화질↓)을 고려한 ABR·스티어링 전략
* 어떤 콘텐츠를 어느 노드에 둘지(인기도 예측, 지역별 취향)

&ensp;a closer look<br/>
&ensp;상황: Bob이 http://netcinema.com/6Y7B23V 영상을 보려고 함. 이 영상 실제 파일은 KingCDN이라는 CDN에 저장돼 있고, netcinema는 CDN을 “대행 창고”처럼 쓰는 중.<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-51.png" width="600"></p>

&ensp;누가 누구?<br/>
* netcinema.com: 콘텐츠 제공자(영화 서비스).
* KingCDN: 전세계에 캐시 서버(엣지 서버)를 깔아 둔 CDN 사업자.
* Bob의 로컬 DNS: Bob PC가 평소 쓰는 DNS(학교/통신사/공용 DNS).
* authoritative DNS: 어떤 도메인의 “최종 답변자”. netcinema의 권한 DNS, KingCDN의 권한 DNS가 각각 따로 있음.

&ensp;단계별 흐름<br/>
1. URL 획득: Bob이 netcinema 웹페이지를 보고, 거기에 적힌 영상 URL(netcinema.com/6Y7B23V)을 클릭
2. 도메인 이름을 IP로 바꾸기 시작: 브라우저는 먼저 Bob의 로컬 DNS에게 "netcinema.com의 IP 좀 알려줘"라고 질의
3. CNAME 반환(별칭) – CDN으로 넘김: netcinema.com의 authoritative DNS는 “그 파일은 우리 서버가 직접 주지 않고 CDN이 대신 줘”라며 CNAME을 돌려줌. 예: NetC6y&B23V.KingCDN.com 같은 별칭.
    - CNAME = “이 이름은 사실 저 도메인의 별명입니다”라는 DNS 레벨의 우회(리다이렉트).
4. CDN 권한 DNS에게 다시 질의: Bob의 로컬 DNS는 이제 KingCDN의 authoritative DNS에게 CNAME에 담긴 CDN 호스트 이름의 IP를 물어봄.
5. 가장 '가까운' 엣지 서버 IP 선택: KingCDN의 권한 DNS는 Bob의 위치(정확히는 질의해 온 로컬 DNS의 위치)를 보고, 지리적으로/네트워크상 가까운 엣지 서버의 IP를 골라서 응답.
(여기서 CDN은 트래픽, 서버부하, 지연 등을 고려해 DNS 기반 로드밸런싱/지오DNS로 최적의 서버를 고름)
6. HTTP로 동영상 요청 → 스트리밍 시작: 브라우저는 이제 받은 엣지 서버 IP로 직접 HTTP GET을 보내고, 세그먼트(조각) 단위로 영상을 받아 재생
    - **캐시 적중(hit)**이면 바로 전송
    - **캐시 미스(miss)**면 엣지 서버가 CDN의 원본(오리진)에서 가져와 캐시에 저장한 뒤 Bob에게 전달

&ensp;DNS 질의 과정에서 CNAME으로 CDN으로 넘기고, CDN 권한 DNS가 '가까운 엣지 서버'의 IP를 골라줘서, 최종 재생은 그 엣지 서버와 직접 HTTP로 이뤄진다.<br/>

&ensp;Netflix<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-52.png" width="600"></p>

&ensp;그림에선 “Amazon cloud(관리/메타)” + “CDN 서버(전송)”로 역할이 나뉜 모습(실제 넷플릭스는 계정/카탈로그/컨트롤면은 클라우드에서, 영상 전송은 전 세계 엣지에서 처리)<br/>

&ensp;단계별 흐름<br/>
1. 계정/결제/관리 트래픽: Bob이 로그인/계정 관리 등을 하면 이것들은 **넷플릭스의 백엔드(클라우드)**가 처리
2. 카탈로그 탐색: Bob이 어떤 영상을 볼지 브라우징 → 메타데이터(제목/썸네일/가용 화질/자막 등)는 클라우드 쪽 API가 응답
3. Manifest(매니페스트) 파일 받기: 특정 영상을 재생하려고 하면, 플레이어는 매니페스트 파일(DASH의 MPD, 또는 HLS의 m3u8 비슷한 것)을 요청/수신
    - 매니페스트에는 영상이 잘게 나뉜 세그먼트들의 URL이, 여러 화질/비트레이트 버전별로 나열돼 있음.
4. 플레이어가 ‘어떤 CDN 서버·어떤 화질’을 고를지 결정 → 스트리밍 시작: 플레이어는 네트워크 속도/버퍼 상황을 보며 적절한 비트레이트의 세그먼트 URL을 골라 가까운 CDN 서버에 순차적으로 HTTP GET.
    - 이게 DASH(동적 적응 스트리밍): 상황에 맞춰 화질을 오르내리며 끊김 없이 재생하려는 메커니즘.
    - 세그먼트는 2~10초짜리 작은 조각들이고, 플레이어는 조각을 하나씩 받아 버퍼에 넣으면서 재생을 이어감.

&ensp;왜 이렇게 나눠서 하냐?<br/>
* 확장성: 계정/결제 같은 “관리 트래픽”은 클라우드가 처리, 대용량 동영상 전송은 전 세계 CDN 엣지가 담당 → 서로 독립적으로 확장 가능
* 지연/품질: 시청자는 “가장 가까운 엣지”에서 받아서 지연↓, 끊김↓
* 적응 스트리밍: 네트워크가 느려지면 낮은 화질 조각을, 빨라지면 높은 화질 조각을 요청 → 버퍼링 최소화

&ensp;핵심 개념 정리<br/>
* CNAME: "이 이름은 저쪽 도메인의 별칭"이라는 DNS 레벨 우회. 웹 302 리다이렉트와 달리 DNS 단계에서 일어남
* authoritative DNS: 특정 도메인에 대해 최종 권한을 가진 DNS. 정답을 알고 있는 곳
* 로컬 DNS(리졸버): 우리 PC/폰이 평소 질의 보내는 DNS. 여기서 캐싱도 해서 다음 요청을 빠르게 함
* 엣지 서버(POP): 사용자의 가까운 곳에 있는 CDN 캐시 서버. 캐시 히트면 즉시 응답, 미스면 상위로부터 받아 캐싱
* DASH/HLS + 매니페스트: “세그먼트 목록과 품질 옵션”을 담은 지침서. 플레이어가 상황에 맞춰 조각을 골라 받는 구조

&ensp;자주 헷갈리는 포인트<br/>
* "왜 굳이 CNAME으로 CDN에 넘기나?" → 콘텐츠 사업자는 자신의 도메인만 노출하고 싶고, 어느 CDN/어느 엣지로 보낼지 유연하게 바꾸기 쉬움. DNS만 손대면 배포 정책을 바꿀 수 있다.
* "가까운 서버는 어떻게 고르나?" → 보통 DNS 질의가 들어온 리졸버의 위치(또는 EDNS Client Subnet 확장)를 기반으로, 지연/부하 등을 고려해 CDN 권한 DNS가 가장 적합한 엣지 IP를 돌려줌
* "공용 DNS(예: 8.8.8.8)를 쓰면?" → 리졸버 위치가 사용자와 다를 수 있어 최적 선택이 틀어질 수 있음. (그래서 EDNS Client Subnet 같은 보완책을 쓰기도 함)

socket programming with UDP and TCP
=====

&ensp;큰 그림: 애플리케이션 계층이 뭐예요?<br/>
&ensp;인터넷은 여러 층(계층)으로 이루어진 다층 케이크라고 생각하면 쉽다.<br/>
* 맨 위 애플리케이션 계층: 우리가 쓰는 서비스(웹, 이메일, 채팅, 넷플릭스, 게임 등)
* 아래 전송/네트워크/링크/물리 계층: 데이터를 잘라서 보내고, 주소 붙이고, 케이블·Wi-Fi로 실제로 옮기는 "배달 시스템"

&ensp;우리는 주로 맨 위층 앱을 만드는데, 이 앱이 아래 배달 시스템을 이용하려면 창구가 필요하다. 그 창구가 바로 소켓(socket) 이다<br/>

&ensp;<b>소켓</b><br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-53.png" width="600"></p>

&ensp;소켓 = 앱과 인터넷 사이의 문(창구)<br/>
* 앱 개발자는 소켓에다 보낼 데이터를 밀어 넣거나 받은 데이터를 꺼낸다.
* 그 아래(전송/네트워크/링크/물리)는 운영체제(OS)가 알아서 처리한다.
* 비유: 택배 접수 창구처럼 생각하면 편하다. 창구(소켓)에 상자를 맡기면, 뒤에서 택배망(TCP/UDP, IP, 케이블)이 알아서 배달한다.

&ensp;추가로 꼭 알아둘 개념<br/>
* IP 주소 = 건물 주소, 포트 번호 = 호수 예) 203.0.113.10:80 → 203.0.113.10 건물의 80호(웹 서버)

&ensp;소켓의 종류 두 가지<br/>
&ensp;1) UDP 소켓 (엽서/택배 우편 느낌)<br/>
* 특징: 빠름, 가벼움, 하지만 잃어버리거나(유실) 순서가 뒤바뀔 수도 있음
* 형태: 데이터그램(datagram) = 조각 하나하나가 독립된 ‘엽서’
* 연결 절차 없음: 그냥 보냄. 받는 쪽이 못 받으면 끝. (알아서 재전송 같은 걸 안 해줌)
* 사용 예: 실시간성이 중요한 것들 → 라이브 방송, 화상통화, 온라인 게임, DNS 조회

&ensp;2) TCP 소켓 (전화 통화/등기 택배 느낌)<br/>
* 특징: 믿을 수 있음(reliable), 순서 보장, 빠진 조각 있으면 재전송
* 형태: 바이트 스트림(stream) = 물이 흐르듯 끊기지 않는 연속 데이터
* 연결(handshake) 후 통신: 먼저 “전화 연결” 같은 절차를 한 뒤 주고받음
* 사용 예: 웹(HTTP/HTTPS), 파일 다운로드, 이메일, 메신저 텍스트

&ensp;정리 한 줄<br/>
* UDP = 빠른 엽서, 분실/순서 뒤바뀜 가능
* TCP = 느긋하지만 안전한 등기/전화, 순서·완전성 보장

&ensp;아주 간단한 예시 흐름<br/>
&ensp;"클라이언트가 한 줄을 보내면, 서버는 대문자로 바꿔서 돌려준다"<br/>
* (1) 클라이언트: 키보드에서 "hello" 읽음 → 소켓에 보냄
* (2) 서버: 소켓에서 "hello" 받음 → "HELLO"로 가공
* (3) 서버: "HELLO"를 클라이언트에게 보냄
* (4) 클라이언트: "HELLO"를 받아 화면에 출력

&ensp;이 예제는 TCP로 하면 "차례대로, 안 빠지고" 오가고, UDP로 하면 "가끔 빠지거나 순서가 바뀔 수도" 있다. (대신 설정이 간단하고 빠름)<br/>

&ensp;<b>UDP</b><br/>
* 연결 없음: "안녕, 바로 보낼게!" → 사전 악수(handshake) 없음
* 매번 주소를 붙임: 보낼 때마다 상대 IP/포트를 봉투에 적어 보냄
* 받는 쪽은 발신 정보 추출: 받은 봉투에서 보낸 사람 IP/포트를 읽어 답장 가능
* 신뢰성 X:
    - 유실 가능(중간에 잃어버릴 수 있음)
    - 순서 뒤바뀜 가능(2번 봉투가 1번보다 먼저 도착)
    - 중복 가능(같은 봉투가 두 번 올 수도)
* 그래서 실시간 스트리밍/게임 처럼 "조금 빠져도 계속 흘러가야 하는" 서비스에 잘 맞는다.
만약 정확성이 중요하면, 앱이 스스로 재전송/번호 붙이기/정렬 같은 보완을 해야 한다.

&ensp;서버/클라이언트 기본 역할<br/>
&ensp;서버<br/>
1. 문 열기: 특정 포트에 소켓을 열고 대기(listen)
2. 손님 받기(TCP라면 연결 accept) / (UDP라면 바로 recvfrom)
3. 데이터 처리하고 응답
4. 연결 종료(TCP) 또는 계속 반복

&ensp;클라이언트<br/>
1. 상대 IP·포트 결정(DNS로 이름→IP 변환)
2. 소켓 열기, (TCP는) 연결 시도
3. 데이터 전송/수신
4. 종료

&ensp;서버는 보통 80/443호(HTTP/HTTPS)에서 기다린다.<br/>
&ensp;클라이언트는 매번 **임시 포트(에페멀 포트)**를 자동으로 배정받아 사용한다.<br/>

&ensp;언제 뭘 쓸까?<br/>
* 웹, 파일, 은행, 로그인, 메신저 텍스트 → TCP (정확/순서가 중요)
* 화상통화, 라이브 방송, 온라인 게임, DNS → UDP (지연↓, 일부 손실 감내)

&ensp;UDP에서 클라이언트–서버가 어떻게 말 주고받나<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-54.png" width="600"></p>

&ensp;서버쪽<br/>
1. 소켓 만들기: socket(AF_INET, SOCK_DGRAM)
* AF_INET : IPv4를 쓴다
* SOCK_DGRAM : UDP(데이터그램) 방식
2. 포트 번호에 바인드(bind): "우리 가게(서버)는 포트 x번에서 손님을 받습니다" 하고 표지판을 거는 것.
3. recvfrom()로 받기: 편지(데이터그램)를 받으면 **내용 + 보낸 주소(IP, 포트)**를 함께 얻음.
4. sendto()로 답장: 방금 받은 보낸 사람 주소로 답장 보냄(“대문자로 바꿔서 돌려주기” 같은 처리)

&ensp;UDP는 연결 절차가 없다는 게 포인트. accept() 같은 것도 없음. 그냥 "오면 받는다, 주소 보고 보낸다"<br/>

&ensp;클라이언트 쪽<br/>
1. 소켓 만들기 (같이 AF_INET, SOCK_DGRAM)
2. sendto()로 보냄: 봉투에 서버 IP와 포트를 적어서 보냄.
3. recvfrom()로 답장 받기
4. 소켓 닫기

&ensp;UDP의 성격<br/>
* 빠름/가벼움, 연결 없음
* 유실/중복/순서 뒤바뀜 가능 → 아주 정확해야 하는 데이터엔 부적합 (필요하면 앱에서 번호 붙여 재전송/정렬을 직접 구현)
* 실시간 성능이 중요한 곳(게임, 음성/영상, DNS)에 자주 사용

&ensp;<b>TCP</b><br/>
* 서버가 먼저 대기해야 해요. “우리 가게는 포트 X번에서 손님 받아요”라고 문을 열어 둠
* **클라이언트가 전화 걸기(connect)**를 하면
* 서버의 TCP가 그 손님 전용 새 소켓을 하나 더 만들어 준다. → 그래서 서버는 동시에 여러 손님과 각각 별도 소켓으로 대화 가능!
* 애플리케이션 입장에서 TCP는 믿을 수 있고(in-order, reliable) 끊기지 않는 파이프(stream) 를 제공

&ensp;꼭 알아둘 TCP 특징 & 팁<br/>
&ensp;· 스트림(연속 바이트)이라 ‘메시지 경계’가 없음<br/>
&ensp;→ send() 한 번 보냈다고 recv() 한 번에 같은 덩어리로 오리란 보장 X<br/>
&ensp;→ 실제 서비스에선 구분자(\n), 길이 헤더 등을 붙여서 프레이밍을 직접 정한다.<br/>
&ensp;· 신뢰성/순서 보장: 분실·중복·순서 뒤바뀜을 TCP가 자동으로 처리(재전송, 정렬)<br/>
&ensp;· 동시 접속: accept()가 새 소켓을 만들어 주므로, 각 손님은 자기 전용 소켓으로 대화, 실무에선 스레드/프로세스/비동기(Asyncio, epoll 등)로 여러 손님을 병렬 처리<br/>
&ensp;· 클라이언트 임시 포트(에페멀 포트): connect() 하면 OS가 자동 배정. 서버는 고정 포트(예: 80, 443, 여기선 12000)로 대기<br/>
&ensp;· listen(backlog): 동시에 대기열에 쌓일 수 있는 “벨 울림” 최대치. 너무 작으면 과부하 시 거절될 수 있다.<br/>
&ensp;· send() vs sendall(): send()는 일부만 보낼 수 있음 → 반복 필요. 처음엔 sendall() 권장<br/>
&ensp;· 방화벽/충돌 에러: <br/>
&ensp;- 포트 막힘 → 방화벽 허용<br/>
&ensp;- “Address already in use” → SO_REUSEADDR 설정, 또는 포트 변경<br/>

&ensp;UDP vs TCP<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter2. Application layer/2-55.png" width="600"></p>

&ensp;TCP 소켓을 이용해서 클라이언트와 서버가 대화하는 과정<br/>
&ensp;서버쪽<br/>
1. 소켓 생성: serverSocket = socket() → 서버는 “문(창구)”을 하나 열어요. 아직 누구랑 연결된 건 아님
2. 포트 지정(bind) + 대기(listen): 그림에선 생략됐지만, 서버는 “포트 X번에서 손님을 받겠다” 하고 기다린다.
3. 연결 요청 수락: connectionSocket = serverSocket.accept() → 클라이언트가 “저 연결하고 싶어요” 하고 TCP 연결을 걸면, 서버는 새로운 소켓을 만들어 그 클라이언트 전용으로 배정. serverSocket은 "환영 전용 문", connectionSocket은 "특정 손님 전용 창구"
4. 데이터 주고받기
* read request from connectionSocket : 클라이언트가 보낸 요청 읽기
* write reply to connectionSocket : 응답 쓰기
5. 닫기: 대화가 끝나면 connectionSocket.close() (단 serverSocket은 계속 열려 있어야 다음 클라이언트도 받을 수 있음)

&ensp;클라이언트 쪽<br/>
1. 소켓 생성: clientSocket = socket()
2. 서버에 연결(connect): connect(hostid, port=x) → 서버의 주소와 포트를 지정해 전화 걸듯 연결
3. 데이터 전송: send request using clientSocket → 예: "hello 서버!"
4. 응답 받기: read reply from clientSocket → 예: "HELLO 클라이언트!"
5. 닫기: clientSocket.close()

&ensp;TCP 연결의 특징<br/>
* 연결 설정 과정(connection setup) : 클라이언트가 연결을 시도하면, TCP는 내부적으로 3-way handshake를 해서 연결을 확립한다.
* 신뢰성 보장 : 메시지가 빠지거나 순서가 바뀌면 TCP가 자동으로 처리해서 애플리케이션은 안전하게 읽기/쓰기만 하면 됨
* 서버는 다수 클라이언트 동시 처리 가능 : 각 클라이언트마다 새로운 connectionSocket을 만들어서 병렬로 대화