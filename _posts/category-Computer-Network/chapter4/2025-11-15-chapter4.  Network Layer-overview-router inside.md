---
title: "chapter4. Network Layer-What's inside a router"
excerpt: ""

wirter: sohee Kim
categories:
  - Computer Network
tags:
  - CS

toc: true
use_math: true 
toc_sticky: true

date: 2025-11-15
last_modified_at: 2025-11-21
---

&ensp;라우터 내부 구성 (What's inside a router)<br/>
&ensp;주요 구성 요소:<br/>
* input ports (입력 포트)
* switching (스위칭)
* output ports (출력 포트)
* buffer management (버퍼 관리)
* scheduling (스케줄링)

Router Architecture Overview
=====

&ensp;라우터는 크게 두 영역으로 나뉜다.<br/>
&ensp;1. Control Plane (라우팅 제어)<br/>
* Routing processor(소프트웨어)에서 동작
* 경로 계산(routing), 관리 기능 수행
* millisecond 단위로 동작 (비교적 느림)

&ensp;Data Plane (패킷 전달)<br/>
* hardware 기반
* 포워딩(switching)을 나노초(nanosecond) 단위로 처리 (매우 빠름)
* high-speed switching fabric이 핵심

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-5.png" width="500"></p>

* 왼쪽: input ports에서 패킷이 들어옴
* 중앙: switching fabric이 패킷을 적절한 output port로 전달
* 오른쪽: output ports에서 외부로 내보냄
* 위: routing processor가 포워딩 테이블을 만들어 각 input port에 유지

&ensp;Data Plane은 패킷을 "빠르게 전달", Control Plane은 "어떻게 보낼지 결정".<br/>

&ensp;Input Port Functions<br/>
&ensp;Input Port의 구성 요소<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-6.png" width="500"></p>

1. Line Termination (physical layer)
* 물리 계층 기능
* 전기 신호 → 비트(bit)로 변환
* 즉 패킷을 구성하는 비트를 물리적으로 읽어들이는 단계
2. Link-layer Protocol (링크 계층)
* Ethernet, WiFi 등 링크 계층 프로토콜을 처리
* frame 단위의 처리 담당
3. Lookup, Forwarding, Queueing
* 포워딩 테이블을 lookup하여 어디로 보낼지 결정
* switching fabric으로 패킷을 전달
* 순식간에 처리해야 함
* 만약 스위칭 속도보다 패킷이 빨리 들어오면 queueing 발생

&ensp;Decentralized Switching (분산 스위칭)<br/>
&ensp;input port 스스로 포워딩을 결정한다.<br/>
&ensp;특징<br/>
* 포워딩 테이블이 input port 자체 메모리에 저장되어 있음
* header를 보고 바로 output port를 결정
* 즉, 중앙 routing processor에게 매번 물어보지 않음
* 속도가 매우 빨라짐

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-7.png" width="500"></p>

&ensp;Match + Action 방식<br/>
&ensp;input port는 header의 특정 값을 기준으로 포워딩을 결정한다.<br/>
* match: header field 검사
* action: output port 선택, drop, mark, 등등
* SDN에서도 이 방식 사용

&ensp;두 가지 포워딩 방식<br/>
&ensp;1) Destination-based forwarding (전통적인 방식)<br/>
* 목적지 IP 주소만 보고 포워딩
* 기존 라우팅 알고리즘에서 사용되는 방식

&ensp;2) Generalized forwarding (일반화된 방식)<br/>
* 목적지 주소뿐 아니라
    - 포트 번호
    - 프로토콜 번호
    - VLAN ID
    - TCP flags

&ensp;등 다양한 header 값을 기반으로 결정 가능 → OpenFlow(SDN)의 핵심 개념이기도 함<br/>

# Destination-based Forwarding

&ensp;Destination-based forwarding이란?<br/>
* 들어온 패킷의 목적지의 IP 주소를 보고
* 포워딩 테이블에서 **해당 주소가 속하는 범위(range)**를 찾아
* 그 범위에 해당하는 **링크 인터페이스(포트)** 로 내보내는 방식이다.

&ensp;목적지 주소가 어디에 속하냐에 따라 포트 결정<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-8.png" width="500"></p>

&ensp;노란색 부분: 주소 범위의 시작<br/>
&ensp;분홍색 부분: 주소 범위의 끝<br/>
&ensp;범위 안에 있으면 해당 인터페이스로 전송<br/>

&ensp;주소 범위가 이렇게 딱 맞게 떨어지지 않으면 어떻게 할까?<br/>
&ensp;실제 네트워크에서는 이렇게 예쁘게 범위를 나누기 어렵다.<br/>
&ensp;그래서 등장한 방법이 Longest Prefix Matching이다.

# Longest Prefix Matching

&ensp;Longest Prefix Match란?<br/>
&ensp;라우터는 목적지 주소와 가장 길게(prefix = 맨 앞에서부터 일치하느 ㄴ비트 수가 가장 많은)일치 구간을 선택한다.<br/>
&ensp;여러 항목이 매칭될 때 “더 많은 비트가 일치하는 항목”이 정답이다.<br/>

&ensp;왜 필요한가?<br/>
* 주소범위가 애매하거나 무작위일 때도 안정적인 라우터이 가능
* CIDR(Classless Inter-Domain Routing)의 핵심 기술
* IP 주소 공간을 효율적으로 배분 가능

&ensp;예제 테이블 해석<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-9.png" width="500"></p>

&ensp;prefix 길이가 각각 다르다.<br/>

&ensp;예제 주소 매칭하기<br/>
&ensp;예제 1<br/>
&ensp;주소: 11001000 00010111 00010110 10100001<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-10.png" width="500"></p>

&ensp;→ Prefix 비교<br/>
* 00010***
* 00011000
* 00011***

&ensp;이 중에서 00010이 가장 길게 매칭됨 → Interface 0<br/>

&ensp;예제 2<br/>
&ensp;주소: 11001000 00010111 00011000 10101010<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-11.png" width="500"></p>

&ensp;→ Prefix 정확히: 00011000 → Interface 1<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-12.png" width="500"></p>
&ensp;→ Prefix 00011*** → Interface 2<br/>

&ensp;Longest Prefix Matching in Hardware<br/>
&ensp;1. TCAM(Ternary Content Addressable Memory)<br/>
&ensp;Longest Prefix Matching은 TCAM이라는 특수한 메모리에서 처리된다.<br/>
&ensp;TCAM 특징<br/>
* 주소를 넣으면 "어느 prefix가 가장 잘 맞는지"를 한 번에 검색
* 일반 메모리는 주소를 주고 데이터 읽음
* TCAM은 패턴을 주고 패턴과 일치하는 항목을 찾아줌 → Content Addressable이라고 부르는 이유

&ensp;2. 장점<br/>
* 테이블 크기와 무관하게 1 clock cycle 만에 결과 반환
* 매우 빠른 포워딩 가능

&ensp;Cisco Catalyst 같은 라우터는 약 100만 개(1M) 라우팅 엔트리를 TCAM에 넣고도 빠르게 검색할 수 있다.<br/>

| 개념                           | 설명                            |
| ---------------------------- | ----------------------------- |
| Destination-based forwarding | 범위 기반 포워딩, 하지만 비효율적           |
| Longest Prefix Matching      | 가장 길게 일치하는 prefix 선택          |
| 왜 필요한가?                      | 주소 범위가 깔끔하게 안 나누어져도 정확한 매칭 가능 |
| 구현?                          | TCAM이라는 하드웨어 사용               |
| 장점                           | 매우 빠르고 대규모 라우팅 테이블도 처리 가능     |

Switching fabrics
-----

&ensp;핵심 개념<br/>
&ensp;라우터에는 여러 개의 입력 포트와 출력 포트가 있다. <br/>
&ensp;스위칭 패브릭(switching fabric)은 입력 포트에서 들어온 패킷을 적절한 포트로 연결해주는 장치(라우터 내부의 교통 정리 시스템)이다.<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-13.png" width="500"></p>

&ensp;두 가지 중요 포인트<br/>
&ensp;1. 패킷 전달 기능<br/>
&ensp;어떤 목적지 IP로 가야 하는지 input port에서 lookup이 끝나면 스위칭 패브릭이 패킷을 output port로 옮겨준다.<br/>
&ensp;2. Switching rate<br/>
&ensp;패브릭이 패킷을 얼마나 빠르게 처리할 수 있는지를 의미<br/>
* N개의 입력 포트가 있따면 이상적으로 N배 속도로 스위칭하는 것이 좋다.
* 왜? → 모든 입력 포트가 동시에 패킷을 보내도 막힘 없이 처리할 수 있어야 하니까.

&ensp;Switching fabrics의 세 가지 구조<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-14.png" width="500"></p>

# Via memory (메모리 기반 스위칭)

&ensp;전통적인 컴퓨터 방식처럼:<br/>
```scss
input port → system memory (copy) → output port
```

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-15.png" width="500"></p>

&ensp;특징<br/>
* CPU가 직접 패킷 이동을 제어하던 초기 라우터 방식
* 패킷이 메모리에 두 번 이동
1. input → memory
2. input → memory

&ensp;단점<br/>
* 메모리 대역폭이 속도의 한계
* CPU가 모든 것을 처리해야 해서 속도 느림 → 초기 세대 라우터에서나 사용됨

# Via a bus (버스 기반 스위칭)

&ensp;구조<br/>
&ensp;여러 input/output 포트가 하나의 공유 버스를 사용함.<br/>
```scss
input port → (공유 bus) → output port
```

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-16.png" width="500"></p>

&ensp;장점<br/>
* 구조 단순, 비용 저렴
* 작은 규모 라우터에서 많이 사용됨

&ensp;단점<br/>
* bus contention(버스 경합) : 여러 입력 포트가 동시에 버스를 사용하려 하면 → 버스는 한 번에 하나의 전송만 가능 → 처리량 제한

# Interconnection Network (교차망 기반)

&ensp;구조<br/>
&ensp;멀티스테이지 스위치 구조<br/>
&ensp;고성능 라우터에서 사용하는 스위칭 구조.<br/>
&ensp;Memory 방식도 아니고, Bus 방식도 아니고, 여러 스위치를 서로 연결한 네트워크 구조를 사용해 병렬 처리를 극대화하는 방법이다.<br/>
* 버스처럼 1개가 아닌 여러 개의 내부 경로
* 여러 input → output 동시 처리 가능

&ensp;장점<br/>
* 고성능 라우터에 사용됨
* 동시에 다수의 패킷이 병렬로 이동 가능

&ensp;단점<br/>
* 구조 복잡
* 비용↑

&ensp;1. Crossbar, Clos network… 이런 구조들 뭘까?<br/>
&ensp;이 구조들은 원래 멀티프로세서 컴퓨터(CPU 여러 개 있는 서버)에서 CPU ↔ 메모리 ↔ 장치같은 것들을 빠르게 연결하기 위해 만들어진 스위칭 구조이다. → 그걸 라우터에도 적용한 것<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-17.png" width="500"></p>

&ensp;대표적인 구조<br/>
* Crossbar switch: 입력 N개 → 출력 N개를 내부에 N×N의 교차점으로 연결 (모든 input이 모든 output과 연결 가능)
* Clos network: Crossbar를 여러 단계로 이어붙인 구조 (규모 확장 쉬움)

&ensp;2. Multistage switch (멀티스테이지 스위치)<br/>
&ensp;큰 NxN 스위치를 한 단계로 만들면 너무 크고 비싸니까… → 이를 여러 개의 작은 스위치로 "계층적으로" 구성한 구조가 바로 multistage switch!<br/>
&ensp;예: 8×8 스위치 → 작은 2×2 스위치를 여러 단계(Stage)로 연결하여 구성<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-18.png" width="500"></p>

&ensp;장점<br/>
* 장비 비용 ↓
* 확장성 ↑
* 여러 패킷을 병렬로 전달 가능 (병렬성 up)

&ensp;3. Exploiting parallelism (병렬성을 활용)<br/>
&ensp;인터너커넥션 네트워크는 내부가 병렬 구조이기 때문에:<br/>
&ensp;1) Datagram을 "고정 길이 셀(cell)"로 잘라서 전달<br/>
&ensp;ATM 셀처럼 일정한 크기 단위로 쪼개서 보냄 → 내부에서 균일하게 처리하기 쉽게 만듦<br/>
&ensp;2) 셀 단위로 스위치 내부를 병렬로 통과<br/>
&ensp;여러 셀이 동시에 서로 다른 경로로 이동 가능<br/>
&ensp;3) 출력 포트에서 다시 조립(reassembly)<br/>
&ensp;원래의 datagram으로 재구성<br/>

&ensp;4. Scaling using multiple switching planes<br/>
&ensp;고성능 라우터(백본 라우터)에서는 하나의 스위칭 패브릭조차도 부족하다. 그래서 여러 개의 스위칭 패브릭을 병렬로 사용 → switching plane을 여러 개 둠<br/>
&ensp;각 plane은 서로 독립<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-19.png" width="500"></p>

&ensp;장점<br/>
* 처리량 수평 확장 가능 (scale-out 방식)
* 패킷을 여러 plane으로 분산 → 병렬 처리량 증가 → 라우터 전체 처리 속도 폭발적으로 증가

# 요약

| 방식              | 설명                   | 장점        | 단점             |
| --------------- | -------------------- | --------- | -------------- |
| **Crossbar**    | 입력 N ↔ 출력 N 모두 독립 연결 | 병목 없음, 고속 | N² 스위치 필요 (비쌈) |
| **Multistage**  | 작은 스위치 여러 단계로 구성     | 확장성 좋음    | 경로 충돌 가능       |
| **병렬 plane 구조** | 여러 패브릭을 병렬로 사용       | Tbps급 처리  | 구조 복잡          |

port queueing
-----

# Input port queueing (입력 포트에서 생기는 큐잉)

&ensp;스위치 패브릭이 input 포트 전체 속도보다 느리면? → 입력 포트에 패킷이 몰려서 줄을 서기 시작함(queueing)<br/>
&ensp;나타날 문제<br/>
1. queueing delay (지연)
2. buffer overflow → packet loss 

&ensp;입력 포트 버퍼가 꽉 차면 더 이상 저장 못 해서 패킷을 버림(drop)<br/>

&ensp;핵심: HOL(Head-of-Line) Blocking<br/>
&ensp;큐 맨 앞에 있는 패킷이 막히면(전달 불가), 뒤에 있는 패킷들도 같이 못 나가는 현상이다. 즉 앞 사람이 막혀서 뒤에 줄 선 사람들도 못 지나간다.<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-20.png" width="500"></p>

&ensp;왼쪽 그림<br/>
* 두 개의 빨간 패킷(red)이 같은 output 포트로 가려고 함 → Output port contention(경쟁)
* 스위치 패브릭은 한 번에 red 하나만 보낼 수 있음
* 아래 빨간 패킷은 앞에 있는 파란/초록 패킷 때문에 앞으로 못 나옴 → 이게 바로 HOL blocking

&ensp;오른쪽 그림<br/>
* 시간이 지나도 초록 패킷이 앞에 있는데 초록은 막혀 있어서 output으로 못 나감
* 뒤의 빨간/파란 패킷도 덩달아 못 나가게 됨 → HOL blocking 지속

&ensp;HOL Blocking은 왜 문제인가?<br/>
* 스위치가 아무리 빠르더라도 큐 맨 앞이 막히면 전체 대역폭을 활용 못함
* 따라서 throughput 감소(30%만 활용되는 경우도 있음)

# Output Port Queueing (출력 포트 큐잉)

&ensp;입력 포트가 아니라 이번엔 출력 포트 쪽에서 큐잉이 발생하는 경우<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-21.png" width="500"></p>

&ensp;언제 output queueing 발생?<br/>
&ensp;switch fabric 속도 > output link 속도 R<br/>
&ensp;스위치 내부에서는 패킷을 빨리 output 포트로 보내는데 output 포트가 외부 링크로 내보내는 속도는 더 느린 경우 → 패킷이 output 포트 버퍼에 쌓임(queueing)<br/>

<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-22.png" width="500"></p>

&ensp;왼쪽 그림<br/>
* 여러 input 포트에서 output 포트로 패킷이 동시에 도착
* output 포트는 한 번에 하나만 보낼 수 있으므로 밀림 현상 발생

&ensp;오른쪽 그림<br/>
* 한 시간 단위(packet time) 뒤
* 오히려 더 많은 패킷이 output 포트로 몰림 → 큐가 길어짐 → 버퍼 overflow 가능, packet loss 발생

&ensp;Output Port에서 중요한 두 가지<br/>
&ensp;1) Buffering<br/>
* 출력 포트에서 패킷이 몰리므로 버퍼가 반드시 필요
* 버퍼 부족 → drop 발생 → "Drop policy" 필요
  - tail drop
  - RED(Random Early Detection) 등

&ensp;2) Scheduling Discipline (스케줄링 정책)<br/>
* 어떤 패킷을 먼저 보낼 것인지 결정
* 대표적인 스케줄링:
  - FIFO
  - Priority Queue
  - Weighted Fair Queuing (WFQ) 등

&ensp;얼마나 버퍼를 둬야 할까?<br/>
&ensp;1) RFC 3439 전통적 공식<br/>
&ensp;**버퍼 크기 = RTT × 링크 용량(C)**<br/>
&ensp;예시<br/>
* RTT ≈ 250 ms
* 링크 용량 C = 10Gbps

&ensp;→ 필요한 버퍼 = 0.25 × 10Gbps = 2.5 Gbit 버퍼<br/>

&ensp;이런 공식인 나온 이유: TCP는 혼잡신호를 받으면 윈도우 크기를 절반으로 줄인다. → 링크가 비지 않도록(underutilization 방지) 최소 RTT 동안 데이터를 쌓아둘 버퍼가 필요했기 때문<br/>

&ensp;문제점<br/>
&ensp;이 방식은 버퍼를 너무 크게 만드는 경향이 있다. → "버퍼블로트(bufferbloat)" 발생<br/>
* 지연(delay) 증가
* TCP 반응 느려짐
* 실시간 앱 성능 저하

&ensp;2) 최신 권장 공식: 여러 플로우가 있을 때<br/>
&ensp;**버퍼 = (RTT × C) / √N**<br/>
* N = 동시에 지나가는 TCP 흐름(flow)의 개수
* √N 로 나누면 버퍼가 훨씬 작아짐

&ensp;→ 대형 ISP 라우터는 수천 개 이상의 플로우를 처리하므로 실제로 필요한 버퍼는 매우 작아진다.<br/>

# Buffer Management (버퍼 관리)

&ensp;버퍼가 꽉 찰 때 라우터가 어떤 패킷을 버릴지(dropping) 또는 표시(marking)할지 결정하는 정책<br/>
&ensp;1) Dropping 정책 (Drop policy)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-23.png" width="500"></p>

&ensp;(1) Tail drop (가장 단순한 방식)<br/>
&ensp;버퍼가 꽉 차면 신규로 도착한 패킷을 버린다.<br/>
&ensp;단점<br/>
* 여러 TCP 연결이 동시에 패킷 손실됨 → 전부 느려짐
* 글로벌 동기화(global synchronization) 문제 발생

&ensp;(2) Priority drop<br/>
&ensp;우선순ㅇ뉘 기반으로 패킷을 버림<br/>
* Qos(품질 보장)가 필요한 VoIP, 스트리밍 등은 drop 덜 함
* 불필요한 flow는 먼저 drop

&ensp;2) Marking 정책 (혼잡을 "표시"만 함)<br/>
&ensp;링크가 혼잡해지기 전에 패킷에 표시만 하여 송신자가 미리 속도를 줄이게 하는 방식<br/>
&ensp;(1) ECN (Explicit Congestion Notification)<br/>
* 패킷에 CE(Congestion Experienced) 비트를 설정
* 송신자에게 혼잡을 "신호"만 보냄 → 패킷 자체는 drop하지 않음

&ensp;(2) RED (Random Early Detection)<br/>
* 버퍼가 가득 차기 전에 "확률적으로" 패킷을 drop하거나 marking → TCP가 미리 속도 줄임
→ tail drop 같은 대량 동기화 방지

&ensp;Queue abstraction (대기열 추상화)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-24.png" width="500"></p>

&ensp;버퍼는 사실상 queue 처럼 동작한다.<br/>
* 패킷이 도착
* 큐에 들어감
* 링크(서버 속도 R)에 따라 차례대로 나감

&ensp;버퍼가 크면:<br/>
* delay 증가
* overflow 발생 가능

# Packet Scheduling

&ensp;패킷 스케줄링: 링크로 어떤 패킷을 먼저 보낼지 결정하는 방식<br/>

&ensp;스케줄링 방식의 종류는 다음과 같다.<br/>
* FCFS (FIFO): 먼저 온 패킷 먼저 처리
* Priority: 중요도가 높은 패킷 먼저 처리
* Round Robin: 여러 클래스(분류)의 패킷을 돌아가며 처리
* Weighted Fair Queueing (WFQ): 각 클래스에 비중(Weight)을 주어 공평하게 처리

&ensp;1. FCFS (First Come First Served)<br/>
&ensp;개념<br/>
* 가장 단순한 방식
* 먼저 도착한 패킷부터 전송
* 현실 세계 예: 은행 줄, 버스 정류장의 줄

&ensp;특징<br/>
* 구현이 쉽다
* 하지만 대기 시간이 큰 패킷 때문에 전체가 느려질 수 있다. (Head-of-line blocking)

&ensp;2. Priority Scheduling (우선순위 스케줄링)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-25.png" width="500"></p>

&ensp;개념<br/>
&ensp;패킷을 등급별로 나누고(high priority, low priority…), 중요도가 높은 패킷을 먼저 서비스하는 방식<br/>

&ensp;동작 방식<br/>
1. 패킷의 헤더를 보고 등급을 분류
2. 우선순위가 높은 큐부터 서비스
3. 같은 큐 안에서는 FCFS 처리

&ensp;장점<br/>
* 긴급한 패킷(예: 음성 통화, 스트리밍)을 빠르게 보낼 수 있음

&ensp;단점<br/>
* 낮은 우선순위 패킷이 계속 대기 → Starvation(기아현상) 가능

&ensp;3. Round Robin Scheduling (라운드 로빈)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-26.png" width="500"></p>

&ensp;개념<br/>
* 클래스 A → B → C → A → B → C 순서로 순환하면서 한 패킷씩 처리하는 방식

&ensp;특징<br/>
* 모든 클래스가 고르게 처리 기회를 가짐 → 공평함
* 클래스별 트래픽 양과 관계없이 "한 번씩 차례대로" 처리
* 패킷 크기가 다르면 불공평할 수 있음

&ensp;4. Weighted Fair Queueing (WFQ)<br/>
<p align="center"><img src="/assets/img/Computer Network/chapter 4. Network Layer/4-27.png" width="500"></p>

&ensp;개념<br/>
&ensp;Round Robin을 확장한 방식으로 각 클래스에 **가중치(Weight)**를 주어 더 중요한 클래스가 더 많은 비중을 갖도록 하는 방식<br/>

&ensp;수식<br/>
&ensp;각 클래스 i가 받는 비중은 $\frac{w_i}{\sum _{j}w_j}$ <br/>

&ensp;장점<br/>
* 각 클래스별 최소 대역폭 보장
* 네트워크 자원을 공평하게 나누면서도 우선순위 조절 가능

| 스케줄링 방식         | 특징            | 장점          | 단점              |
| --------------- | ------------- | ----------- | --------------- |
| **FCFS**        | 먼저 온 패킷 먼저    | 단순          | 특정 패킷 때문에 전체 지연 |
| **Priority**    | 우선순위 높은 패킷 먼저 | 긴급 트래픽에 유리  | 기아 현상 가능        |
| **Round Robin** | 클래스별로 번갈아 처리  | 공평          | 비효율적일 수 있음      |
| **WFQ**         | 각 클래스에 가중치 부여 | QoS 보장, 공정성 | 구현 복잡           |


Network Neutrality
----

&ensp;트워크 중립성(Network Neutrality)은 ISP(Internet Service Provider, 인터넷 제공자)가 모든 인터넷 트래픽을 공정하게 다뤄야 한다는 원칙이다.<br/>
&ensp;→ 특정 웹사이트·앱·서비스를 차별하거나 우대하면 안 된다는 규칙<br/>

&ensp;1) Technical 관점<br/>
&ensp;ISP가 네트워크 자원을 어떻게 나눠쓰게 할 것인가?<br/>
* 패킷 스케줄링
* 버퍼 관리

&ensp;→ 이런 기술적 메커니즘으로 인터넷 트래픽을 관리함<br/>

&ensp;2) 사회적·경제적 관점<br/>
* 자유로운 표현의 보호
* 혁신·경쟁을 장려
&ensp;→ 특정 기업만 빠르게 해주지 않도록 해 공정한 경쟁을 보장<br/>

&ensp;3) 법적 관점<br/>
* 각 나라가 네트워크 중립성을 어떻게 규정할지 법과 정책으로 정함